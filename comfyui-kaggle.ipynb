{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"server_env=\"kaggle\" # kaggle CN_server colab\nif server_env==\"CN_server\":\n    !git config --global url.\"https://mirror.ghproxy.com/https://github.com/\".insteadOf https://github.com/\n    !export HF_ENDPOINT=https://hf-mirror.com\n    # !export HF_ENDPOINT=https://hf-api.gitee.com","metadata":{"execution":{"iopub.status.busy":"2024-10-08T07:18:05.101451Z","iopub.execute_input":"2024-10-08T07:18:05.101854Z","iopub.status.idle":"2024-10-08T07:18:05.114934Z","shell.execute_reply.started":"2024-10-08T07:18:05.101815Z","shell.execute_reply":"2024-10-08T07:18:05.113407Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvcc --version\n!nvidia-smi \n\n!pip list |grep numba\n!pip list |grep numpy\n!pip list |grep transformers","metadata":{"execution":{"iopub.status.busy":"2024-10-08T07:47:34.267450Z","iopub.execute_input":"2024-10-08T07:47:34.267910Z","iopub.status.idle":"2024-10-08T07:47:44.366203Z","shell.execute_reply.started":"2024-10-08T07:47:34.267867Z","shell.execute_reply":"2024-10-08T07:47:44.364785Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/\n!git clone https://github.com/comfyanonymous/ComfyUI.git\n\n%cd /kaggle/working/ComfyUI\n# branch\n!git checkout master\n# update\n!git pull\n!pip install -r requirements.txt \n#pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu121","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-08T07:20:24.873368Z","iopub.execute_input":"2024-10-08T07:20:24.873764Z","iopub.status.idle":"2024-10-08T07:20:44.679899Z","shell.execute_reply.started":"2024-10-08T07:20:24.873729Z","shell.execute_reply":"2024-10-08T07:20:44.678760Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd  /kaggle/working/ComfyUI/custom_nodes\n!git clone https://github.com/ltdrdata/ComfyUI-Manager.git\n!git clone https://github.com/Stability-AI/stability-ComfyUI-nodes.git\n!git clone https://github.com/Kosinkadink/ComfyUI-Advanced-ControlNet\n!git clone https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite\n!git clone https://github.com/Kosinkadink/ComfyUI-AnimateDiff-Evolved\n!git clone https://github.com/cubiq/ComfyUI_IPAdapter_plus\n!git clone https://github.com/WASasquatch/was-node-suite-comfyui\n!git clone https://github.com/EllangoK/ComfyUI-post-processing-nodes.git \n!git clone https://github.com/Fannovel16/comfyui_controlnet_aux\n!git clone https://github.com/chrisgoringe/cg-use-everywhere.git\n!git clone https://github.com/yolain/ComfyUI-Easy-Use.git\n!git clone https://github.com/ltdrdata/ComfyUI-Inspire-Pack\n!git clone https://github.com/huchenlei/ComfyUI-layerdiffuse.git   \n# !git clone https://github.com/chflame163/ComfyUI_LayerStyle\n!git clone https://github.com/Gourieff/comfyui-reactor-node\n# !git clone https://github.com/kijai/ComfyUI-MimicMotionWrapper\n!git clone https://github.com/kijai/ComfyUI-segment-anything-2\n# !git clone https://github.com/AIFSH/GSTTS-ComfyUI\n# !git clone https://github.com/kijai/ComfyUI-ControlNeXt-SVD\n!git clone https://github.com/john-mnz/ComfyUI-Inspyrenet-Rembg\n# !git clone https://github.com/PowerHouseMan/ComfyUI-AdvancedLivePortrait\n!git clone https://github.com/lldacing/ComfyUI_BiRefNet_ll\n!git clone https://github.com/StartHua/Comfyui_joytag\n!git clone https://github.com/rgthree/rgthree-comfy\n# ComfyUI-Custom-Scripts\n!git clone https://github.com/Fannovel16/ComfyUI-Frame-Interpolation\n!git clone https://github.com/kijai/ComfyUI-KJNodes\n# !git clone https://github.com/kijai/ComfyUI-LivePortraitKJ\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-08T07:18:05.120867Z","iopub.execute_input":"2024-10-08T07:18:05.121168Z","iopub.status.idle":"2024-10-08T07:19:23.423331Z","shell.execute_reply.started":"2024-10-08T07:18:05.121138Z","shell.execute_reply":"2024-10-08T07:19:23.422133Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd  /kaggle/working/ComfyUI\n!wget https://civitai.com/api/download/models/125849 -O ./models/embeddings/bad-hands-5.pt\n!wget https://huggingface.co/datasets/gsdf/EasyNegative/resolve/main/EasyNegative.safetensors -O ./models/embeddings/EasyNegative.safetensors\n!wget https://civitai.com/api/download/models/5637 -O ./models/embeddings/deepnegative_v1_75t.pt\n","metadata":{"execution":{"iopub.status.busy":"2024-10-08T07:24:39.395133Z","iopub.execute_input":"2024-10-08T07:24:39.395532Z","iopub.status.idle":"2024-10-08T07:24:46.653082Z","shell.execute_reply.started":"2024-10-08T07:24:39.395495Z","shell.execute_reply":"2024-10-08T07:24:46.652035Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## REBOOT","metadata":{}},{"cell_type":"code","source":"!nvcc --version\n!nvidia-smi \n!lscpu | grep '^Thread(s) per core'\n!lscpu | grep '^CPU(s):' | awk '{print $2}'","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Config","metadata":{}},{"cell_type":"code","source":"# config\nlocalproxy = \"localtunnel\" # ngrok localtunnel\n\nsdxl=0\nsd15=0\nAN=0\nkolors=1\npony=0\nflux=0\nkrita=0\ncogvideo=0\nsam2=0\nLivePortrait=0\ncontrolnext_comfy=0\nmimicmotion=0\nGSTTS=0\nRVC=0\n\nhf_token =\"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\"\ncivitai_token =\"bbf631e0a67a9c72d8044d3552ec3079\"\nngrok_token=\"2Z6mxdfOQtkCd0cRypa73E1YTSi_3pByoAmFqphopTJ585RGu\"\n\nif localproxy==\"localtunnel\":\n    !npm install -g localtunnel\nelse:\n    !pip install pyngrok","metadata":{"execution":{"iopub.status.busy":"2024-10-25T04:45:18.928356Z","iopub.execute_input":"2024-10-25T04:45:18.928662Z","iopub.status.idle":"2024-10-25T04:45:23.172208Z","shell.execute_reply.started":"2024-10-25T04:45:18.928628Z","shell.execute_reply":"2024-10-25T04:45:23.170943Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[K\u001b[?25hm#################\u001b[0m\u001b[100;90m.\u001b[0m] / reify:yargs-parser: \u001b[32;40mhttp\u001b[0m \u001b[35mfetch\u001b[0m GET 200 https://registry.\u001b[0m\u001b[K\nadded 22 packages in 2s\n\n3 packages are looking for funding\n  run `npm fund` for details\n\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m \n\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m New \u001b[33mminor\u001b[39m version of npm available! \u001b[31m10.5.0\u001b[39m -> \u001b[32m10.9.0\u001b[39m\n\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m Changelog: \u001b[36mhttps://github.com/npm/cli/releases/tag/v10.9.0\u001b[39m\n\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m Run \u001b[32mnpm install -g npm@10.9.0\u001b[39m to update!\n\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m \n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"%cd /kaggle/working/ComfyUI\n\ncontent = \"\"\"\ncomfyui:\n     base_path: /kaggle/working/ComfyUI\n     checkpoints: /opt/models/checkpoints/\n     clip: /opt/models/clip/\n     clip_vision: /opt/models/clip_vision/\n     configs: /opt/models/configs/\n     controlnet: /opt/models/controlnet/\n     embeddings: /opt/models/embeddings/\n     loras: /opt/models/loras/\n     upscale_models: /opt/models/upscale_models/\n     vae: /opt/models/vae/\n     unet: /opt/models/unet/ \n     LLM: /opt/models/LLM/ \n     sam2: /opt/models/sam2/ \n     ipadapter: /opt/models/ipadapter/ \n     animatediff_models: /opt/models/animatediff_models/ \n     animatediff_motion_lora: /opt/models/animatediff_motion_lora/ \n\"\"\"\n\n# 将内容写入文件 'a'\nwith open('extra_model_paths.yaml', 'w') as file:\n    file.write(content)","metadata":{"execution":{"iopub.status.busy":"2024-10-25T04:45:23.174861Z","iopub.execute_input":"2024-10-25T04:45:23.175306Z","iopub.status.idle":"2024-10-25T04:45:23.187647Z","shell.execute_reply.started":"2024-10-25T04:45:23.175251Z","shell.execute_reply":"2024-10-25T04:45:23.186331Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/working/ComfyUI\n","output_type":"stream"}]},{"cell_type":"code","source":"\n%cd /kaggle/working/ComfyUI\n!apt -y update -qq\n!apt -y install -qq aria2\n# !pip install gdown\n!pip install huggingface_hub  hf_transfer\nimport os\nos.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-25T04:45:23.189233Z","iopub.execute_input":"2024-10-25T04:45:23.189622Z","iopub.status.idle":"2024-10-25T04:45:51.803330Z","shell.execute_reply.started":"2024-10-25T04:45:23.189581Z","shell.execute_reply":"2024-10-25T04:45:51.802174Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/working/ComfyUI\n70 packages can be upgraded. Run 'apt list --upgradable' to see them.\n\u001b[1;33mW: \u001b[0mhttps://packages.cloud.google.com/apt/dists/gcsfuse-focal/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\u001b[0m\n\u001b[1;33mW: \u001b[0mhttps://packages.cloud.google.com/apt/dists/google-fast-socket/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\u001b[0m\nThe following additional packages will be installed:\n  libaria2-0 libc-ares2 libssh2-1\nThe following NEW packages will be installed:\n  aria2 libaria2-0 libc-ares2 libssh2-1\n0 upgraded, 4 newly installed, 0 to remove and 70 not upgraded.\nNeed to get 1622 kB of archives.\nAfter this operation, 5817 kB of additional disk space will be used.\n\n\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package libc-ares2:amd64.\n(Reading database ... 122996 files and directories currently installed.)\nPreparing to unpack .../libc-ares2_1.18.1-1ubuntu0.22.04.3_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  6%]\u001b[49m\u001b[39m [###.......................................................] \u001b8Unpacking libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 12%]\u001b[49m\u001b[39m [######....................................................] \u001b8Selecting previously unselected package libssh2-1:amd64.\nPreparing to unpack .../libssh2-1_1.10.0-3_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 18%]\u001b[49m\u001b[39m [##########................................................] \u001b8Unpacking libssh2-1:amd64 (1.10.0-3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 24%]\u001b[49m\u001b[39m [#############.............................................] \u001b8Selecting previously unselected package libaria2-0:amd64.\nPreparing to unpack .../libaria2-0_1.36.0-1_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 29%]\u001b[49m\u001b[39m [#################.........................................] \u001b8Unpacking libaria2-0:amd64 (1.36.0-1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 35%]\u001b[49m\u001b[39m [####################......................................] \u001b8Selecting previously unselected package aria2.\nPreparing to unpack .../aria2_1.36.0-1_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 41%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Unpacking aria2 (1.36.0-1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 47%]\u001b[49m\u001b[39m [###########################...............................] \u001b8Setting up libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 53%]\u001b[49m\u001b[39m [##############################............................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 59%]\u001b[49m\u001b[39m [##################################........................] \u001b8Setting up libssh2-1:amd64 (1.10.0-3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 65%]\u001b[49m\u001b[39m [#####################################.....................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 71%]\u001b[49m\u001b[39m [########################################..................] \u001b8Setting up libaria2-0:amd64 (1.36.0-1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 76%]\u001b[49m\u001b[39m [############################################..............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 82%]\u001b[49m\u001b[39m [###############################################...........] \u001b8Setting up aria2 (1.36.0-1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 88%]\u001b[49m\u001b[39m [###################################################.......] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 94%]\u001b[49m\u001b[39m [######################################################....] \u001b8Processing triggers for man-db (2.10.2-1) ...\nProcessing triggers for libc-bin (2.35-0ubuntu3.8) ...\n\n\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[JRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.25.1)\nCollecting hf_transfer\n  Downloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.8.30)\nDownloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: hf_transfer\nSuccessfully installed hf_transfer-0.1.8\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Download models","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working/ComfyUI\n\n\nfrom huggingface_hub import snapshot_download, hf_hub_download\n\nimport os\n%mkdir /opt/models\n\nsnapshot_download(repo_id=\"Acly/Omni-SR\",  allow_patterns=[\"*.safetensors\"], local_dir=\"/opt/models/upscale_models\")\nsnapshot_download(repo_id=\"alexgenovese/reica_upscalers\",  local_dir=\"/opt/models/upscale_models\" )\n\n\nif sd15==1:\n    # !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/131004 -d /opt/models/checkpoints -o DreamShaperV8_inpaint.safetensors\n    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/128713 -d /opt/models/checkpoints -o DreamShaperV8.safetensors\n#     !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/624939?token=$civitai_token  -d /opt/models/checkpoints -o AWPainting.safetensors #2d toon\n    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/474453?token=$civitai_token   -d /opt/models/checkpoints -o ReV_Animated.safetensors #2.5d\n#     !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/119057 -d /opt/models/checkpoints -o MeinaMix.safetensors #2d mango\n    \n    # control-lora-v3 try it\n    hf_hub_download(repo_id=\"ByteDance/Hyper-SD\", filename=\"Hyper-SD15-8steps-CFG-lora.safetensors\", local_dir=\"/opt/models/loras\" )\n    # hf_hub_download(repo_id=\"ByteDance/Hyper-SD\", filename=\"Hyper-SD15-2steps-lora.safetensors\", local_dir=\"/opt/models/loras\" )\n    snapshot_download(repo_id=\"comfyanonymous/ControlNet-v1-1_fp16_safetensors\",  allow_patterns=[\"control_v11*.safetensors\"], local_dir=\"/opt/models/controlnet\" )\n    # snapshot_download(repo_id=\"webui/ControlNet-modules-safetensors\",  allow_patterns=[\"t2iadapter*.safetensors\"], local_dir=\"/opt/models/controlnet\" )\n\n    hf_hub_download(repo_id=\"h94/IP-Adapter\",subfolder='models',filename=\"ip-adapter_sd15.safetensors\", local_dir=\"/opt/models/ipadapter\")\n    hf_hub_download(repo_id=\"h94/IP-Adapter\",subfolder='models',filename=\"ip-adapter-plus_sd15.safetensors\", local_dir=\"/opt/models/ipadapter\")\n    hf_hub_download(repo_id=\"h94/IP-Adapter-FaceID\", filename=\"ip-adapter-faceid-plusv2_sd15.bin\", local_dir=\"/opt/models/ipadapter\")\n    hf_hub_download(repo_id=\"h94/IP-Adapter-FaceID\", filename=\"ip-adapter-faceid-plusv2_sd15_lora.safetensors\", local_dir=\"/opt/models/loras\")\n    hf_hub_download(repo_id=\"h94/IP-Adapter\", subfolder=\"models/image_encoder\", filename=\"model.safetensors\", local_dir=\"/opt/models/clip_vision\")\n    os.rename('/opt/models/clip_vision/models/image_encoder/model.safetensors','/opt/models/clip_vision/CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors')\n\nif AN==1:\n    hf_hub_download(repo_id=\"conrevo/AnimateDiff-A1111\", filename=\"mm_sd15_v3.safetensors\", subfolder=\"motion_module\", local_dir=\"/opt/models/animatediff_models\")\n    # hf_hub_download(repo_id=\"wangfuyun/AnimateLCM-I2V\", filename=\"AnimateLCM_sd15_i2v.ckpt\",  local_dir=\"/opt/models/animatediff_models\")\n    hf_hub_download(repo_id=\"conrevo/AnimateDiff-A1111\", filename=\"mm_sd15_AnimateLCM.safetensors\", subfolder=\"motion_module\", local_dir=\"/opt/models/animatediff_models\")\n    hf_hub_download(repo_id=\"conrevo/AnimateDiff-A1111\", filename=\"mm_sd15_v3_adapter.safetensors\", subfolder=\"lora\", local_dir=\"/opt/models/loras\" )\n    hf_hub_download(repo_id=\"latent-consistency/lcm-lora-sdv1-5\", filename=\"pytorch_lora_weights.safetensors\", local_dir=\"/opt/models/loras\" )\n    os.rename('/opt/models/loras/pytorch_lora_weights.safetensors','/opt/models/loras/lcm.safetensors')\n    hf_hub_download(repo_id=\"guoyww/animatediff-sparsectrl-rgb\", filename=\"diffusion_pytorch_model.fp16.safetensors\",  local_dir=\"/opt/models/controlnet\")\n    os.rename('/opt/models/controlnet/diffusion_pytorch_model.fp16.safetensors','/opt/models/controlnet/animatediff-sparsectrl-rgb.safetensors')\n    hf_hub_download(repo_id=\"stabilityai/sd-vae-ft-mse-original\", filename=\"vae-ft-mse-840000-ema-pruned.safetensors\",  local_dir=\"/opt/models/vae\")\n\n\n# hyper\nif sdxl==1:\n#     !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M  -d /opt/models/checkpoints -o dreamshaper.turbo.xl.safetensors https://civitai.com/api/download/models/351306?type=Model\n#         AlbedoBase XL try it\n    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M  -d /opt/models/checkpoints -o AlbedoBase.XL.v3-mini.safetensors https://civitai.com/api/download/models/892880?type=Model\n\n    hf_hub_download(repo_id=\"ByteDance/Hyper-SD\", filename=\"Hyper-SDXL-8steps-CFG-lora.safetensors\", local_dir=\"/opt/models/loras\" )\n    hf_hub_download(repo_id=\"xinsir/controlnet-union-sdxl-1.0\", filename=\"diffusion_pytorch_model_promax.safetensors\", local_dir=\"/opt/models/controlnet\")\n    os.rename('/opt/models/controlnet/diffusion_pytorch_model_promax.safetensors','/opt/models/controlnet/union-promax-sdxl-1.0.safetensors')\n    hf_hub_download(repo_id=\"TheMistoAI/MistoLine\", filename=\"mistoLine_rank256.safetensors\", local_dir=\"/opt/models/controlnet\")\n    hf_hub_download(repo_id=\"xinsir/controlnet-tile-sdxl-1.0\", filename=\"diffusion_pytorch_model.safetensors\", local_dir=\"/opt/models/controlnet\")\n    os.rename('/opt/models/controlnet/diffusion_pytorch_model.safetensors','/opt/models/controlnet/xinsir.tile.xl.safetensors')\n    hf_hub_download(repo_id=\"h94/IP-Adapter\", subfolder='sdxl_models', filename=\"ip-adapter_sdxl_vit-h.safetensors\", local_dir=\"/opt/models/ipadapter\")\n    hf_hub_download(repo_id=\"h94/IP-Adapter\", subfolder='sdxl_models', filename=\"ip-adapter-plus_sdxl_vit-h.safetensors\", local_dir=\"/opt/models/ipadapter\")\n    hf_hub_download(repo_id=\"h94/IP-Adapter-FaceID\", filename=\"ip-adapter-faceid-plusv2_sdxl.bin\", local_dir=\"/opt/models/ipadapter\")\n    hf_hub_download(repo_id=\"h94/IP-Adapter-FaceID\", filename=\"ip-adapter-faceid-plusv2_sdxl_lora.safetensors\", local_dir=\"/opt/models/loras\")\n    hf_hub_download(repo_id=\"h94/IP-Adapter\", subfolder=\"models/image_encoder\", filename=\"model.safetensors\", local_dir=\"/opt/models/clip_vision\")\n    os.rename('/opt/models/clip_vision/models/image_encoder/model.safetensors','/opt/models/clip_vision/CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors')\n#     hf_hub_download(repo_id=\"h94/IP-Adapter\", subfolder=\"sdxl_models/image_encoder\", filename=\"model.safetensors\", local_dir=\"/opt/models/clip_vision\")\n#     os.rename('/opt/models/clip_vision/sdxl_models/image_encoder/model.safetensors','/opt/models/clip_vision/CLIP-ViT-bigG-14-laion2B-39B-b160k.safetensors')\nif kolors==1:\n    # ChatGLMTokenizer._pad() err, wait transformer fixed,check it and remove it\n    # !pip uninstall transformers -y; pip install transformers==4.44.2 \n    !git clone https://github.com/MinusZoneAI/ComfyUI-Kolors-MZ /opt/custom_nodes/ComfyUI-Kolors-MZ\n    !ln -s -f /opt/custom_nodes/ComfyUI-Kolors-MZ  /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Kolors-MZ\n        \n    hf_hub_download(repo_id=\"Kwai-Kolors/Kolors\", subfolder=\"unet\", filename=\"diffusion_pytorch_model.fp16.safetensors\", local_dir=\"/opt/models/\" )\n    os.rename(\"/opt/models/unet/diffusion_pytorch_model.fp16.safetensors\", \"/opt/models/unet/kolors.fp16.safetensors\")\n    !ln -s -f  /opt/models/unet/kolors.fp16.safetensors  /kaggle/working/ComfyUI/models/unet/Kolors.fp16.safetensors\n\n\n    hf_hub_download(repo_id=\"Kijai/ChatGLM3-safetensors\", filename=\"chatglm3-8bit.safetensors\", local_dir=\"/opt/models/LLM\" )\n    !ln -s -f  /opt/models/LLM/chatglm3-8bit.safetensors  /kaggle/working/ComfyUI/models/LLM/chatglm3-8bit.safetensors\n\n    hf_hub_download(repo_id=\"Kwai-Kolors/Kolors-IP-Adapter-Plus\", filename=\"ip_adapter_plus_general.bin\", local_dir=\"/opt/models/ipadapter\")\n    os.rename('/opt/models/ipadapter/ip_adapter_plus_general.bin','/opt/models/ipadapter/Kolors_ip_adapter_plus_general.bin')\n\n    hf_hub_download(repo_id=\"Kwai-Kolors/Kolors-IP-Adapter-FaceID-Plus\", filename=\"ipa-faceid-plus.bin\", local_dir=\"/opt/models/ipadapter\")\n    # from huggingface_hub import snapshot_download\n    # snapshot_download(repo_id=\"DIAMONIK7777/antelopev2\",  local_dir=\"/kaggle/working/ComfyUI/models/inisghtface/models/antelopev2\")\n    # !unzip antelopev2.zip -d . # or unzip dirctly\n    # clip_vision\n    hf_hub_download(repo_id=\"Kwai-Kolors/Kolors-IP-Adapter-Plus\", subfolder=\"image_encoder\", filename=\"pytorch_model.bin\", local_dir=\"/opt/models/clip_vision\")\n    os.rename('/opt/models/clip_vision/image_encoder/pytorch_model.bin','/opt/models/clip_vision/Kolors.bin')\n\n    hf_hub_download(repo_id=\"stabilityai/sdxl-vae\", filename=\"sdxl_vae.safetensors\", local_dir=\"/opt/models/vae\")\n\n    hf_hub_download(repo_id=\"xinsir/controlnet-union-sdxl-1.0\", filename=\"diffusion_pytorch_model_promax.safetensors\", local_dir=\"/opt/models/controlnet\")\n    os.rename('/opt/models/controlnet/diffusion_pytorch_model_promax.safetensors','/opt/models/controlnet/union-promax-sdxl-1.0.safetensors')\n\n# llm\n# minicpm\nif pony==1:\n    # Pony\n    # https://civitai.com/models/669261/wukong-black-myth-wukong-pony-ad\n#     !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/749210?token=$civitai_token   -d /opt/models/loras -o Black-Myth-Wukong.pony.safetensors\n    # https://civitai.com/models/666554/black-myth-wukong\n#     !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/779789?token=$civitai_token  -d /opt/models/loras -o Black-Myth-Wukong.v2.pony.safetensors\n\n    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M  -d /opt/models/checkpoints -o pony.v6.safetensors https://civitai.com/api/download/models/290640?type=Model\n    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M  -d /opt/models/checkpoints -o pony.dpoturbo.v6.safetensors https://civitai.com/api/download/models/298112?type=Model\n\n#     hf_hub_download(repo_id=\"ByteDance/Hyper-SD\", filename=\"Hyper-SDXL-8steps-CFG-lora.safetensors\", local_dir=\"/opt/models/loras\" )\n\n\n# dreamshaper\n# flux\nif flux==1:\n    hf_hub_download(repo_id=\"Kijai/flux-fp8\", filename=\"flux1-dev-fp8.safetensors\", local_dir=\"/opt/models/unet\" )\n    # hf_hub_download(repo_id=\"Kijai/flux-fp8\", filename=\"flux1-schnell-fp8-e4m3fn.safetensors\", local_dir=\"/opt/models/unet\" )\n    # hf_hub_download(repo_id=\"Comfy-Org/flux1-dev\", filename=\" flux1-dev-fp8.safetensors\", local_dir=\"/opt/models/checkpoints\" )\n    hf_hub_download(repo_id=\"black-forest-labs/FLUX.1-schnell\", filename=\"ae.safetensors\", local_dir=\"/opt/models/vae\" )\n    hf_hub_download(repo_id=\"comfyanonymous/flux_text_encoders\", filename=\"t5xxl_fp8_e4m3fn.safetensors\", local_dir=\"/opt/models/clip\" )\n#     hf_hub_download(repo_id=\"comfyanonymous/flux_text_encoders\", filename=\"clip_l.safetensors\", local_dir=\"/opt/models/clip\" )\n    hf_hub_download(repo_id=\"zer0int/CLIP-GmP-ViT-L-14\", filename=\"ViT-L-14-TEXT-detail-improved-hiT-GmP-TE-only-HF.safetensors\", local_dir=\"/opt/models/clip\" )\n\n#     !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/753328?token=$civitai_token  -d /opt/models/loras -o Black-Myth-Wukong.flux.safetensors\n#     hf_hub_download(repo_id=\"ByteDance/Hyper-SD\", filename=\"Hyper-FLUX.1-dev-8steps-lora.safetensors\", local_dir=\"/opt/models/loras\" )\n    hf_hub_download(repo_id=\"ByteDance/Hyper-SD\", filename=\"Hyper-FLUX.1-dev-16steps-lora.safetensors\", local_dir=\"/opt/models/loras\" )\n#     !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/931495?token=$civitai_token   -d /opt/models/lora -o flux1.1Detailerforflux1.0dev.safetensors \n    hf_hub_download(repo_id=\"XLabs-AI/flux-ip-adapter\", filename=\"flux-ip-adapter.safetensors\", local_dir=\"/opt/models/ipadapter\" )\n    hf_hub_download(repo_id=\"openai/clip-vit-large-patch14\", filename=\"model.safetensors\", local_dir=\"/opt/models/clip_vision\" )\n    os.rename('/opt/models/clip_vision/model.safetensors', '/opt/models/clip_vision/clip-vit-large-patch14.safetensors')\n    # controlnet\n    hf_hub_download(repo_id=\"jasperai/Flux.1-dev-Controlnet-Upscaler\", filename=\"diffusion_pytorch_model.safetensors\", local_dir=\"/opt/models/controlnet\" )\n    os.rename('/opt/models/controlnet/diffusion_pytorch_model.safetensors', '/opt/models/controlnet/Flux.1-dev-Controlnet-Upscaler.safetensors')\n    hf_hub_download(repo_id=\"Kijai/flux-fp8\", filename=\"flux_shakker_labs_union_pro-fp8_e4m3fn.safetensors\", local_dir=\"/opt/models/controlnet\" )\n    hf_hub_download(repo_id=\"promeai/FLUX.1-controlnet-lineart-promeai\", filename=\"diffusion_pytorch_model.safetensors.safetensors\", local_dir=\"/opt/models/controlnet\" )\n    os.rename('/opt/models/controlnet/diffusion_pytorch_model.safetensors', '/opt/models/controlnet/FLUX.1-controlnet-lineart-promeai.safetensors')\n\n# for krita\n\nif krita==1:\n    hf_hub_download(repo_id=\"comfyanonymous/ControlNet-v1-1_fp16_safetensors\",filename=\"control_v11p_sd15_inpaint_fp16.safetensors\", local_dir=\"/opt/models/controlnet\")\n    hf_hub_download(repo_id=\"comfyanonymous/ControlNet-v1-1_fp16_safetensors\",filename=\"control_lora_rank128_v11f1e_sd15_tile_fp16.safetensors\", local_dir=\"/opt/models/controlnet\")\n\n    hf_hub_download(repo_id=\"Acly/Omni-SR\",filename=\"OmniSR_X2_DIV2K.safetensors\", local_dir=\"/opt/models/upscale_models\")\n    hf_hub_download(repo_id=\"Acly/Omni-SR\",filename=\"OmniSR_X3_DIV2K.safetensors\", local_dir=\"/opt/models/upscale_models\")\n    hf_hub_download(repo_id=\"Acly/Omni-SR\",filename=\"OmniSR_X4_DIV2K.safetensors\", local_dir=\"/opt/models/upscale_models\")\n    hf_hub_download(repo_id=\"Acly/MAT\",filename=\"MAT_Places512_G_fp16.safetensors\", local_dir=\"/opt/models/upscale_models\")\n\n    hf_hub_download(repo_id=\"h94/IP-Adapter\",subfolder='models/image_encoder',filename=\"model.safetensors\", local_dir=\"/opt/models/clip_vision\")\n    # os.rename('/opt/models/clip_vision/models/image_encoder/model.safetensors','/opt/models/clip_vision/clip-vision_vit-h.safetensors')\n    !ln -s -f  /opt/models/clip_vision/models/image_encoder/model.safetensors /opt/models/clip_vision/clip-vision_vit-h.safetensors\n\n    hf_hub_download(repo_id=\"h94/IP-Adapter\",subfolder='sdxl_models',filename=\"ip-adapter_sdxl_vit-h.safetensors\", local_dir=\"/opt/models/ipadapter\")\n    hf_hub_download(repo_id=\"h94/IP-Adapter\",subfolder='models',filename=\"ip-adapter_sd15.safetensors\", local_dir=\"/opt/models/ipadapter\")\n    # os.rename('/opt/models/ipadapter/models/ip-adapter_sd15.safetensors','/opt/models/ipadapter/ip-adapter_sd15.safetensors')\n    !ln -s -f  /opt/models/ipadapter/models/ip-adapter_sd15.safetensors /opt/models/ipadapter/ip-adapter_sd15.safetensors\n\n    hf_hub_download(repo_id=\"ByteDance/Hyper-SD\",filename=\"Hyper-SD15-8steps-CFG-lora.safetensors\", local_dir=\"/opt/models/loras\")\n    hf_hub_download(repo_id=\"ByteDance/Hyper-SD\",filename=\"Hyper-SD15-8steps-CFG-lora.safetensors\", local_dir=\"/opt/models/loras\")\n    hf_hub_download(repo_id=\"ByteDance/Hyper-SD\",filename=\"Hyper-SD15-2steps-lora.safetensors\", local_dir=\"/opt/models/loras\")\n\n    hf_hub_download(repo_id=\"lllyasviel/fooocus_inpaint\",filename=\"inpaint_v26.fooocus.patch\", local_dir=\"/opt/models/inpaint\")\n    hf_hub_download(repo_id=\"lllyasviel/fooocus_inpaint\",filename=\"fooocus_inpaint_head.pth\", local_dir=\"/opt/models/inpaint\")\n\n    hf_hub_download(repo_id=\"Lykon/DreamShaper\",filename=\"DreamShaper_8_pruned.safetensors\", local_dir=\"/opt/models/checkpoints\")\n    !ln -s -f  /opt/models/DreamShaper_8_pruned.safetensors /kaggle/working/ComfyUI/models/checkpoints/DreamShaper_8_pruned.safetensors\n\n\n    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/351306 -d /opt/models -o dreamshaperxl.safetensors\n    !ln -s -f  /opt/models/dreamshaperxl.safetensors /kaggle/working/ComfyUI/models/checkpoints/dreamshaperxl.turbo.safetensors\n\n    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/128713 -d /opt/models -o DreamShaperV8.safetensors\n    !ln -s -f  /opt/models/DreamShaperV8.safetensors /kaggle/working/ComfyUI/models/checkpoints/DreamShaperV8.safetensors\n\nif controlnext_comfy==1:\n    !git clone https://github.com/kijai/ComfyUI-ControlNeXt-SVD /opt/custom_nodes/ComfyUI-ControlNeXt-SVD\n    !ln -s -f /opt/custom_nodes/ComfyUI-ControlNeXt-SVD  /kaggle/working/ComfyUI/custom_nodes/ComfyUI-ControlNeXt-SVD\n    \n    hf_hub_download(repo_id=\"stabilityai/stable-video-diffusion-img2vid-xt-1-1\",filename=\"svd_xt_1_1.safetensors\", local_dir=\"/opt/models/checkpoints\",token=hf_token)\n    hf_hub_download(repo_id=\"Kijai/ControlNeXt-SVD-V2-Comfy\",filename=\"controlnext-svd_v2-unet-fp16_converted.safetensors\", local_dir=\"/opt/models/unet\" )\n    # https://huggingface.co/wangfuyun/AnimateLCM-SVD-xt/resolve/main/AnimateLCM-SVD-xt-1.1.safetensors\n    snapshot_download(repo_id=\"Kijai/ControlNeXt-SVD-V2-Comfy\",ignore_patterns=[\"controlnext-svd_v2-unet-fp16_converted.safetensors\"], local_dir=\"/opt/models/diffusers/controlnext\" )\n    !ln -s -f  /opt/models/diffusers/controlnext /kaggle/working/ComfyUI/models/diffusers/controlnext\n    \nif mimicmotion==1:\n    !git clone https://github.com/kijai/ComfyUI-MimicMotionWrapper /opt/custom_nodes/ComfyUI-MimicMotionWrapper\n    !ln -s -f /opt/custom_nodes/ComfyUI-MimicMotionWrapper  /kaggle/working/ComfyUI/custom_nodes/ComfyUI-MimicMotionWrapper\n    \n    hf_hub_download(repo_id=\"Kijai/MimicMotion_pruned\",filename=\"MimicMotionMergedUnet_1-1-fp16.safetensors\", local_dir=\"/opt/models/mimicmotion\")\n    hf_hub_download(repo_id=\"Kijai/MimicMotion_pruned\",filename=\"MimicMotionMergedUnet_1-0-fp16.safetensors\", local_dir=\"/opt/models/mimicmotion\")\n    !ln -s -f /opt/models/mimicmotion /kaggle/working/ComfyUI/models/mimicmotion\n    hf_hub_download(repo_id=\"stabilityai/stable-video-diffusion-img2vid-xt-1-1\",filename=\"svd_xt_1_1.safetensors\", local_dir=\"/opt/models/checkpoints\",token=hf_token)\n    snapshot_download(repo_id=\"vdo/stable-video-diffusion-img2vid-xt-1-1\", \n                    allow_patterns=[f\"*.json\", \"*fp16*\"],\n                    local_dir='/opt/models/diffusers/stable-video-diffusion-img2vid-xt-1-1')\n    !ln -s -f /opt/models/diffusers/stable-video-diffusion-img2vid-xt-1-1 /kaggle/working/ComfyUI/models/diffusers/stable-video-diffusion-img2vid-xt-1-1\n    \n# sam2\nif sam2==1:\n    snapshot_download(repo_id=\"Kijai/sam2-safetensors\",  allow_patterns=[\"sam2.1*fp16.safetensors\"], local_dir=\"/opt/models/sam2\" )\n    !ln -s -f /opt/models/sam2 /kaggle/working/ComfyUI/models/sam2\n    snapshot_download(repo_id=\"ShilongLiu/GroundingDINO\",  allow_patterns=[\"*.pth\"], local_dir=\"/opt/models/grounding-dino\" )\n    !ln -s -f /opt/models/grounding-dino /kaggle/working/ComfyUI/models/grounding-dino\n    \nif cogvideo==1:\n    !git clone https://github.com/kijai/ComfyUI-CogVideoXWrapper /opt/custom_nodes/ComfyUI-CogVideoXWrapper \n    !ln -s -f /opt/custom_nodes/ComfyUI-CogVideoXWrapper  /kaggle/working/ComfyUI/custom_nodes/ComfyUI-CogVideoXWrapper\n    \n    hf_hub_download(repo_id=\"comfyanonymous/flux_text_encoders\", filename=\"t5xxl_fp8_e4m3fn.safetensors\", local_dir=\"/opt/models/clip\")\n    hf_hub_download(repo_id=\"Kijai/CogVideoX_GGUF\", filename=\"CogVideoX_5b_fun_1_1_Pose_GGUF_Q4_0.safetensors\", local_dir=\"/opt/models/CogVideo/GGUF\")\n    hf_hub_download(repo_id=\"Kijai/CogVideoX_GGUF\", filename=\"CogVideoX_5b_fun_1_1_GGUF_Q4_0.safetensors\", local_dir=\"/opt/models/CogVideo/GGUF\")\n    hf_hub_download(repo_id=\"Kijai/CogVideoX-Fun-pruned\", filename=\"cogvideox_vae.safetensors\", local_dir=\"/opt/models/CogVideo/VAE\")\n    !ln -s -f /opt/models/CogVideo /kaggle/working/ComfyUI/models/CogVideo\n    \nif RVC==1: \n    !git clone https://github.com/ywaby/Comfy-RVC /opt/custom_nodes/Comfy-RVC\n    cd /opt/custom_nodes/Comfy-RVC\n    !git checkout fixed\n    !ln -s -f /opt/custom_nodes/Comfy-RVC  /kaggle/working/ComfyUI/custom_nodes/Comfy-RVC \n    !apt install -y libportaudio2 portaudio19-dev\n    # wait fir bug fix 32k,json open fail\n    #     download model v2\n    # !git clone https://github.com/AIFSH/ComfyUI-RVC\n\nif GSTTS==1: \n    !git clone https://github.com/AIFSH/GSTTS-ComfyUI /opt/custom_nodes/GSTTS-ComfyUI\n    !ln -s -f /opt/custom_nodes/GSTTS-ComfyUI /kaggle/working/ComfyUI/custom_nodes/GSTTS-ComfyUI\nif LivePortrait==1: \n    !git clone https://github.com/kijai/ComfyUI-LivePortrait /opt/custom_nodes/ComfyUI-LivePortrait\n    !ln -s -f /opt/custom_nodes/ComfyUI-LivePortrait /kaggle/working/ComfyUI/custom_nodes/ComfyUI-LivePortrait\n    !git clone https://github.com/kijai/ComfyUI-LivePortrait /opt/custom_nodes/ComfyUI-LivePortrait\n    !ln -s -f /opt/custom_nodes/ComfyUI-LivePortrait /kaggle/working/ComfyUI/custom_nodes/ComfyUI-LivePortrait    ","metadata":{"execution":{"iopub.status.busy":"2024-10-25T04:45:51.806159Z","iopub.execute_input":"2024-10-25T04:45:51.806515Z","iopub.status.idle":"2024-10-25T04:48:19.016629Z","shell.execute_reply.started":"2024-10-25T04:45:51.806477Z","shell.execute_reply":"2024-10-25T04:48:19.015260Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/working/ComfyUI\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"OmniSR_X2_DIV2K.safetensors:   0%|          | 0.00/1.66M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d00906a68c0443c8eedea1d601b36a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"OmniSR_X3_DIV2K.safetensors:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"842ab3d0e85545a68c735235ffb9c0be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"OmniSR_X4_DIV2K.safetensors:   0%|          | 0.00/1.70M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f2fd975626f4f0cae48f7c42eaa73c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1df804d57797498d9d307d7afd2ac5ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1x-ITF-SkinDiffDetail-Lite-v1.pth:   0%|          | 0.00/20.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76cd30272787409ba781c9fd799630b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1xDeJPG_OmniSR.pth:   0%|          | 0.00/3.26M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b20527057cf94e9aba00b62e4c4c1f3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1xOverExposureCorrection_compact.pth:   0%|          | 0.00/2.40M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a70244aea5c4e79a1db78132fcd9c6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1xUnderExposureCorrection_compact.pth:   0%|          | 0.00/2.40M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe19c91e30ea4985913dec331328ea04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1x_DeBLR.pth:   0%|          | 0.00/66.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82ea49da2f38428e990956f9c5a68d42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"4x-ClearRealityV1.pth:   0%|          | 0.00/9.02M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ec466a494a64d16bf65373e63dc6fa8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"4x-UltraSharp.pth:   0%|          | 0.00/67.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df24dac9067a406f858ed3bae36c3586"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"4xUltrasharp_4xUltrasharpV10.pt:   0%|          | 0.00/67.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89b38df09aed4c1b8ddf297729f5985d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"4x_NMKD-Superscale-SP_178000_G.pth:   0%|          | 0.00/67.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aed61ceca0fd46ffb085b08bdcb916aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"4x_RealisticRescaler_100000_G.pth:   0%|          | 0.00/134M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ab90bfd280a408aa45a01aa8e959acb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)x_UniversalUpscalerV2-Sharp_101000_G.pth:   0%|          | 0.00/67.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e1cab017d0a40aa97bce7cbb167f4cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"8x_NMKD-Superscale_150000_G.pth:   0%|          | 0.00/67.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"290a35d563304935b30b78004836d009"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"RealESRGAN_x2.pth:   0%|          | 0.00/67.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b19c7afdbf6b427782c246984d8431b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"RealESRGAN_x4plus.pth:   0%|          | 0.00/67.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"386b9d59398145eda9aaf3ef840cf65c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"real-world_ccsr.ckpt:   0%|          | 0.00/7.29G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f38d878b8f8e4c76bbc7c393c409eee4"}},"metadata":{}},{"name":"stdout","text":"Cloning into '/opt/custom_nodes/ComfyUI-Kolors-MZ'...\nremote: Enumerating objects: 396, done.\u001b[K\nremote: Counting objects: 100% (122/122), done.\u001b[K\nremote: Compressing objects: 100% (89/89), done.\u001b[K\nremote: Total 396 (delta 60), reused 56 (delta 33), pack-reused 274 (from 1)\u001b[K\nReceiving objects: 100% (396/396), 10.24 MiB | 18.08 MiB/s, done.\nResolving deltas: 100% (224/224), done.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"diffusion_pytorch_model.fp16.safetensors:   0%|          | 0.00/5.16G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb78c16595a24b18a78e917d3a2eba3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"chatglm3-8bit.safetensors:   0%|          | 0.00/6.78G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"209b3b89c57c4d7596b87e85dff8a59d"}},"metadata":{}},{"name":"stdout","text":"ln: failed to create symbolic link '/kaggle/working/ComfyUI/models/LLM/chatglm3-8bit.safetensors': No such file or directory\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"ip_adapter_plus_general.bin:   0%|          | 0.00/1.01G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b61dee7a1042454f928dbcbd2f67b429"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"ipa-faceid-plus.bin:   0%|          | 0.00/2.39G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1db93b8d3bee43499337b8a9b4c75376"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.71G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66893cd3908242c0910c5af2a7697613"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sdxl_vae.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"332bd9499d2049899462e82f9fa28888"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)ffusion_pytorch_model_promax.safetensors:   0%|          | 0.00/2.51G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a243fce2abb40eab0d0571d0a77cc08"}},"metadata":{}}]},{"cell_type":"code","source":"\n%cd /kaggle/working/ComfyUI\n# branch\n!git checkout .\n## update\n!git pull\n\n!pip install -r requirements.txt \n\n            ","metadata":{"execution":{"iopub.status.busy":"2024-10-25T04:48:19.018396Z","iopub.execute_input":"2024-10-25T04:48:19.018831Z","iopub.status.idle":"2024-10-25T04:48:51.375651Z","shell.execute_reply.started":"2024-10-25T04:48:19.018780Z","shell.execute_reply":"2024-10-25T04:48:51.374677Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"/kaggle/working/ComfyUI\nUpdated 347 paths from the index\nAlready up to date.\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.4.0)\nCollecting torchsde (from -r requirements.txt (line 2))\n  Downloading torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (0.19.0)\nRequirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (2.4.0)\nCollecting einops (from -r requirements.txt (line 5))\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: transformers>=4.28.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (4.45.1)\nRequirement already satisfied: tokenizers>=0.13.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (0.20.0)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (0.2.0)\nRequirement already satisfied: safetensors>=0.4.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (0.4.5)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (3.9.5)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (6.0.2)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (10.3.0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (1.14.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (5.9.3)\nRequirement already satisfied: kornia>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 18)) (0.7.3)\nCollecting spandrel (from -r requirements.txt (line 19))\n  Downloading spandrel-0.4.0-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: soundfile in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 20)) (0.12.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (2024.6.1)\nRequirement already satisfied: numpy>=1.19 in /opt/conda/lib/python3.10/site-packages (from torchsde->-r requirements.txt (line 2)) (1.26.4)\nCollecting trampoline>=0.1.2 (from torchsde->-r requirements.txt (line 2))\n  Downloading trampoline-0.1.2-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.28.1->-r requirements.txt (line 6)) (0.25.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.28.1->-r requirements.txt (line 6)) (21.3)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.28.1->-r requirements.txt (line 6)) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.28.1->-r requirements.txt (line 6)) (2.32.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->-r requirements.txt (line 10)) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->-r requirements.txt (line 10)) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->-r requirements.txt (line 10)) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->-r requirements.txt (line 10)) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->-r requirements.txt (line 10)) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->-r requirements.txt (line 10)) (4.0.3)\nRequirement already satisfied: kornia-rs>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from kornia>=0.7.1->-r requirements.txt (line 18)) (0.1.5)\nRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile->-r requirements.txt (line 20)) (1.16.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile->-r requirements.txt (line 20)) (2.22)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.28.1->-r requirements.txt (line 6)) (3.1.2)\nRequirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp->-r requirements.txt (line 10)) (3.7)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->-r requirements.txt (line 1)) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 6)) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 6)) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 6)) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->-r requirements.txt (line 1)) (1.3.0)\nDownloading torchsde-0.2.6-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m12.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading spandrel-0.4.0-py3-none-any.whl (297 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.5/297.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\nInstalling collected packages: trampoline, einops, torchsde, spandrel\nSuccessfully installed einops-0.8.0 spandrel-0.4.0 torchsde-0.2.6 trampoline-0.1.2\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd /kaggle/working/ComfyUI/custom_nodes\nimport os, subprocess\ncustom_nodes = [d for d in os.listdir(\".\") if os.path.isdir(d)]\nfor custom_node in custom_nodes:\n    if os.path.exists(os.path.join(custom_node, '.git')):\n        print(f'update {custom_node}')\n        %cd $custom_node\n#         !git checkout . \n#         subprocess.run(['git', 'pull'])\n        if os.path.exists( 'requirements.txt'):\n            subprocess.run(['pip', 'install',   '-q','-r','requirements.txt'])\n        %cd /kaggle/working/ComfyUI/custom_nodes","metadata":{"execution":{"iopub.status.busy":"2024-10-25T04:48:51.377146Z","iopub.execute_input":"2024-10-25T04:48:51.377526Z","iopub.status.idle":"2024-10-25T04:54:31.888298Z","shell.execute_reply.started":"2024-10-25T04:48:51.377488Z","shell.execute_reply":"2024-10-25T04:54:31.887334Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"/kaggle/working/ComfyUI/custom_nodes\nupdate ComfyUI-Easy-Use\n/kaggle/working/ComfyUI/custom_nodes/ComfyUI-Easy-Use\n/kaggle/working/ComfyUI/custom_nodes\nupdate ComfyUI-KJNodes\n/kaggle/working/ComfyUI/custom_nodes/ComfyUI-KJNodes\n/kaggle/working/ComfyUI/custom_nodes\nupdate ComfyUI-AdvancedLivePortrait\n/kaggle/working/ComfyUI/custom_nodes/ComfyUI-AdvancedLivePortrait\n/kaggle/working/ComfyUI/custom_nodes\nupdate comfyui_controlnet_aux\n/kaggle/working/ComfyUI/custom_nodes/comfyui_controlnet_aux\n","output_type":"stream"},{"name":"stderr","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\napache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.0.0 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires protobuf<4,>3.12.2, but you have protobuf 4.25.5 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\ngoogle-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires protobuf<4.0.0dev,>=3.12.0, but you have protobuf 4.25.5 which is incompatible.\ngoogle-cloud-bigtable 1.7.3 requires protobuf<4.0.0dev, but you have protobuf 4.25.5 which is incompatible.\ngoogle-cloud-vision 2.8.0 requires protobuf<4.0.0dev,>=3.19.0, but you have protobuf 4.25.5 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.5 which is incompatible.\nkfp-pipeline-spec 0.2.2 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.5 which is incompatible.\ntensorflow-metadata 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.5 which is incompatible.\ntensorflow-transform 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.5 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"},{"name":"stdout","text":"/kaggle/working/ComfyUI/custom_nodes\nupdate comfyui-reactor-node\n/kaggle/working/ComfyUI/custom_nodes/comfyui-reactor-node\n/kaggle/working/ComfyUI/custom_nodes\nupdate ComfyUI-LivePortraitKJ\n/kaggle/working/ComfyUI/custom_nodes/ComfyUI-LivePortraitKJ\n/kaggle/working/ComfyUI/custom_nodes\nupdate ComfyUI-Inspyrenet-Rembg\n/kaggle/working/ComfyUI/custom_nodes/ComfyUI-Inspyrenet-Rembg\n","output_type":"stream"},{"name":"stderr","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.8.3 requires cubinlinker, which is not installed.\ncudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.8.3 requires ptxcompiler, which is not installed.\ncuml 24.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.8.3 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\ndistributed 2024.7.1 requires dask==2024.7.1, but you have dask 2024.9.1 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires protobuf<4.0.0dev,>=3.12.0, but you have protobuf 4.25.3 which is incompatible.\njupyterlab 4.2.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nrapids-dask-dependency 24.8.0a0 requires dask==2024.7.1, but you have dask 2024.9.1 which is incompatible.\nydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"},{"name":"stdout","text":"/kaggle/working/ComfyUI/custom_nodes\nupdate ComfyUI-VideoHelperSuite\n/kaggle/working/ComfyUI/custom_nodes/ComfyUI-VideoHelperSuite\n/kaggle/working/ComfyUI/custom_nodes\nupdate ComfyUI-Manager\n/kaggle/working/ComfyUI/custom_nodes/ComfyUI-Manager\n/kaggle/working/ComfyUI/custom_nodes\nupdate ComfyUI-Frame-Interpolation\n/kaggle/working/ComfyUI/custom_nodes/ComfyUI-Frame-Interpolation\n/kaggle/working/ComfyUI/custom_nodes\nupdate ComfyUI-Inspire-Pack\n/kaggle/working/ComfyUI/custom_nodes/ComfyUI-Inspire-Pack\n/kaggle/working/ComfyUI/custom_nodes\nupdate Comfyui_CXH_joy_caption\n/kaggle/working/ComfyUI/custom_nodes/Comfyui_CXH_joy_caption\n","output_type":"stream"},{"name":"stderr","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\naiobotocore 2.15.1 requires botocore<1.35.24,>=1.35.16, but you have botocore 1.34.162 which is incompatible.\nydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"},{"name":"stdout","text":"/kaggle/working/ComfyUI/custom_nodes\nupdate rgthree-comfy\n/kaggle/working/ComfyUI/custom_nodes/rgthree-comfy\n/kaggle/working/ComfyUI/custom_nodes\nupdate ComfyUI_IPAdapter_plus\n/kaggle/working/ComfyUI/custom_nodes/ComfyUI_IPAdapter_plus\n/kaggle/working/ComfyUI/custom_nodes\nupdate ComfyUI-Kolors-MZ\n/opt/custom_nodes/ComfyUI-Kolors-MZ\n/kaggle/working/ComfyUI/custom_nodes\nupdate ComfyUI-fastblend\n/kaggle/working/ComfyUI/custom_nodes/ComfyUI-fastblend\n/kaggle/working/ComfyUI/custom_nodes\nupdate ComfyUI-AnimateDiff-Evolved\n/kaggle/working/ComfyUI/custom_nodes/ComfyUI-AnimateDiff-Evolved\n/kaggle/working/ComfyUI/custom_nodes\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# webui","metadata":{}},{"cell_type":"markdown","source":"## fixed","metadata":{}},{"cell_type":"code","source":"# !pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu124\n!rm -rf /opt/conda/lib/python3.10/site-packages/numpy-1.26.4.dist-info\n!pip install  numpy==1.25.0 numba==0.59.1 \n!pip install insightface\n!pip install face-alignment\n\n!pip install onnxruntime-gpu --extra-index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/\n!pip install cpm_kernels","metadata":{"execution":{"iopub.status.busy":"2024-10-25T04:54:31.889699Z","iopub.execute_input":"2024-10-25T04:54:31.890003Z","iopub.status.idle":"2024-10-25T04:55:55.089594Z","shell.execute_reply.started":"2024-10-25T04:54:31.889971Z","shell.execute_reply":"2024-10-25T04:55:55.088375Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Collecting numpy==1.25.0\n  Downloading numpy-1.25.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\nCollecting numba==0.59.1\n  Downloading numba-0.59.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\nCollecting llvmlite<0.43,>=0.42.0dev0 (from numba==0.59.1)\n  Downloading llvmlite-0.42.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\nDownloading numpy-1.25.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading numba-0.59.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading llvmlite-0.42.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: numpy, llvmlite, numba\n  Attempting uninstall: llvmlite\n    Found existing installation: llvmlite 0.43.0\n    Uninstalling llvmlite-0.43.0:\n      Successfully uninstalled llvmlite-0.43.0\n  Attempting uninstall: numba\n    Found existing installation: numba 0.60.0\n    Uninstalling numba-0.60.0:\n      Successfully uninstalled numba-0.60.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.8.3 requires cubinlinker, which is not installed.\ncudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.8.3 requires ptxcompiler, which is not installed.\ncuml 24.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\nucxx 0.39.1 requires libucx>=1.15.0, which is not installed.\napache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.0.0 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.25.0 which is incompatible.\napache-beam 2.46.0 requires protobuf<4,>3.12.2, but you have protobuf 4.25.3 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\ncesium 0.12.3 requires numpy<3.0,>=2.0, but you have numpy 1.25.0 which is incompatible.\ncudf 24.8.3 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\ngensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.14.1 which is incompatible.\nibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 16.1.0 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nrmm 24.8.2 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\ntensorflow-transform 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.3 which is incompatible.\nydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed llvmlite-0.42.0 numba-0.59.1 numpy-1.25.0\nRequirement already satisfied: insightface in /opt/conda/lib/python3.10/site-packages (0.7.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from insightface) (1.25.0)\nRequirement already satisfied: onnx in /opt/conda/lib/python3.10/site-packages (from insightface) (1.17.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from insightface) (4.66.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from insightface) (2.32.3)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from insightface) (3.7.5)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from insightface) (10.1.0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from insightface) (1.14.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from insightface) (1.2.2)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from insightface) (0.23.2)\nRequirement already satisfied: easydict in /opt/conda/lib/python3.10/site-packages (from insightface) (1.13)\nRequirement already satisfied: cython in /opt/conda/lib/python3.10/site-packages (from insightface) (3.0.10)\nRequirement already satisfied: albumentations in /opt/conda/lib/python3.10/site-packages (from insightface) (1.4.15)\nRequirement already satisfied: prettytable in /opt/conda/lib/python3.10/site-packages (from insightface) (3.10.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from albumentations->insightface) (6.0.2)\nRequirement already satisfied: pydantic>=2.7.0 in /opt/conda/lib/python3.10/site-packages (from albumentations->insightface) (2.9.2)\nRequirement already satisfied: albucore>=0.0.15 in /opt/conda/lib/python3.10/site-packages (from albumentations->insightface) (0.0.16)\nRequirement already satisfied: eval-type-backport in /opt/conda/lib/python3.10/site-packages (from albumentations->insightface) (0.2.0)\nRequirement already satisfied: opencv-python-headless>=4.9.0.80 in /opt/conda/lib/python3.10/site-packages (from albumentations->insightface) (4.10.0.84)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->insightface) (3.3)\nRequirement already satisfied: imageio>=2.33 in /opt/conda/lib/python3.10/site-packages (from scikit-image->insightface) (2.34.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->insightface) (2024.5.22)\nRequirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image->insightface) (23.2)\nRequirement already satisfied: lazy-loader>=0.4 in /opt/conda/lib/python3.10/site-packages (from scikit-image->insightface) (0.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->insightface) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->insightface) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->insightface) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->insightface) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->insightface) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->insightface) (2.9.0.post0)\nRequirement already satisfied: protobuf>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from onnx->insightface) (4.25.3)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prettytable->insightface) (0.2.13)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->insightface) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->insightface) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->insightface) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->insightface) (2024.8.30)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->insightface) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->insightface) (3.5.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations->insightface) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations->insightface) (2.23.4)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations->insightface) (4.12.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->insightface) (1.16.0)\nCollecting face-alignment\n  Downloading face_alignment-1.4.1-py2.py3-none-any.whl.metadata (7.4 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from face-alignment) (2.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from face-alignment) (1.25.0)\nRequirement already satisfied: scipy>=0.17 in /opt/conda/lib/python3.10/site-packages (from face-alignment) (1.14.1)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from face-alignment) (0.23.2)\nRequirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (from face-alignment) (4.10.0.84)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from face-alignment) (4.66.4)\nRequirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from face-alignment) (0.59.1)\nRequirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->face-alignment) (0.42.0)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->face-alignment) (3.3)\nRequirement already satisfied: pillow>=9.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->face-alignment) (10.1.0)\nRequirement already satisfied: imageio>=2.33 in /opt/conda/lib/python3.10/site-packages (from scikit-image->face-alignment) (2.34.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->face-alignment) (2024.5.22)\nRequirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image->face-alignment) (23.2)\nRequirement already satisfied: lazy-loader>=0.4 in /opt/conda/lib/python3.10/site-packages (from scikit-image->face-alignment) (0.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->face-alignment) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->face-alignment) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->face-alignment) (1.13.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->face-alignment) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->face-alignment) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->face-alignment) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->face-alignment) (1.3.0)\nDownloading face_alignment-1.4.1-py2.py3-none-any.whl (30 kB)\nInstalling collected packages: face-alignment\nSuccessfully installed face-alignment-1.4.1\nLooking in indexes: https://pypi.org/simple, https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/\nRequirement already satisfied: onnxruntime-gpu in /opt/conda/lib/python3.10/site-packages (1.19.2)\nRequirement already satisfied: coloredlogs in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (15.0.1)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (24.3.25)\nRequirement already satisfied: numpy>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (1.25.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (23.2)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (4.25.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (1.13.3)\nRequirement already satisfied: humanfriendly>=9.1 in /opt/conda/lib/python3.10/site-packages (from coloredlogs->onnxruntime-gpu) (10.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime-gpu) (1.3.0)\nCollecting cpm_kernels\n  Downloading cpm_kernels-1.0.11-py3-none-any.whl.metadata (1.2 kB)\nDownloading cpm_kernels-1.0.11-py3-none-any.whl (416 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.6/416.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: cpm_kernels\nSuccessfully installed cpm_kernels-1.0.11\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## info for debug","metadata":{}},{"cell_type":"code","source":"# !pip list |grep numba\n# !pip list |grep numpy\n# !pip list |grep transformers\n# !pip list |grep torch\n# !pip list |grep cupy\n","metadata":{"execution":{"iopub.status.busy":"2024-10-25T04:55:55.091075Z","iopub.execute_input":"2024-10-25T04:55:55.091404Z","iopub.status.idle":"2024-10-25T04:55:55.097621Z","shell.execute_reply.started":"2024-10-25T04:55:55.091370Z","shell.execute_reply":"2024-10-25T04:55:55.096838Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# start webui \n%cd /kaggle/working/ComfyUI\n\nif localproxy==\"localtunnel\":\n    import subprocess\n    import urllib.request\n    print(\"The password/enpoint ip for localtunnel is:\", urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))\n    subprocess.Popen([\"lt\", \"--port\", \"8188\"])\n    !python main.py --dont-print-server --force-fp16 --use-pytorch-cross-attention\nelse:\n    import os\n    from pyngrok import ngrok\n    from IPython.display import clear_output, Javascript\n    ngrok.kill()\n    ngrok.set_auth_token(ngrok_token)\n    p_tunnel = ngrok.connect(8188)\n    clear_output()\n    print(\"Applio Url:\", p_tunnel.public_url)\n    print(\"Save the link for later, this will take a while...\")\n    !python main.py --dont-print-server --force-fp16 --use-pytorch-cross-attention","metadata":{"execution":{"iopub.status.busy":"2024-10-25T04:55:55.098686Z","iopub.execute_input":"2024-10-25T04:55:55.098945Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"/kaggle/working/ComfyUI\nThe password/enpoint ip for localtunnel is: 34.80.67.200\n[START] Security scan\nyour url is: https://pink-walls-visit.loca.lt\n[DONE] Security scan\n## ComfyUI-Manager: installing dependencies done.\n** ComfyUI startup time: 2024-10-25 04:55:58.559831\n** Platform: Linux\n** Python version: 3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:45:18) [GCC 12.3.0]\n** Python executable: /opt/conda/bin/python\n** ComfyUI Path: /kaggle/working/ComfyUI\n** Log path: /kaggle/working/ComfyUI/comfyui.log\n\nPrestartup times for custom nodes:\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Easy-Use\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/rgthree-comfy\n   2.4 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Manager\n\nTotal VRAM 16269 MB, total RAM 32110 MB\npytorch version: 2.4.0\nForcing FP16.\nSet vram state to: NORMAL_VRAM\nDevice: cuda:0 Tesla P100-PCIE-16GB : cudaMallocAsync\nUsing pytorch cross attention\nThe cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n0it [00:00, ?it/s]\n[Prompt Server] web root: /kaggle/working/ComfyUI/web\nAdding extra search path checkpoints /opt/models/checkpoints/\nAdding extra search path clip /opt/models/clip/\nAdding extra search path clip_vision /opt/models/clip_vision/\nAdding extra search path configs /opt/models/configs/\nAdding extra search path controlnet /opt/models/controlnet/\nAdding extra search path embeddings /opt/models/embeddings/\nAdding extra search path loras /opt/models/loras/\nAdding extra search path upscale_models /opt/models/upscale_models/\nAdding extra search path vae /opt/models/vae/\nAdding extra search path unet /opt/models/unet/\nAdding extra search path LLM /opt/models/LLM/\nAdding extra search path sam2 /opt/models/sam2/\nAdding extra search path ipadapter /opt/models/ipadapter/\nAdding extra search path animatediff_models /opt/models/animatediff_models/\nAdding extra search path animatediff_motion_lora /opt/models/animatediff_motion_lora/\n/opt/conda/lib/python3.10/site-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\nNumExpr defaulting to 4 threads.\n\u001b[34m[ComfyUI-Easy-Use] server: \u001b[0mv1.2.3 \u001b[92mLoaded\u001b[0m\n\u001b[34m[ComfyUI-Easy-Use] web root: \u001b[0m/kaggle/working/ComfyUI/custom_nodes/ComfyUI-Easy-Use/web_version/v2 \u001b[92mLoaded\u001b[0m\nTotal VRAM 16269 MB, total RAM 32110 MB\npytorch version: 2.4.0\nForcing FP16.\nSet vram state to: NORMAL_VRAM\nDevice: cuda:0 Tesla P100-PCIE-16GB : cudaMallocAsync\nCreating new Ultralytics Settings v0.0.6 file ✅ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using ckpts path: /kaggle/working/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts\u001b[0m\n\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using symlinks: False\u001b[0m\n\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using ort providers: ['CUDAExecutionProvider', 'DirectMLExecutionProvider', 'OpenVINOExecutionProvider', 'ROCMExecutionProvider', 'CPUExecutionProvider', 'CoreMLExecutionProvider']\u001b[0m\nDWPose: Onnxruntime with acceleration providers detected\n/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.20 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n\u001b[0;33m[ReActor]\u001b[0m - \u001b[38;5;173mSTATUS\u001b[0m - \u001b[0;32mRunning v0.5.1-a7 in ComfyUI\u001b[0m\nTorch version: 2.4.0\n### Loading: ComfyUI-Manager (V2.50.3)\n### ComfyUI Revision: 2785 [52810907] | Released on '2024-10-24'\n### Loading: ComfyUI-Inspire-Pack (V1.2.2)\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/github-stats.json\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json\n\n\u001b[92m[rgthree-comfy] Loaded 42 fantastic nodes. 🎉\u001b[00m\n\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.jsontorch version----------------------\n 2.4.0\n[AnimateDiffEvo] - \u001b[0;31mERROR\u001b[0m - No motion models found. Please download one and place in: ['/opt/models/animatediff_models/', '/kaggle/working/ComfyUI/custom_nodes/ComfyUI-AnimateDiff-Evolved/models', '/kaggle/working/ComfyUI/models/animatediff_models']\n\nImport times for custom nodes:\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/websocket_image_save.py\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/Comfyui_CXH_joy_caption\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Frame-Interpolation\n   0.1 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-LivePortraitKJ\n   0.1 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI_IPAdapter_plus\n   0.1 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Kolors-MZ\n   0.1 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-KJNodes\n   0.1 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Manager\n   0.1 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-AnimateDiff-Evolved\n   0.2 seconds: /kaggle/working/ComfyUI/custom_nodes/rgthree-comfy\n   0.2 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Inspire-Pack\n   0.2 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-VideoHelperSuite\n   0.2 seconds: /kaggle/working/ComfyUI/custom_nodes/comfyui_controlnet_aux\n   0.6 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-AdvancedLivePortrait\n   0.9 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-fastblend\n   1.8 seconds: /kaggle/working/ComfyUI/custom_nodes/comfyui-reactor-node\n   2.0 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Inspyrenet-Rembg\n  13.4 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Easy-Use\n\nStarting server\n\nTo see the GUI go to: http://127.0.0.1:8188\nFETCH DATA from: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Manager/extension-node-map.json [DONE]\ngot prompt\nUsing pytorch attention in VAE\nUsing pytorch attention in VAE\ntorch version: 2.4.0\n!!! Exception during processing !!! 'select_styles'\nTraceback (most recent call last):\n  File \"/kaggle/working/ComfyUI/execution.py\", line 323, in execute\n    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 198, in get_output_data\n    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 169, in _map_node_over_list\n    process_inputs(input_dict, i)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 158, in process_inputs\n    results.append(getattr(obj, func)(**inputs))\n  File \"/kaggle/working/ComfyUI/custom_nodes/ComfyUI-Easy-Use/py/easyNodes.py\", line 179, in run\n    if prompt[my_unique_id][\"inputs\"]['select_styles']:\nKeyError: 'select_styles'\n\nPrompt executed in 11.91 seconds\nWarning torch.load doesn't support weights_only on this pytorch version, loading unsafely.\nWARNING: the load_unet_state_dict function has been deprecated and will be removed please switch to: load_diffusion_model_state_dict\ninput_blocks.1.0.skip_connection.weight down_blocks.0.resnets.0.conv_shortcut.weight\ninput_blocks.1.0.skip_connection.bias down_blocks.0.resnets.0.conv_shortcut.bias\ninput_blocks.2.0.skip_connection.weight down_blocks.0.resnets.1.conv_shortcut.weight\ninput_blocks.2.0.skip_connection.bias down_blocks.0.resnets.1.conv_shortcut.bias\ninput_blocks.5.0.skip_connection.weight down_blocks.1.resnets.1.conv_shortcut.weight\ninput_blocks.5.0.skip_connection.bias down_blocks.1.resnets.1.conv_shortcut.bias\ninput_blocks.8.0.skip_connection.weight down_blocks.2.resnets.1.conv_shortcut.weight\ninput_blocks.8.0.skip_connection.bias down_blocks.2.resnets.1.conv_shortcut.bias\ninput_blocks.9.0.op.weight down_blocks.2.downsamplers.0.conv.weight\ninput_blocks.9.0.op.bias down_blocks.2.downsamplers.0.conv.bias\nmiddle_block.0.skip_connection.weight mid_block.resnets.0.conv_shortcut.weight\nmiddle_block.0.skip_connection.bias mid_block.resnets.0.conv_shortcut.bias\nmiddle_block.2.skip_connection.weight mid_block.resnets.1.conv_shortcut.weight\nmiddle_block.2.skip_connection.bias mid_block.resnets.1.conv_shortcut.bias\noutput_blocks.8.1.conv.weight up_blocks.2.upsamplers.0.conv.weight\noutput_blocks.8.1.conv.bias up_blocks.2.upsamplers.0.conv.bias\nlabel_emb.0.2.weight class_embedding.linear_2.weight\nlabel_emb.0.0.weight class_embedding.linear_1.weight\nlabel_emb.0.0.bias class_embedding.linear_1.bias\nlabel_emb.0.2.bias class_embedding.linear_2.bias\nmodel weight dtype torch.float16, manual cast: None\nmodel_type EPS\n\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\nRequested to load CLIPVisionModelProjection\nLoading 1 new model\nloaded completely 0.0 581.900390625 True\nRequested to load SDXL\nLoading 1 new model\nloaded completely 0.0 4935.9311599731445 True\n100%|███████████████████████████████████████████| 30/30 [01:01<00:00,  2.06s/it]\nRequested to load AutoencoderKL\nLoading 1 new model\nloaded completely 0.0 319.11416244506836 True\nPrompt executed in 189.80 seconds\ngot prompt\nRequested to load SDXL\nLoading 1 new model\ngot prompt\nWarning torch.load doesn't support weights_only on this pytorch version, loading unsafely.\n\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\nRequested to load CLIPVisionModelProjection\nLoading 1 new model\nloaded completely 0.0 581.900390625 True\ngot prompt\n\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\nRequested to load SDXL\nLoading 1 new model\nloaded completely 9.5367431640625e+25 4935.9311599731445 True\n100%|███████████████████████████████████████████| 30/30 [01:00<00:00,  2.02s/it]\nloaded partially 188.05077743530273 188.05015563964844 0\nPrompt executed in 87.14 seconds\n\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\nRequested to load CLIPVisionModelProjection\nLoading 1 new model\nloaded completely 0.0 581.900390625 True\nRequested to load SDXL\nLoading 1 new model\nloaded partially 4823.172924804688 4823.1717529296875 0\n100%|███████████████████████████████████████████| 30/30 [01:01<00:00,  2.05s/it]\nRequested to load AutoencoderKL\nLoading 1 new model\nloaded completely 0.0 319.11416244506836 True\nPrompt executed in 70.36 seconds\ngot prompt\n\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\nRequested to load CLIPVisionModelProjection\nLoading 1 new model\nloaded completely 0.0 581.900390625 True\n\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\nRequested to load SDXL\nLoading 1 new model\nloaded partially 4823.172924804688 4823.1717529296875 0\n100%|███████████████████████████████████████████| 30/30 [01:01<00:00,  2.05s/it]\nRequested to load AutoencoderKL\nLoading 1 new model\nloaded completely 0.0 319.11416244506836 True\nPrompt executed in 82.40 seconds\ngot prompt\n\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\nRequested to load CLIPVisionModelProjection\nLoading 1 new model\nloaded completely 0.0 581.900390625 True\nRequested to load SDXL\nLoading 1 new model\nloaded partially 4823.172924804688 4823.1717529296875 0\n100%|███████████████████████████████████████████| 30/30 [01:01<00:00,  2.04s/it]\nRequested to load AutoencoderKL\nLoading 1 new model\nloaded completely 0.0 319.11416244506836 True\nPrompt executed in 70.34 seconds\ngot prompt\nFailed to validate prompt for output 149:\n* (prompt):\n  - Required input is missing: images\n* PreviewImage 149:\n  - Required input is missing: images\nOutput will be ignored\n\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\nRequested to load CLIPVisionModelProjection\nLoading 1 new model\nloaded completely 0.0 581.900390625 True\nRequested to load SDXL\nLoading 1 new model\nloaded partially 4823.172924804688 4823.1717529296875 0\n100%|███████████████████████████████████████████| 30/30 [01:01<00:00,  2.04s/it]\nRequested to load AutoencoderKL\nLoading 1 new model\nloaded completely 0.0 319.11416244506836 True\nPrompt executed in 70.01 seconds\ngot prompt\n\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\nRequested to load CLIPVisionModelProjection\nLoading 1 new model\nloaded completely 0.0 581.900390625 True\nRequested to load SDXL\nLoading 1 new model\nloaded completely 0.0 4935.9311599731445 True\n100%|███████████████████████████████████████████| 30/30 [00:59<00:00,  2.00s/it]\nPrompt executed in 67.33 seconds\ngot prompt\nRequested to load SDXL\nLoading 1 new model\nloaded completely 0.0 4935.9311599731445 True\n100%|███████████████████████████████████████████| 30/30 [01:00<00:00,  2.00s/it]\nRequested to load AutoencoderKL\nLoading 1 new model\nloaded completely 0.0 319.11416244506836 True\nPrompt executed in 73.11 seconds\ngot prompt\n\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\nRequested to load CLIPVisionModelProjection\nLoading 1 new model\nloaded completely 0.0 581.900390625 True\n\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\nRequested to load SDXL\nLoading 1 new model\nloaded completely 9.5367431640625e+25 4935.9311599731445 True\n100%|███████████████████████████████████████████| 30/30 [01:00<00:00,  2.03s/it]\nUnloading models for lowram load.\n0 models unloaded.\nPrompt executed in 79.60 seconds\ngot prompt\nRequested to load SDXL\nLoading 1 new model\nloaded completely 0.0 4935.9311599731445 True\n100%|███████████████████████████████████████████| 30/30 [01:00<00:00,  2.03s/it]\nloaded partially 188.05077743530273 188.05015563964844 0\nPrompt executed in 65.01 seconds\ngot prompt\n\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\nRequested to load CLIPVisionModelProjection\nLoading 1 new model\nloaded completely 0.0 581.900390625 True\nRequested to load SDXL\nLoading 1 new model\nloaded partially 4823.172924804688 4823.1717529296875 0\n100%|███████████████████████████████████████████| 30/30 [01:01<00:00,  2.04s/it]\nRequested to load AutoencoderKL\nLoading 1 new model\nloaded completely 0.0 319.11416244506836 True\nPrompt executed in 70.20 seconds\ngot prompt\nRequested to load SDXL\nLoading 1 new model\nloaded completely 0.0 4935.9311599731445 True\n 13%|█████▊                                      | 4/30 [00:08<00:52,  2.02s/it]got prompt\n100%|███████████████████████████████████████████| 30/30 [01:00<00:00,  2.02s/it]\nRequested to load AutoencoderKL\nLoading 1 new model\nloaded completely 0.0 319.11416244506836 True\nPrompt executed in 73.46 seconds\n\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\nRequested to load CLIPVisionModelProjection\nLoading 1 new model\nloaded completely 0.0 581.900390625 True\nRequested to load SDXL\nLoading 1 new model\nloaded partially 4823.172924804688 4823.1717529296875 0\n100%|███████████████████████████████████████████| 30/30 [01:01<00:00,  2.05s/it]\nRequested to load AutoencoderKL\nLoading 1 new model\nloaded completely 0.0 319.11416244506836 True\nPrompt executed in 70.11 seconds\ngot prompt\nRequested to load SDXL\nLoading 1 new model\nloaded completely 0.0 4935.9311599731445 True\n100%|███████████████████████████████████████████| 30/30 [01:00<00:00,  2.03s/it]\nRequested to load AutoencoderKL\nLoading 1 new model\nloaded completely 0.0 319.11416244506836 True\nPrompt executed in 73.16 seconds\ngot prompt\n\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\nRequested to load CLIPVisionModelProjection\nLoading 1 new model\nloaded completely 0.0 581.900390625 True\n\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\nRequested to load SDXL\nLoading 1 new model\nloaded partially 4823.172924804688 4823.1717529296875 0\n100%|███████████████████████████████████████████| 30/30 [01:01<00:00,  2.04s/it]\nRequested to load AutoencoderKL\nLoading 1 new model\nloaded completely 0.0 319.11416244506836 True\nPrompt executed in 81.45 seconds\ngot prompt\nRequested to load SDXL\nLoading 1 new model\nloaded completely 0.0 4935.9311599731445 True\n100%|███████████████████████████████████████████| 30/30 [01:00<00:00,  2.01s/it]\nRequested to load AutoencoderKL\nLoading 1 new model\nloaded completely 0.0 319.11416244506836 True\nPrompt executed in 71.92 seconds\ngot prompt\nPrompt executed in 0.01 seconds\ngot prompt\n\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\nRequested to load CLIPVisionModelProjection\nLoading 1 new model\nloaded completely 0.0 581.900390625 True\nRequested to load SDXL\nLoading 1 new model\nloaded completely 9.5367431640625e+25 4935.9311599731445 True\n100%|███████████████████████████████████████████| 30/30 [01:00<00:00,  2.01s/it]\nPrompt executed in 74.48 seconds\ngot prompt\nloaded completely 11019.404465484618 4935.9311599731445 True\n100%|███████████████████████████████████████████| 30/30 [01:00<00:00,  2.01s/it]\nPrompt executed in 62.69 seconds\ngot prompt\n\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\nRequested to load CLIPVisionModelProjection\nLoading 1 new model\nloaded completely 0.0 581.900390625 True\nRequested to load SDXL\nLoading 1 new model\nloaded completely 9.5367431640625e+25 4935.9311599731445 True\n100%|███████████████████████████████████████████| 30/30 [01:00<00:00,  2.01s/it]\nPrompt executed in 74.46 seconds\ngot prompt\nPrompt executed in 0.01 seconds\ngot prompt\n\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\nRequested to load CLIPVisionModelProjection\nLoading 1 new model\nloaded completely 0.0 581.900390625 True\nRequested to load SDXL\nLoading 1 new model\nloaded completely 9.5367431640625e+25 4935.9311599731445 True\n100%|███████████████████████████████████████████| 30/30 [01:00<00:00,  2.01s/it]\nPrompt executed in 74.63 seconds\ngot prompt\nloaded completely 11019.404465484618 4935.9311599731445 True\n100%|███████████████████████████████████████████| 30/30 [01:00<00:00,  2.01s/it]\nPrompt executed in 62.80 seconds\ngot prompt\ngot prompt\nRequested to load SDXL\nLoading 1 new model\nloaded completely 0.0 4935.9311599731445 True\n100%|███████████████████████████████████████████| 30/30 [01:00<00:00,  2.01s/it]\nRequested to load AutoencoderKL\nLoading 1 new model\nloaded completely 0.0 319.11416244506836 True\nPrompt executed in 72.88 seconds\nPrompt executed in 0.01 seconds\ngot prompt\nRequested to load SDXL\nLoading 1 new model\nloaded completely 0.0 4935.9311599731445 True\n100%|███████████████████████████████████████████| 30/30 [01:00<00:00,  2.01s/it]\nRequested to load AutoencoderKL\nLoading 1 new model\nloaded completely 0.0 319.11416244506836 True\nPrompt executed in 72.78 seconds\ngot prompt\nRequested to load SDXL\nLoading 1 new model\nloaded completely 0.0 4935.9311599731445 True\n100%|███████████████████████████████████████████| 30/30 [01:00<00:00,  2.01s/it]\nRequested to load AutoencoderKL\nLoading 1 new model\nloaded completely 0.0 319.11416244506836 True\nPrompt executed in 72.87 seconds\ngot prompt\nRequested to load CLIPVisionModelProjection\nLoading 1 new model\nloaded completely 0.0 581.900390625 True\nRequested to load SDXL\nLoading 1 new model\nloaded completely 9.5367431640625e+25 4935.9311599731445 True\n100%|███████████████████████████████████████████| 30/30 [01:00<00:00,  2.01s/it]\nPrompt executed in 74.76 seconds\ngot prompt\nFailed to find /kaggle/working/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/yzd-v/DWPose/yolox_l.onnx.\n Downloading from huggingface.co\ncacher folder is /tmp, you can change it by custom_tmp_path in config.yaml\n[Errno 2] No such file or directory: '/tmp/ckpts'\nmodel_path is /kaggle/working/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/yzd-v/DWPose/yolox_l.onnx\nFailed to find /kaggle/working/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/hr16/DWPose-TorchScript-BatchSize5/dw-ll_ucoco_384_bs5.torchscript.pt.\n Downloading from huggingface.co\ncacher folder is /tmp, you can change it by custom_tmp_path in config.yaml\n[Errno 2] No such file or directory: '/tmp/ckpts'\nmodel_path is /kaggle/working/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/hr16/DWPose-TorchScript-BatchSize5/dw-ll_ucoco_384_bs5.torchscript.pt\n\nDWPose: Using yolox_l.onnx for bbox detection and dw-ll_ucoco_384_bs5.torchscript.pt for pose estimation\nDWPose: Caching ONNXRuntime session yolox_l.onnx...\nDWPose: Caching TorchScript module dw-ll_ucoco_384_bs5.torchscript.pt on ...\nDWPose: Bbox 9629.43ms\nRequested to load ControlNet\nLoading 1 new model\nloaded completely 0.0 2396.797637939453 True\nloaded completely 7904.460881042481 4935.9311599731445 True\n  0%|                                                    | 0/30 [00:00<?, ?it/s]\n!!! Exception during processing !!! mat1 and mat2 shapes cannot be multiplied (2x5632 and 2816x1280)\nTraceback (most recent call last):\n  File \"/kaggle/working/ComfyUI/execution.py\", line 323, in execute\n    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 198, in get_output_data\n    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 169, in _map_node_over_list\n    process_inputs(input_dict, i)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 158, in process_inputs\n    results.append(getattr(obj, func)(**inputs))\n  File \"/kaggle/working/ComfyUI/nodes.py\", line 1437, in sample\n    return common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise)\n  File \"/kaggle/working/ComfyUI/nodes.py\", line 1404, in common_ksampler\n    samples = comfy.sample.sample(model, noise, steps, cfg, sampler_name, scheduler, positive, negative, latent_image,\n  File \"/kaggle/working/ComfyUI/custom_nodes/ComfyUI-AnimateDiff-Evolved/animatediff/sampling.py\", line 420, in motion_sample\n    return orig_comfy_sample(model, noise, *args, **kwargs)\n  File \"/kaggle/working/ComfyUI/comfy/sample.py\", line 43, in sample\n    samples = sampler.sample(noise, positive, negative, cfg=cfg, latent_image=latent_image, start_step=start_step, last_step=last_step, force_full_denoise=force_full_denoise, denoise_mask=noise_mask, sigmas=sigmas, callback=callback, disable_pbar=disable_pbar, seed=seed)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 832, in sample\n    return sample(self.model, noise, positive, negative, cfg, self.device, sampler, sigmas, self.model_options, latent_image=latent_image, denoise_mask=denoise_mask, callback=callback, disable_pbar=disable_pbar, seed=seed)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 732, in sample\n    return cfg_guider.sample(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 719, in sample\n    output = self.inner_sample(noise, latent_image, device, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 698, in inner_sample\n    samples = sampler.sample(self, sigmas, extra_args, callback, noise, latent_image, denoise_mask, disable_pbar)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 603, in sample\n    samples = self.sampler_function(model_k, noise, sigmas, extra_args=extra_args, callback=k_callback, disable=disable_pbar, **self.extra_options)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n    return func(*args, **kwargs)\n  File \"/kaggle/working/ComfyUI/comfy/k_diffusion/sampling.py\", line 664, in sample_dpmpp_2m\n    denoised = model(x, sigmas[i] * s_in, **extra_args)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 299, in __call__\n    out = self.inner_model(x, sigma, model_options=model_options, seed=seed)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 685, in __call__\n    return self.predict_noise(*args, **kwargs)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 688, in predict_noise\n    return sampling_function(self.inner_model, x, timestep, self.conds.get(\"negative\", None), self.conds.get(\"positive\", None), self.cfg, model_options=model_options, seed=seed)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 279, in sampling_function\n    out = calc_cond_batch(model, conds, x, timestep, model_options)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 202, in calc_cond_batch\n    c['control'] = control.get_control(input_x, timestep_, c, len(cond_or_uncond))\n  File \"/kaggle/working/ComfyUI/comfy/controlnet.py\", line 255, in get_control\n    control = self.control_model(x=x_noisy.to(dtype), hint=self.cond_hint, timesteps=timestep.to(dtype), context=context.to(dtype), **extra)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/kaggle/working/ComfyUI/comfy/cldm/cldm.py\", line 421, in forward\n    emb = emb + self.label_emb(y)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 219, in forward\n    input = module(input)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 219, in forward\n    input = module(input)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/kaggle/working/ComfyUI/comfy/ops.py\", line 70, in forward\n    return super().forward(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 117, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (2x5632 and 2816x1280)\n\nPrompt executed in 32.15 seconds\ngot prompt\n 80%|██████████████████████████████████▍        | 24/30 [00:48<00:12,  2.01s/it]got prompt\n100%|███████████████████████████████████████████| 30/30 [01:00<00:00,  2.01s/it]\nPrompt executed in 63.41 seconds\nRequested to load SDXL\nLoading 1 new model\nloaded completely 0.0 4935.9311599731445 True\n  0%|                                                    | 0/30 [00:00<?, ?it/s]\n!!! Exception during processing !!! mat1 and mat2 shapes cannot be multiplied (2x5632 and 2816x1280)\nTraceback (most recent call last):\n  File \"/kaggle/working/ComfyUI/execution.py\", line 323, in execute\n    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 198, in get_output_data\n    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 169, in _map_node_over_list\n    process_inputs(input_dict, i)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 158, in process_inputs\n    results.append(getattr(obj, func)(**inputs))\n  File \"/kaggle/working/ComfyUI/nodes.py\", line 1437, in sample\n    return common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise)\n  File \"/kaggle/working/ComfyUI/nodes.py\", line 1404, in common_ksampler\n    samples = comfy.sample.sample(model, noise, steps, cfg, sampler_name, scheduler, positive, negative, latent_image,\n  File \"/kaggle/working/ComfyUI/custom_nodes/ComfyUI-AnimateDiff-Evolved/animatediff/sampling.py\", line 420, in motion_sample\n    return orig_comfy_sample(model, noise, *args, **kwargs)\n  File \"/kaggle/working/ComfyUI/comfy/sample.py\", line 43, in sample\n    samples = sampler.sample(noise, positive, negative, cfg=cfg, latent_image=latent_image, start_step=start_step, last_step=last_step, force_full_denoise=force_full_denoise, denoise_mask=noise_mask, sigmas=sigmas, callback=callback, disable_pbar=disable_pbar, seed=seed)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 832, in sample\n    return sample(self.model, noise, positive, negative, cfg, self.device, sampler, sigmas, self.model_options, latent_image=latent_image, denoise_mask=denoise_mask, callback=callback, disable_pbar=disable_pbar, seed=seed)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 732, in sample\n    return cfg_guider.sample(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 719, in sample\n    output = self.inner_sample(noise, latent_image, device, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 698, in inner_sample\n    samples = sampler.sample(self, sigmas, extra_args, callback, noise, latent_image, denoise_mask, disable_pbar)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 603, in sample\n    samples = self.sampler_function(model_k, noise, sigmas, extra_args=extra_args, callback=k_callback, disable=disable_pbar, **self.extra_options)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n    return func(*args, **kwargs)\n  File \"/kaggle/working/ComfyUI/comfy/k_diffusion/sampling.py\", line 664, in sample_dpmpp_2m\n    denoised = model(x, sigmas[i] * s_in, **extra_args)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 299, in __call__\n    out = self.inner_model(x, sigma, model_options=model_options, seed=seed)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 685, in __call__\n    return self.predict_noise(*args, **kwargs)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 688, in predict_noise\n    return sampling_function(self.inner_model, x, timestep, self.conds.get(\"negative\", None), self.conds.get(\"positive\", None), self.cfg, model_options=model_options, seed=seed)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 279, in sampling_function\n    out = calc_cond_batch(model, conds, x, timestep, model_options)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 202, in calc_cond_batch\n    c['control'] = control.get_control(input_x, timestep_, c, len(cond_or_uncond))\n  File \"/kaggle/working/ComfyUI/comfy/controlnet.py\", line 255, in get_control\n    control = self.control_model(x=x_noisy.to(dtype), hint=self.cond_hint, timesteps=timestep.to(dtype), context=context.to(dtype), **extra)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/kaggle/working/ComfyUI/comfy/cldm/cldm.py\", line 421, in forward\n    emb = emb + self.label_emb(y)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 219, in forward\n    input = module(input)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 219, in forward\n    input = module(input)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/kaggle/working/ComfyUI/comfy/ops.py\", line 70, in forward\n    return super().forward(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 117, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (2x5632 and 2816x1280)\n\nPrompt executed in 1.53 seconds\ngot prompt\n100%|███████████████████████████████████████████| 30/30 [01:00<00:00,  2.02s/it]\nPrompt executed in 63.26 seconds\ngot prompt\nRequested to load SDXL\nLoading 1 new model\nloaded completely 0.0 4935.9311599731445 True\n  0%|                                                    | 0/30 [00:00<?, ?it/s]\n!!! Exception during processing !!! mat1 and mat2 shapes cannot be multiplied (2x5632 and 2816x1280)\nTraceback (most recent call last):\n  File \"/kaggle/working/ComfyUI/execution.py\", line 323, in execute\n    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 198, in get_output_data\n    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 169, in _map_node_over_list\n    process_inputs(input_dict, i)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 158, in process_inputs\n    results.append(getattr(obj, func)(**inputs))\n  File \"/kaggle/working/ComfyUI/nodes.py\", line 1437, in sample\n    return common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise)\n  File \"/kaggle/working/ComfyUI/nodes.py\", line 1404, in common_ksampler\n    samples = comfy.sample.sample(model, noise, steps, cfg, sampler_name, scheduler, positive, negative, latent_image,\n  File \"/kaggle/working/ComfyUI/custom_nodes/ComfyUI-AnimateDiff-Evolved/animatediff/sampling.py\", line 420, in motion_sample\n    return orig_comfy_sample(model, noise, *args, **kwargs)\n  File \"/kaggle/working/ComfyUI/comfy/sample.py\", line 43, in sample\n    samples = sampler.sample(noise, positive, negative, cfg=cfg, latent_image=latent_image, start_step=start_step, last_step=last_step, force_full_denoise=force_full_denoise, denoise_mask=noise_mask, sigmas=sigmas, callback=callback, disable_pbar=disable_pbar, seed=seed)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 832, in sample\n    return sample(self.model, noise, positive, negative, cfg, self.device, sampler, sigmas, self.model_options, latent_image=latent_image, denoise_mask=denoise_mask, callback=callback, disable_pbar=disable_pbar, seed=seed)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 732, in sample\n    return cfg_guider.sample(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 719, in sample\n    output = self.inner_sample(noise, latent_image, device, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 698, in inner_sample\n    samples = sampler.sample(self, sigmas, extra_args, callback, noise, latent_image, denoise_mask, disable_pbar)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 603, in sample\n    samples = self.sampler_function(model_k, noise, sigmas, extra_args=extra_args, callback=k_callback, disable=disable_pbar, **self.extra_options)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n    return func(*args, **kwargs)\n  File \"/kaggle/working/ComfyUI/comfy/k_diffusion/sampling.py\", line 664, in sample_dpmpp_2m\n    denoised = model(x, sigmas[i] * s_in, **extra_args)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 299, in __call__\n    out = self.inner_model(x, sigma, model_options=model_options, seed=seed)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 685, in __call__\n    return self.predict_noise(*args, **kwargs)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 688, in predict_noise\n    return sampling_function(self.inner_model, x, timestep, self.conds.get(\"negative\", None), self.conds.get(\"positive\", None), self.cfg, model_options=model_options, seed=seed)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 279, in sampling_function\n    out = calc_cond_batch(model, conds, x, timestep, model_options)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 202, in calc_cond_batch\n    c['control'] = control.get_control(input_x, timestep_, c, len(cond_or_uncond))\n  File \"/kaggle/working/ComfyUI/comfy/controlnet.py\", line 255, in get_control\n    control = self.control_model(x=x_noisy.to(dtype), hint=self.cond_hint, timesteps=timestep.to(dtype), context=context.to(dtype), **extra)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/kaggle/working/ComfyUI/comfy/cldm/cldm.py\", line 421, in forward\n    emb = emb + self.label_emb(y)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 219, in forward\n    input = module(input)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 219, in forward\n    input = module(input)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/kaggle/working/ComfyUI/comfy/ops.py\", line 70, in forward\n    return super().forward(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 117, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (2x5632 and 2816x1280)\n\nPrompt executed in 1.58 seconds\ngot prompt\n  0%|                                                    | 0/30 [00:00<?, ?it/s]\n!!! Exception during processing !!! mat1 and mat2 shapes cannot be multiplied (2x5632 and 2816x1280)\nTraceback (most recent call last):\n  File \"/kaggle/working/ComfyUI/execution.py\", line 323, in execute\n    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 198, in get_output_data\n    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 169, in _map_node_over_list\n    process_inputs(input_dict, i)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 158, in process_inputs\n    results.append(getattr(obj, func)(**inputs))\n  File \"/kaggle/working/ComfyUI/nodes.py\", line 1437, in sample\n    return common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise)\n  File \"/kaggle/working/ComfyUI/nodes.py\", line 1404, in common_ksampler\n    samples = comfy.sample.sample(model, noise, steps, cfg, sampler_name, scheduler, positive, negative, latent_image,\n  File \"/kaggle/working/ComfyUI/custom_nodes/ComfyUI-AnimateDiff-Evolved/animatediff/sampling.py\", line 420, in motion_sample\n    return orig_comfy_sample(model, noise, *args, **kwargs)\n  File \"/kaggle/working/ComfyUI/comfy/sample.py\", line 43, in sample\n    samples = sampler.sample(noise, positive, negative, cfg=cfg, latent_image=latent_image, start_step=start_step, last_step=last_step, force_full_denoise=force_full_denoise, denoise_mask=noise_mask, sigmas=sigmas, callback=callback, disable_pbar=disable_pbar, seed=seed)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 832, in sample\n    return sample(self.model, noise, positive, negative, cfg, self.device, sampler, sigmas, self.model_options, latent_image=latent_image, denoise_mask=denoise_mask, callback=callback, disable_pbar=disable_pbar, seed=seed)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 732, in sample\n    return cfg_guider.sample(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 719, in sample\n    output = self.inner_sample(noise, latent_image, device, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 698, in inner_sample\n    samples = sampler.sample(self, sigmas, extra_args, callback, noise, latent_image, denoise_mask, disable_pbar)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 603, in sample\n    samples = self.sampler_function(model_k, noise, sigmas, extra_args=extra_args, callback=k_callback, disable=disable_pbar, **self.extra_options)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n    return func(*args, **kwargs)\n  File \"/kaggle/working/ComfyUI/comfy/k_diffusion/sampling.py\", line 664, in sample_dpmpp_2m\n    denoised = model(x, sigmas[i] * s_in, **extra_args)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 299, in __call__\n    out = self.inner_model(x, sigma, model_options=model_options, seed=seed)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 685, in __call__\n    return self.predict_noise(*args, **kwargs)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 688, in predict_noise\n    return sampling_function(self.inner_model, x, timestep, self.conds.get(\"negative\", None), self.conds.get(\"positive\", None), self.cfg, model_options=model_options, seed=seed)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 279, in sampling_function\n    out = calc_cond_batch(model, conds, x, timestep, model_options)\n  File \"/kaggle/working/ComfyUI/comfy/samplers.py\", line 202, in calc_cond_batch\n    c['control'] = control.get_control(input_x, timestep_, c, len(cond_or_uncond))\n  File \"/kaggle/working/ComfyUI/comfy/controlnet.py\", line 255, in get_control\n    control = self.control_model(x=x_noisy.to(dtype), hint=self.cond_hint, timesteps=timestep.to(dtype), context=context.to(dtype), **extra)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/kaggle/working/ComfyUI/comfy/cldm/cldm.py\", line 421, in forward\n    emb = emb + self.label_emb(y)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 219, in forward\n    input = module(input)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 219, in forward\n    input = module(input)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/kaggle/working/ComfyUI/comfy/ops.py\", line 70, in forward\n    return super().forward(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 117, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (2x5632 and 2816x1280)\n\nPrompt executed in 0.05 seconds\ngot prompt\nkey adm_in_channels does not match 2816 || 5632\nkey in_channels does not match 4 || 9\nkey in_channels does not match 4 || 8\n!!! Exception during processing !!! This loader does not support SDXL type, please use ControlNet loader + KolorsControlNetPatch node\nTraceback (most recent call last):\n  File \"/kaggle/working/ComfyUI/execution.py\", line 323, in execute\n    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 198, in get_output_data\n    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 169, in _map_node_over_list\n    process_inputs(input_dict, i)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 158, in process_inputs\n    results.append(getattr(obj, func)(**inputs))\n  File \"/kaggle/working/ComfyUI/custom_nodes/ComfyUI-Kolors-MZ/__init__.py\", line 183, in load_controlnet\n    return mz_kolors_core.MZ_KolorsControlNetLoader_call(kwargs)\n  File \"/kaggle/working/ComfyUI/custom_nodes/ComfyUI-Kolors-MZ/mz_kolors_core.py\", line 243, in MZ_KolorsControlNetLoader_call\n    control_net = comfy.controlnet.load_controlnet(controlnet_path)\n  File \"/kaggle/working/ComfyUI/comfy/controlnet.py\", line 654, in load_controlnet\n    cnet = load_controlnet_state_dict(comfy.utils.load_torch_file(ckpt_path, safe_load=True), model=model, model_options=model_options)\n  File \"/kaggle/working/ComfyUI/comfy/controlnet.py\", line 613, in load_controlnet_state_dict\n    control_model = comfy.cldm.cldm.ControlNet(**controlnet_config)\n  File \"/kaggle/working/ComfyUI/custom_nodes/ComfyUI-Kolors-MZ/hook_comfyui_kolors_v2.py\", line 259, in __init__\n    raise Exception(\nException: This loader does not support SDXL type, please use ControlNet loader + KolorsControlNetPatch node\n\nPrompt executed in 0.07 seconds\ngot prompt\nFailed to validate prompt for output 101:\n* SetUnionControlNetType 146:\n  - Required input is missing: control_net\nOutput will be ignored\nPrompt executed in 0.02 seconds\ngot prompt\nRequested to load ControlNet\nLoading 1 new model\n 97%|█████████████████████████████████████████▌ | 29/30 [01:24<00:02,  2.93s/it]got prompt\n100%|███████████████████████████████████████████| 30/30 [01:27<00:00,  2.93s/it]\nPrompt executed in 93.18 seconds\nFailed to find /kaggle/working/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/lllyasviel/Annotators/body_pose_model.pth.\n Downloading from huggingface.co\ncacher folder is /tmp, you can change it by custom_tmp_path in config.yaml\n[Errno 2] No such file or directory: '/tmp/ckpts'\nmodel_path is /kaggle/working/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/lllyasviel/Annotators/body_pose_model.pth\nFailed to find /kaggle/working/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/lllyasviel/Annotators/hand_pose_model.pth.\n Downloading from huggingface.co\ncacher folder is /tmp, you can change it by custom_tmp_path in config.yaml\n[Errno 2] No such file or directory: '/tmp/ckpts'\nmodel_path is /kaggle/working/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/lllyasviel/Annotators/hand_pose_model.pth\nFailed to find /kaggle/working/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/lllyasviel/Annotators/facenet.pth.\n Downloading from huggingface.co\ncacher folder is /tmp, you can change it by custom_tmp_path in config.yaml\n[Errno 2] No such file or directory: '/tmp/ckpts'\nmodel_path is /kaggle/working/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/lllyasviel/Annotators/facenet.pth\nPrompt executed in 6.96 seconds\ngot prompt\nPrompt executed in 0.04 seconds\ngot prompt\nFailed to find /kaggle/working/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/hr16/yolo-nas-fp16/yolo_nas_s_fp16.onnx.\n Downloading from huggingface.co\ncacher folder is /tmp, you can change it by custom_tmp_path in config.yaml\n[Errno 2] No such file or directory: '/tmp/ckpts'\nmodel_path is /kaggle/working/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/hr16/yolo-nas-fp16/yolo_nas_s_fp16.onnx\nFailed to find /kaggle/working/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/hr16/UnJIT-DWPose/dw-ll_ucoco.onnx.\n Downloading from huggingface.co\ncacher folder is /tmp, you can change it by custom_tmp_path in config.yaml\n[Errno 2] No such file or directory: '/tmp/ckpts'\nmodel_path is /kaggle/working/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/hr16/UnJIT-DWPose/dw-ll_ucoco.onnx\n\nDWPose: Using yolo_nas_s_fp16.onnx for bbox detection and dw-ll_ucoco.onnx for pose estimation\nDWPose: Caching ONNXRuntime session yolo_nas_s_fp16.onnx...\nDWPose: Caching ONNXRuntime session dw-ll_ucoco.onnx...\nDWPose: Bbox 3136.20ms\ngot prompt\nDWPose: Pose 3108.11ms on 1 people\n\nPrompt executed in 11.21 seconds\nPrompt executed in 0.02 seconds\ngot prompt\nPrompt executed in 0.02 seconds\ngot prompt\nPrompt executed in 0.02 seconds\ngot prompt\nPrompt executed in 0.02 seconds\ngot prompt\nUnloading models for lowram load.\n1 models unloaded.\nLoading 1 new model\nloaded completely 0.0 319.11416244506836 True\nRequested to load SDXL\nLoading 1 new model\nloaded completely 0.0 4935.9311599731445 True\n100%|███████████████████████████████████████████| 30/30 [02:18<00:00,  4.61s/it]\nUnloading models for lowram load.\n1 models unloaded.\nLoading 1 new model\nloaded completely 0.0 319.11416244506836 True\nPrompt executed in 149.14 seconds\ngot prompt\nPrompt executed in 0.02 seconds\ngot prompt\nRequested to load SDXL\nLoading 1 new model\nloaded completely 0.0 4935.9311599731445 True\n100%|███████████████████████████████████████████| 30/30 [02:18<00:00,  4.61s/it]\nRequested to load AutoencoderKL\nLoading 1 new model\nloaded completely 0.0 319.11416244506836 True\nPrompt executed in 153.01 seconds\ngot prompt\nRequested to load SDXL\nLoading 1 new model\nloaded completely 0.0 4935.9311599731445 True\n100%|███████████████████████████████████████████| 30/30 [02:18<00:00,  4.62s/it]\nRequested to load AutoencoderKL\nLoading 1 new model\nloaded completely 0.0 319.11416244506836 True\nPrompt executed in 152.96 seconds\ngot prompt\nRequested to load SDXL\nLoading 1 new model\nloaded completely 0.0 4935.9311599731445 True\n 17%|███████▎                                    | 5/30 [00:22<01:54,  4.59s/it]got prompt\n100%|███████████████████████████████████████████| 30/30 [02:18<00:00,  4.61s/it]\nRequested to load AutoencoderKL\nLoading 1 new model\nloaded completely 0.0 319.11416244506836 True\nPrompt executed in 152.97 seconds\nRequested to load SDXL\nLoading 1 new model\nloaded completely 0.0 4935.9311599731445 True\n100%|███████████████████████████████████████████| 30/30 [02:18<00:00,  4.62s/it]\nRequested to load AutoencoderKL\nLoading 1 new model\nloaded completely 0.0 319.11416244506836 True\nPrompt executed in 153.28 seconds\ngot prompt\nFailed to validate prompt for output 160:\n* (prompt):\n  - Required input is missing: images\n* PreviewImage 160:\n  - Required input is missing: images\nOutput will be ignored\nRequested to load CLIPVisionModelProjection\nLoading 1 new model\nloaded completely 0.0 581.900390625 True\nRequested to load SDXL\nLoading 1 new model\nloaded completely 0.0 4935.9311599731445 True\n100%|███████████████████████████████████████████| 30/30 [02:20<00:00,  4.67s/it]\nUnloading models for lowram load.\n1 models unloaded.\nLoading 1 new model\nloaded completely 0.0 319.11416244506836 True\nPrompt executed in 158.81 seconds\ngot prompt\n\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\nRequested to load CLIPVisionModelProjection\nLoading 1 new model\nloaded completely 0.0 581.900390625 True\nRequested to load SDXL\nLoading 1 new model\nloaded completely 0.0 4935.9311599731445 True\n100%|███████████████████████████████████████████| 30/30 [00:59<00:00,  2.00s/it]\nPrompt executed in 68.36 seconds\ngot prompt\nRequested to load SDXL\nLoading 1 new model\nloaded completely 0.0 4935.9311599731445 True\n100%|███████████████████████████████████████████| 30/30 [00:59<00:00,  2.00s/it]\nRequested to load AutoencoderKL\nLoading 1 new model\nloaded completely 0.0 319.11416244506836 True\nPrompt executed in 72.67 seconds\ngot prompt\nloaded completely 11306.4883354187 4935.9311599731445 True\n 20%|████████▊                                   | 6/30 [00:12<00:48,  2.01s/it]","output_type":"stream"}]},{"cell_type":"code","source":"# hf_hub_download(repo_id=\"promeai/FLUX.1-controlnet-lineart-promeai\", filename=\"diffusion_pytorch_model.safetensors\", local_dir=\"/opt/models/controlnet\" )\n# os.rename('/opt/models/controlnet/diffusion_pytorch_model.safetensors', '/opt/models/controlnet/FLUX.1-controlnet-lineart-promeai.safetensors')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#clear output\n%cd /kaggle/working/ComfyUI\n# !rm -rf /kaggle/working/ComfyUI/output/*\n# !rm -rf /kaggle/working/ComfyUI/input/*","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#TODO\n# clear DISK\n%cd /kaggle/working/ComfyUI\n!du -hd1 ./|sort -hr\n!du -hd1 ./models|sort -hr\n!du -hd1 ./custom_nodes|sort -hr\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}