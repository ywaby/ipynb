{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"server_env=\"kaggle\" # kaggle CN_server colab\nif server_env==\"CN_server\":\n    !git config --global url.\"https://mirror.ghproxy.com/https://github.com/\".insteadOf https://github.com/\n    !export HF_ENDPOINT=https://hf-mirror.com\n    # !export HF_ENDPOINT=https://hf-api.gitee.com","metadata":{"execution":{"iopub.status.busy":"2024-10-08T07:18:05.101451Z","iopub.execute_input":"2024-10-08T07:18:05.101854Z","iopub.status.idle":"2024-10-08T07:18:05.114934Z","shell.execute_reply.started":"2024-10-08T07:18:05.101815Z","shell.execute_reply":"2024-10-08T07:18:05.113407Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvcc --version\n!nvidia-smi \n\n!pip list |grep numba\n!pip list |grep numpy\n!pip list |grep transformers","metadata":{"execution":{"iopub.status.busy":"2024-10-08T07:47:34.267450Z","iopub.execute_input":"2024-10-08T07:47:34.267910Z","iopub.status.idle":"2024-10-08T07:47:44.366203Z","shell.execute_reply.started":"2024-10-08T07:47:34.267867Z","shell.execute_reply":"2024-10-08T07:47:44.364785Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/\n!git clone https://github.com/comfyanonymous/ComfyUI.git\n\n%cd /kaggle/working/ComfyUI\n# branch\n!git checkout master\n# update\n!git pull\n!pip install -r requirements.txt \n#pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu121","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-08T07:20:24.873368Z","iopub.execute_input":"2024-10-08T07:20:24.873764Z","iopub.status.idle":"2024-10-08T07:20:44.679899Z","shell.execute_reply.started":"2024-10-08T07:20:24.873729Z","shell.execute_reply":"2024-10-08T07:20:44.678760Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd  /kaggle/working/ComfyUI/custom_nodes\n!git clone https://github.com/ltdrdata/ComfyUI-Manager.git\n!git clone https://github.com/Stability-AI/stability-ComfyUI-nodes.git\n!git clone https://github.com/Kosinkadink/ComfyUI-Advanced-ControlNet\n!git clone https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite\n!git clone https://github.com/Kosinkadink/ComfyUI-AnimateDiff-Evolved\n!git clone https://github.com/cubiq/ComfyUI_IPAdapter_plus\n!git clone https://github.com/WASasquatch/was-node-suite-comfyui\n!git clone https://github.com/EllangoK/ComfyUI-post-processing-nodes.git \n!git clone https://github.com/Fannovel16/comfyui_controlnet_aux\n!git clone https://github.com/chrisgoringe/cg-use-everywhere.git\n!git clone https://github.com/yolain/ComfyUI-Easy-Use.git\n!git clone https://github.com/ltdrdata/ComfyUI-Inspire-Pack\n!git clone https://github.com/huchenlei/ComfyUI-layerdiffuse.git   \n# !git clone https://github.com/chflame163/ComfyUI_LayerStyle\n!git clone https://github.com/Gourieff/comfyui-reactor-node\n!git clone https://github.com/kijai/ComfyUI-MimicMotionWrapper\n!git clone https://github.com/kijai/ComfyUI-segment-anything-2\n!git clone https://github.com/AIFSH/GSTTS-ComfyUI\n!git clone https://github.com/kijai/ComfyUI-ControlNeXt-SVD\n!git clone https://github.com/john-mnz/ComfyUI-Inspyrenet-Rembg\n!git clone https://github.com/PowerHouseMan/ComfyUI-AdvancedLivePortrait\n!git clone https://github.com/lldacing/ComfyUI_BiRefNet_ll\n!git clone https://github.com/StartHua/Comfyui_joytag\n!git clone https://github.com/rgthree/rgthree-comfy\n# ComfyUI-Custom-Scripts\n!git clone https://github.com/Fannovel16/ComfyUI-Frame-Interpolation\n!git clone https://github.com/kijai/ComfyUI-KJNodes\n!git clone https://github.com/kijai/ComfyUI-LivePortraitKJ\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-08T07:18:05.120867Z","iopub.execute_input":"2024-10-08T07:18:05.121168Z","iopub.status.idle":"2024-10-08T07:19:23.423331Z","shell.execute_reply.started":"2024-10-08T07:18:05.121138Z","shell.execute_reply":"2024-10-08T07:19:23.422133Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd  /kaggle/working/ComfyUI\n!wget https://civitai.com/api/download/models/125849 -O ./models/embeddings/bad-hands-5.pt\n!wget https://huggingface.co/datasets/gsdf/EasyNegative/resolve/main/EasyNegative.safetensors -O ./models/embeddings/EasyNegative.safetensors\n!wget https://civitai.com/api/download/models/5637 -O ./models/embeddings/deepnegative_v1_75t.pt\n","metadata":{"execution":{"iopub.status.busy":"2024-10-08T07:24:39.395133Z","iopub.execute_input":"2024-10-08T07:24:39.395532Z","iopub.status.idle":"2024-10-08T07:24:46.653082Z","shell.execute_reply.started":"2024-10-08T07:24:39.395495Z","shell.execute_reply":"2024-10-08T07:24:46.652035Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## REBOOT","metadata":{}},{"cell_type":"code","source":"!nvcc --version\n!nvidia-smi ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n%cd /kaggle/working/ComfyUI\n!apt -y update -qq\n!apt -y install -qq aria2\n# !pip install gdown\n!npm install -g localtunnel\n!pip install huggingface_hub  hf_transfer\nimport os\nos.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n","metadata":{"execution":{"iopub.status.busy":"2024-10-14T03:10:23.685874Z","iopub.execute_input":"2024-10-14T03:10:23.686237Z","iopub.status.idle":"2024-10-14T03:10:54.050738Z","shell.execute_reply.started":"2024-10-14T03:10:23.686202Z","shell.execute_reply":"2024-10-14T03:10:54.049523Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/working/ComfyUI\n68 packages can be upgraded. Run 'apt list --upgradable' to see them.\n\u001b[1;33mW: \u001b[0mhttps://packages.cloud.google.com/apt/dists/gcsfuse-focal/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\u001b[0m\n\u001b[1;33mW: \u001b[0mhttps://packages.cloud.google.com/apt/dists/google-fast-socket/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\u001b[0m\nThe following additional packages will be installed:\n  libaria2-0 libc-ares2 libssh2-1\nThe following NEW packages will be installed:\n  aria2 libaria2-0 libc-ares2 libssh2-1\n0 upgraded, 4 newly installed, 0 to remove and 68 not upgraded.\nNeed to get 1622 kB of archives.\nAfter this operation, 5817 kB of additional disk space will be used.\n\n\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package libc-ares2:amd64.\n(Reading database ... 122996 files and directories currently installed.)\nPreparing to unpack .../libc-ares2_1.18.1-1ubuntu0.22.04.3_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  6%]\u001b[49m\u001b[39m [###.......................................................] \u001b8Unpacking libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 12%]\u001b[49m\u001b[39m [######....................................................] \u001b8Selecting previously unselected package libssh2-1:amd64.\nPreparing to unpack .../libssh2-1_1.10.0-3_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 18%]\u001b[49m\u001b[39m [##########................................................] \u001b8Unpacking libssh2-1:amd64 (1.10.0-3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 24%]\u001b[49m\u001b[39m [#############.............................................] \u001b8Selecting previously unselected package libaria2-0:amd64.\nPreparing to unpack .../libaria2-0_1.36.0-1_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 29%]\u001b[49m\u001b[39m [#################.........................................] \u001b8Unpacking libaria2-0:amd64 (1.36.0-1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 35%]\u001b[49m\u001b[39m [####################......................................] \u001b8Selecting previously unselected package aria2.\nPreparing to unpack .../aria2_1.36.0-1_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 41%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Unpacking aria2 (1.36.0-1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 47%]\u001b[49m\u001b[39m [###########################...............................] \u001b8Setting up libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 53%]\u001b[49m\u001b[39m [##############################............................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 59%]\u001b[49m\u001b[39m [##################################........................] \u001b8Setting up libssh2-1:amd64 (1.10.0-3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 65%]\u001b[49m\u001b[39m [#####################################.....................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 71%]\u001b[49m\u001b[39m [########################################..................] \u001b8Setting up libaria2-0:amd64 (1.36.0-1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 76%]\u001b[49m\u001b[39m [############################################..............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 82%]\u001b[49m\u001b[39m [###############################################...........] \u001b8Setting up aria2 (1.36.0-1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 88%]\u001b[49m\u001b[39m [###################################################.......] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 94%]\u001b[49m\u001b[39m [######################################################....] \u001b8Processing triggers for man-db (2.10.2-1) ...\nProcessing triggers for libc-bin (2.35-0ubuntu3.8) ...\n\n\u001b[K\u001b[?25hm#################\u001b[0m\u001b[100;90m.\u001b[0m] / reify:yargs-parser: \u001b[32;40mhttp\u001b[0m \u001b[35mfetch\u001b[0m GET 200 https://registry.\u001b[0m\u001b[K\nadded 22 packages in 2s\n\n3 packages are looking for funding\n  run `npm fund` for details\n\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m \n\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m New \u001b[33mminor\u001b[39m version of npm available! \u001b[31m10.5.0\u001b[39m -> \u001b[32m10.9.0\u001b[39m\n\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m Changelog: \u001b[36mhttps://github.com/npm/cli/releases/tag/v10.9.0\u001b[39m\n\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m Run \u001b[32mnpm install -g npm@10.9.0\u001b[39m to update!\n\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m \n\u001b[0mRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.25.1)\nCollecting hf_transfer\n  Downloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.8.30)\nDownloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: hf_transfer\nSuccessfully installed hf_transfer-0.1.8\n","output_type":"stream"}]},{"cell_type":"code","source":"\n%cd /kaggle/working/ComfyUI\n# branch\n!git checkout .\n## update\n!git pull\n\n!pip install -r requirements.txt \n\n            ","metadata":{"execution":{"iopub.status.busy":"2024-10-14T03:10:54.052847Z","iopub.execute_input":"2024-10-14T03:10:54.053194Z","iopub.status.idle":"2024-10-14T03:11:09.610325Z","shell.execute_reply.started":"2024-10-14T03:10:54.053156Z","shell.execute_reply":"2024-10-14T03:11:09.609254Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/working/ComfyUI\nUpdated 347 paths from the index\nremote: Enumerating objects: 15, done.\u001b[K\nremote: Counting objects: 100% (15/15), done.\u001b[K\nremote: Compressing objects: 100% (8/8), done.\u001b[K\nremote: Total 15 (delta 7), reused 14 (delta 7), pack-reused 0 (from 0)\u001b[K\nUnpacking objects: 100% (15/15), 10.49 KiB | 2.10 MiB/s, done.\nFrom https://github.com/comfyanonymous/ComfyUI\n   6632365..191a0d5  master     -> origin/master\nUpdating 6632365..191a0d5\nFast-forward\n .github/workflows/stable-release.yml               | 4 \u001b[32m++\u001b[m\u001b[31m--\u001b[m\n .github/workflows/windows_release_dependencies.yml | 4 \u001b[32m++\u001b[m\u001b[31m--\u001b[m\n .github/workflows/windows_release_package.yml      | 4 \u001b[32m++\u001b[m\u001b[31m--\u001b[m\n comfy/sd1_clip.py                                  | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n comfy/supported_models_base.py                     | 1 \u001b[32m+\u001b[m\n 5 files changed, 8 insertions(+), 7 deletions(-)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.4.0)\nCollecting torchsde (from -r requirements.txt (line 2))\n  Downloading torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (0.19.0)\nRequirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (2.4.0)\nCollecting einops (from -r requirements.txt (line 5))\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: transformers>=4.28.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (4.45.1)\nRequirement already satisfied: tokenizers>=0.13.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (0.20.0)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (0.2.0)\nRequirement already satisfied: safetensors>=0.4.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (0.4.5)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (3.9.5)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (6.0.2)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (10.3.0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (1.14.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (5.9.3)\nRequirement already satisfied: kornia>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 18)) (0.7.3)\nCollecting spandrel (from -r requirements.txt (line 19))\n  Downloading spandrel-0.4.0-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: soundfile in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 20)) (0.12.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (2024.6.1)\nRequirement already satisfied: numpy>=1.19 in /opt/conda/lib/python3.10/site-packages (from torchsde->-r requirements.txt (line 2)) (1.26.4)\nCollecting trampoline>=0.1.2 (from torchsde->-r requirements.txt (line 2))\n  Downloading trampoline-0.1.2-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.28.1->-r requirements.txt (line 6)) (0.25.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.28.1->-r requirements.txt (line 6)) (21.3)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.28.1->-r requirements.txt (line 6)) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.28.1->-r requirements.txt (line 6)) (2.32.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->-r requirements.txt (line 10)) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->-r requirements.txt (line 10)) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->-r requirements.txt (line 10)) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->-r requirements.txt (line 10)) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->-r requirements.txt (line 10)) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->-r requirements.txt (line 10)) (4.0.3)\nRequirement already satisfied: kornia-rs>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from kornia>=0.7.1->-r requirements.txt (line 18)) (0.1.5)\nRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile->-r requirements.txt (line 20)) (1.16.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile->-r requirements.txt (line 20)) (2.22)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.28.1->-r requirements.txt (line 6)) (3.1.2)\nRequirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp->-r requirements.txt (line 10)) (3.7)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->-r requirements.txt (line 1)) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 6)) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 6)) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 6)) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->-r requirements.txt (line 1)) (1.3.0)\nDownloading torchsde-0.2.6-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading spandrel-0.4.0-py3-none-any.whl (297 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.5/297.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\nInstalling collected packages: trampoline, einops, torchsde, spandrel\nSuccessfully installed einops-0.8.0 spandrel-0.4.0 torchsde-0.2.6 trampoline-0.1.2\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd /kaggle/working/ComfyUI\n\ncontent = \"\"\"\ncomfyui:\n     base_path: /kaggle/working/ComfyUI\n     checkpoints: /opt/models/checkpoints/\n     clip: /opt/models/clip/\n     clip_vision: /opt/models/clip_vision/\n     configs: /opt/models/configs/\n     controlnet: /opt/models/controlnet/\n     embeddings: /opt/models/embeddings/\n     loras: /opt/models/loras/\n     upscale_models: /opt/models/upscale_models/\n     vae: /opt/models/vae/\n     unet: /opt/models/unet/ \n     LLM: /opt/models/LLM/ \n     sam2: /opt/models/sam2/ \n     ipadapter: /opt/models/ipadapter/ \n     animatediff_models: /opt/models/animatediff_models/ \n     animatediff_motion_lora: /opt/models/animatediff_motion_lora/ \n\"\"\"\n\n# 将内容写入文件 'a'\nwith open('extra_model_paths.yaml', 'w') as file:\n    file.write(content)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T03:11:09.612074Z","iopub.execute_input":"2024-10-14T03:11:09.612551Z","iopub.status.idle":"2024-10-14T03:11:09.622776Z","shell.execute_reply.started":"2024-10-14T03:11:09.612443Z","shell.execute_reply":"2024-10-14T03:11:09.621800Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/working/ComfyUI\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Download models","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working/ComfyUI\n\n# hug token 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\n# civi token bbf631e0a67a9c72d8044d3552ec3079\nfrom huggingface_hub import snapshot_download, hf_hub_download\n\nimport os\n%mkdir /opt/models\nsdxl=0\nsd15=1\nAN=0\nkolors=0\npony=0\nflux=0\nkrita=0\ncontrolnext_comfy=0\ncogvideo=0\nsam2==1\n\n\nsnapshot_download(repo_id=\"Acly/Omni-SR\",  allow_patterns=[\"*.safetensors\"], local_dir=\"/opt/models/upscale_models\")\nsnapshot_download(repo_id=\"alexgenovese/reica_upscalers\",  local_dir=\"/opt/models/upscale_models\" )\n\n\nif sd15==1 or AN==1:\n    # !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/131004 -d /opt/models/checkpoints -o DreamShaperV8_inpaint.safetensors\n    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/128713 -d /opt/models/checkpoints -o DreamShaperV8.safetensors\n    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/624939?token=bbf631e0a67a9c72d8044d3552ec3079  -d /opt/models/checkpoints -o AWPainting.safetensors #2d toon\n    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/474453?token=bbf631e0a67a9c72d8044d3552ec3079  -d /opt/models/checkpoints -o ReV_Animated.safetensors #2.5d\n    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/119057 -d /opt/models/checkpoints -o MeinaMix.safetensors #2d mango\n    \n    # control-lora-v3 try it\n    hf_hub_download(repo_id=\"ByteDance/Hyper-SD\", filename=\"Hyper-SD15-8steps-CFG-lora.safetensors\", local_dir=\"/opt/models/loras\" )\n    # hf_hub_download(repo_id=\"ByteDance/Hyper-SD\", filename=\"Hyper-SD15-2steps-lora.safetensors\", local_dir=\"/opt/models/loras\" )\n    snapshot_download(repo_id=\"comfyanonymous/ControlNet-v1-1_fp16_safetensors\",  allow_patterns=[\"control_v11*.safetensors\"], local_dir=\"/opt/models/controlnet\" )\n    # snapshot_download(repo_id=\"webui/ControlNet-modules-safetensors\",  allow_patterns=[\"t2iadapter*.safetensors\"], local_dir=\"/opt/models/controlnet\" )\n\n    hf_hub_download(repo_id=\"h94/IP-Adapter\",subfolder='models',filename=\"ip-adapter_sd15.safetensors\", local_dir=\"/opt/models/ipadapter\")\n    hf_hub_download(repo_id=\"h94/IP-Adapter\",subfolder='models',filename=\"ip-adapter-plus_sd15.safetensors\", local_dir=\"/opt/models/ipadapter\")\n    hf_hub_download(repo_id=\"h94/IP-Adapter-FaceID\", filename=\"ip-adapter-faceid-plusv2_sd15.bin\", local_dir=\"/opt/models/ipadapter\")\n    hf_hub_download(repo_id=\"h94/IP-Adapter-FaceID\", filename=\"ip-adapter-faceid-plusv2_sd15_lora.safetensors\", local_dir=\"/opt/models/loras\")\n    hf_hub_download(repo_id=\"h94/IP-Adapter\", subfolder=\"models/image_encoder\", filename=\"model.safetensors\", local_dir=\"/opt/models/clip_vision\")\n    os.rename('/opt/models/clip_vision/models/image_encoder/model.safetensors','/opt/models/clip_vision/CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors')\n    if AN==1:\n        hf_hub_download(repo_id=\"conrevo/AnimateDiff-A1111\", filename=\"mm_sd15_v3.safetensors\", subfolder=\"motion_module\", local_dir=\"/opt/models/animatediff_models\")\n        # hf_hub_download(repo_id=\"wangfuyun/AnimateLCM-I2V\", filename=\"AnimateLCM_sd15_i2v.ckpt\",  local_dir=\"/opt/models/animatediff_models\")\n        hf_hub_download(repo_id=\"conrevo/AnimateDiff-A1111\", filename=\"mm_sd15_AnimateLCM.safetensors\", subfolder=\"motion_module\", local_dir=\"/opt/models/animatediff_models\")\n        hf_hub_download(repo_id=\"conrevo/AnimateDiff-A1111\", filename=\"mm_sd15_v3_adapter.safetensors\", subfolder=\"lora\", local_dir=\"/opt/models/loras\" )\n        hf_hub_download(repo_id=\"latent-consistency/lcm-lora-sdv1-5\", filename=\"pytorch_lora_weights.safetensors\", local_dir=\"/opt/models/loras\" )\n        os.rename('/opt/models/loras/pytorch_lora_weights.safetensors','/opt/models/loras/lcm.safetensors')\n        hf_hub_download(repo_id=\"guoyww/animatediff-sparsectrl-rgb\", filename=\"diffusion_pytorch_model.fp16.safetensors\",  local_dir=\"/opt/models/controlnet\")\n        os.rename('/opt/models/controlnet/diffusion_pytorch_model.fp16.safetensors','/opt/models/controlnet/animatediff-sparsectrl-rgb.safetensors')\n        hf_hub_download(repo_id=\"stabilityai/sd-vae-ft-mse-original\", filename=\"vae-ft-mse-840000-ema-pruned.safetensors\",  local_dir=\"/opt/models/vae\")\n\n\n# hyper\nif sdxl==1:\n    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M  -d /opt/models/checkpoints -o dreamshaper.xlturbo.2.1.safetensors https://civitai.com/api/download/models/351306?type=Model\n    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M  -d /opt/models/checkpoints -o dreamshaper.lighting.xl.safetensors https://civitai.com/api/download/models/354657?type=Model\n    hf_hub_download(repo_id=\"ByteDance/Hyper-SD\", filename=\"Hyper-SDXL-8steps-CFG-lora.safetensors\", local_dir=\"/opt/models/loras\" )\n    hf_hub_download(repo_id=\"xinsir/controlnet-union-sdxl-1.0\", filename=\"diffusion_pytorch_model_promax.safetensors\", local_dir=\"/opt/models/controlnet\")\n    os.rename('/opt/models/controlnet/diffusion_pytorch_model_promax.safetensors','/opt/models/controlnet/union-promax-sdxl-1.0.safetensors')\n    hf_hub_download(repo_id=\"h94/IP-Adapter\", subfolder='sdxl_models', filename=\"ip-adapter_sdxl_vit-h.safetensors\", local_dir=\"/opt/models/ipadapter\")\n    hf_hub_download(repo_id=\"h94/IP-Adapter\", subfolder='sdxl_models', filename=\"ip-adapter-plus_sdxl_vit-h.safetensors\", local_dir=\"/opt/models/ipadapter\")\n    hf_hub_download(repo_id=\"h94/IP-Adapter-FaceID\", filename=\"ip-adapter-faceid-plusv2_sdxl.bin\", local_dir=\"/opt/models/ipadapter\")\n    hf_hub_download(repo_id=\"h94/IP-Adapter-FaceID\", filename=\"ip-adapter-faceid-plusv2_sdxl_lora.safetensors\", local_dir=\"/opt/models/loras\")\n    hf_hub_download(repo_id=\"h94/IP-Adapter\", subfolder=\"models/image_encoder\", filename=\"model.safetensors\", local_dir=\"/opt/models/clip_vision\")\n    os.rename('/opt/models/clip_vision/models/image_encoder/model.safetensors','/opt/models/clip_vision/CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors')\n#     hf_hub_download(repo_id=\"h94/IP-Adapter\", subfolder=\"sdxl_models/image_encoder\", filename=\"model.safetensors\", local_dir=\"/opt/models/clip_vision\")\n#     os.rename('/opt/models/clip_vision/sdxl_models/image_encoder/model.safetensors','/opt/models/clip_vision/CLIP-ViT-bigG-14-laion2B-39B-b160k.safetensors')\nif kolors==1:\n    hf_hub_download(repo_id=\"Kwai-Kolors/Kolors\", subfolder=\"unet\", filename=\"diffusion_pytorch_model.fp16.safetensors\", local_dir=\"/opt/models/\" )\n    os.rename(\"/opt/models/unet/diffusion_pytorch_model.fp16.safetensors\", \"/opt/models/unet/kolors.fp16.safetensors\")\n    !ln -s -f  /opt/models/unet/kolors.fp16.safetensors  /kaggle/working/ComfyUI/models/unet/Kolors.fp16.safetensors\n\n\n    hf_hub_download(repo_id=\"Kijai/ChatGLM3-safetensors\", filename=\"chatglm3-8bit.safetensors\", local_dir=\"/opt/models/LLM\" )\n    !ln -s -f  /opt/models/LLM/chatglm3-8bit.safetensors  /kaggle/working/ComfyUI/models/LLM/chatglm3-8bit.safetensors\n\n    hf_hub_download(repo_id=\"Kwai-Kolors/Kolors-IP-Adapter-Plus\", filename=\"ip_adapter_plus_general.bin\", local_dir=\"/opt/models/ipadapter\")\n    os.rename('/opt/models/ipadapter/ip_adapter_plus_general.bin','/opt/models/ipadapter/Kolors_ip_adapter_plus_general.bin')\n\n    hf_hub_download(repo_id=\"Kwai-Kolors/Kolors-IP-Adapter-FaceID-Plus\", filename=\"ipa-faceid-plus.bin\", local_dir=\"/opt/models/ipadapter\")\n    # from huggingface_hub import snapshot_download\n    # snapshot_download(repo_id=\"DIAMONIK7777/antelopev2\",  local_dir=\"/kaggle/working/ComfyUI/models/inisghtface/models/antelopev2\")\n    # !unzip antelopev2.zip -d . # or unzip dirctly\n    # clip_vision\n    hf_hub_download(repo_id=\"Kwai-Kolors/Kolors-IP-Adapter-Plus\", subfolder=\"image_encoder\", filename=\"pytorch_model.bin\", local_dir=\"/opt/models/clip_vision\")\n    os.rename('/opt/models/clip_vision/image_encoder/pytorch_model.bin','/opt/models/clip_vision/Kolors.bin')\n\n    hf_hub_download(repo_id=\"stabilityai/sdxl-vae\", filename=\"sdxl_vae.safetensors\", local_dir=\"/opt/models/vae\")\n\n    hf_hub_download(repo_id=\"xinsir/controlnet-union-sdxl-1.0\", filename=\"diffusion_pytorch_model_promax.safetensors\", local_dir=\"/opt/models/controlnet\")\n    os.rename('/opt/models/controlnet/diffusion_pytorch_model_promax.safetensors','/opt/models/controlnet/union-promax-sdxl-1.0.safetensors')\n\n# llm\n# minicpm\nif pony==1:\n    # Pony\n    # https://civitai.com/models/669261/wukong-black-myth-wukong-pony-ad\n#     !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/749210?token=bbf631e0a67a9c72d8044d3552ec3079  -d /opt/models/loras -o Black-Myth-Wukong.pony.safetensors\n    # https://civitai.com/models/666554/black-myth-wukong\n#     !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/779789?token=bbf631e0a67a9c72d8044d3552ec3079 -d /opt/models/loras -o Black-Myth-Wukong.v2.pony.safetensors\n\n    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M  -d /opt/models/checkpoints -o pony.v6.safetensors https://civitai.com/api/download/models/290640?type=Model\n    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M  -d /opt/models/checkpoints -o pony.dpoturbo.v6.safetensors https://civitai.com/api/download/models/298112?type=Model\n\n#     hf_hub_download(repo_id=\"ByteDance/Hyper-SD\", filename=\"Hyper-SDXL-8steps-CFG-lora.safetensors\", local_dir=\"/opt/models/loras\" )\n\n\n# dreamshaper\n# flux\nif flux==1:\n    hf_hub_download(repo_id=\"Kijai/flux-fp8\", filename=\"flux1-dev-fp8.safetensors\", local_dir=\"/opt/models/unet\" )\n    # hf_hub_download(repo_id=\"Kijai/flux-fp8\", filename=\"flux1-schnell-fp8-e4m3fn.safetensors\", local_dir=\"/opt/models/unet\" )\n    # hf_hub_download(repo_id=\"Comfy-Org/flux1-dev\", filename=\" flux1-dev-fp8.safetensors\", local_dir=\"/opt/models/checkpoints\" )\n    hf_hub_download(repo_id=\"black-forest-labs/FLUX.1-schnell\", filename=\"ae.safetensors\", local_dir=\"/opt/models/vae\" )\n    hf_hub_download(repo_id=\"comfyanonymous/flux_text_encoders\", filename=\"t5xxl_fp8_e4m3fn.safetensors\", local_dir=\"/opt/models/clip\" )\n#     hf_hub_download(repo_id=\"comfyanonymous/flux_text_encoders\", filename=\"clip_l.safetensors\", local_dir=\"/opt/models/clip\" )\n    hf_hub_download(repo_id=\"zer0int/CLIP-GmP-ViT-L-14\", filename=\"ViT-L-14-TEXT-detail-improved-hiT-GmP-TE-only-HF.safetensors\", local_dir=\"/opt/models/clip\" )\n\n#     !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/753328?token=bbf631e0a67a9c72d8044d3552ec3079 -d /opt/models/loras -o Black-Myth-Wukong.flux.safetensors\n#     hf_hub_download(repo_id=\"ByteDance/Hyper-SD\", filename=\"Hyper-FLUX.1-dev-8steps-lora.safetensors\", local_dir=\"/opt/models/loras\" )\n    hf_hub_download(repo_id=\"ByteDance/Hyper-SD\", filename=\"Hyper-FLUX.1-dev-16steps-lora.safetensors\", local_dir=\"/opt/models/loras\" )\n    hf_hub_download(repo_id=\"Kijai/flux-fp8\", filename=\"flux_shakker_labs_union_pro-fp8_e4m3fn.safetensors\", local_dir=\"/opt/models/controlnet\" )\n    hf_hub_download(repo_id=\"XLabs-AI/flux-ip-adapter\", filename=\"flux-ip-adapter.safetensors\", local_dir=\"/opt/models/ipadapter\" )\n    hf_hub_download(repo_id=\"openai/clip-vit-large-patch14\", filename=\"model.safetensors\", local_dir=\"/opt/models/clip_vision\" )\n    os.rename('/opt/models/clip_vision/model.safetensors', '/opt/models/clip_vision/clip-vit-large-patch14.safetensors')\n    # controlnet\n    hf_hub_download(repo_id=\"jasperai/Flux.1-dev-Controlnet-Upscaler\", filename=\"diffusion_pytorch_model.safetensors\", local_dir=\"/opt/models/controlnet\" )\n    os.rename('/opt/models/controlnet/diffusion_pytorch_model.safetensors', '/opt/models/controlnet/Flux.1-dev-Controlnet-Upscaler.safetensors')\n    \n# for krita\nimport os\nfrom huggingface_hub import snapshot_download, hf_hub_download\nif krita==1:\n    hf_hub_download(repo_id=\"comfyanonymous/ControlNet-v1-1_fp16_safetensors\",filename=\"control_v11p_sd15_inpaint_fp16.safetensors\", local_dir=\"/opt/models/controlnet\")\n    hf_hub_download(repo_id=\"comfyanonymous/ControlNet-v1-1_fp16_safetensors\",filename=\"control_lora_rank128_v11f1e_sd15_tile_fp16.safetensors\", local_dir=\"/opt/models/controlnet\")\n\n    hf_hub_download(repo_id=\"Acly/Omni-SR\",filename=\"OmniSR_X2_DIV2K.safetensors\", local_dir=\"/opt/models/upscale_models\")\n    hf_hub_download(repo_id=\"Acly/Omni-SR\",filename=\"OmniSR_X3_DIV2K.safetensors\", local_dir=\"/opt/models/upscale_models\")\n    hf_hub_download(repo_id=\"Acly/Omni-SR\",filename=\"OmniSR_X4_DIV2K.safetensors\", local_dir=\"/opt/models/upscale_models\")\n    hf_hub_download(repo_id=\"Acly/MAT\",filename=\"MAT_Places512_G_fp16.safetensors\", local_dir=\"/opt/models/upscale_models\")\n\n    hf_hub_download(repo_id=\"h94/IP-Adapter\",subfolder='models/image_encoder',filename=\"model.safetensors\", local_dir=\"/opt/models/clip_vision\")\n    # os.rename('/opt/models/clip_vision/models/image_encoder/model.safetensors','/opt/models/clip_vision/clip-vision_vit-h.safetensors')\n    !ln -s -f  /opt/models/clip_vision/models/image_encoder/model.safetensors /opt/models/clip_vision/clip-vision_vit-h.safetensors\n\n    hf_hub_download(repo_id=\"h94/IP-Adapter\",subfolder='sdxl_models',filename=\"ip-adapter_sdxl_vit-h.safetensors\", local_dir=\"/opt/models/ipadapter\")\n    hf_hub_download(repo_id=\"h94/IP-Adapter\",subfolder='models',filename=\"ip-adapter_sd15.safetensors\", local_dir=\"/opt/models/ipadapter\")\n    # os.rename('/opt/models/ipadapter/models/ip-adapter_sd15.safetensors','/opt/models/ipadapter/ip-adapter_sd15.safetensors')\n    !ln -s -f  /opt/models/ipadapter/models/ip-adapter_sd15.safetensors /opt/models/ipadapter/ip-adapter_sd15.safetensors\n\n    hf_hub_download(repo_id=\"ByteDance/Hyper-SD\",filename=\"Hyper-SD15-8steps-CFG-lora.safetensors\", local_dir=\"/opt/models/loras\")\n    hf_hub_download(repo_id=\"ByteDance/Hyper-SD\",filename=\"Hyper-SD15-8steps-CFG-lora.safetensors\", local_dir=\"/opt/models/loras\")\n    hf_hub_download(repo_id=\"ByteDance/Hyper-SD\",filename=\"Hyper-SD15-2steps-lora.safetensors\", local_dir=\"/opt/models/loras\")\n\n    hf_hub_download(repo_id=\"lllyasviel/fooocus_inpaint\",filename=\"inpaint_v26.fooocus.patch\", local_dir=\"/opt/models/inpaint\")\n    hf_hub_download(repo_id=\"lllyasviel/fooocus_inpaint\",filename=\"fooocus_inpaint_head.pth\", local_dir=\"/opt/models/inpaint\")\n\n    hf_hub_download(repo_id=\"Lykon/DreamShaper\",filename=\"DreamShaper_8_pruned.safetensors\", local_dir=\"/opt/models/checkpoints\")\n    !ln -s -f  /opt/models/DreamShaper_8_pruned.safetensors /kaggle/working/ComfyUI/models/checkpoints/DreamShaper_8_pruned.safetensors\n\n\n    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/351306 -d /opt/models -o dreamshaperxl.safetensors\n    !ln -s -f  /opt/models/dreamshaperxl.safetensors /kaggle/working/ComfyUI/models/checkpoints/dreamshaperxl.turbo.safetensors\n\n    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/128713 -d /opt/models -o DreamShaperV8.safetensors\n    !ln -s -f  /opt/models/DreamShaperV8.safetensors /kaggle/working/ComfyUI/models/checkpoints/DreamShaperV8.safetensors\n\nif controlnext_comfy==1:\n    hf_hub_download(repo_id=\"stabilityai/stable-video-diffusion-img2vid-xt-1-1\",filename=\"svd_xt_1_1.safetensors\", local_dir=\"/opt/models/checkpoints\",token='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')\n    hf_hub_download(repo_id=\"Kijai/ControlNeXt-SVD-V2-Comfy\",filename=\"controlnext-svd_v2-unet-fp16_converted.safetensors\", local_dir=\"/opt/models/unet\" )\n    # https://huggingface.co/wangfuyun/AnimateLCM-SVD-xt/resolve/main/AnimateLCM-SVD-xt-1.1.safetensors?download=true\n# sam2\nif sam2==1:\n    snapshot_download(repo_id=\"Kijai/sam2-safetensors\",  allow_patterns=[\"sam2.1*fp16.safetensors\"], local_dir=\"/opt/models/sam2\" )\n    !ln -s -f /opt/models/sam2 /kaggle/working/ComfyUI/models/sam2\n    snapshot_download(repo_id=\"ShilongLiu/GroundingDINO\",  allow_patterns=[\"*.pth\"], local_dir=\"/opt/models/grounding-dino\" )\n    !ln -s -f /opt/models/grounding-dino /kaggle/working/ComfyUI/models/grounding-dino\n    \nif cogvideo==1:\n    hf_hub_download(repo_id=\"comfyanonymous/flux_text_encoders\", filename=\"t5xxl_fp8_e4m3fn.safetensors\", local_dir=\"/opt/models/clip\")\n    hf_hub_download(repo_id=\"Kijai/CogVideoX_GGUF\", filename=\"CogVideoX_5b_fun_1_1_Pose_GGUF_Q4_0.safetensors\", local_dir=\"/opt/models/CogVideo/GGUF\")\n    hf_hub_download(repo_id=\"Kijai/CogVideoX_GGUF\", filename=\"CogVideoX_5b_fun_1_1_GGUF_Q4_0.safetensors\", local_dir=\"/opt/models/CogVideo/GGUF\")\n    hf_hub_download(repo_id=\"Kijai/CogVideoX-Fun-pruned\", filename=\"cogvideox_vae.safetensors\", local_dir=\"/opt/models/CogVideo/VAE\")","metadata":{"execution":{"iopub.status.busy":"2024-10-14T03:11:09.626349Z","iopub.execute_input":"2024-10-14T03:11:09.626660Z","iopub.status.idle":"2024-10-14T03:14:37.197976Z","shell.execute_reply.started":"2024-10-14T03:11:09.626628Z","shell.execute_reply":"2024-10-14T03:14:37.196564Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/working/ComfyUI\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"OmniSR_X2_DIV2K.safetensors:   0%|          | 0.00/1.66M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f530131518c4c2eb9f633e2bbda8e2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"OmniSR_X3_DIV2K.safetensors:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"768c13683efd48bc8efe786b03901a4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"OmniSR_X4_DIV2K.safetensors:   0%|          | 0.00/1.70M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b500c70e610468e9d020e92afa2a8e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a40bca31b4c447498467e06088506ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1x-ITF-SkinDiffDetail-Lite-v1.pth:   0%|          | 0.00/20.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d822acbeb514ba6a792d937c4aa8d1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1xDeJPG_OmniSR.pth:   0%|          | 0.00/3.26M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25ca0c1c30e94954af47f9b55a68fbd8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1xOverExposureCorrection_compact.pth:   0%|          | 0.00/2.40M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"052ef6b90c3642a897d1dec175e139bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1xUnderExposureCorrection_compact.pth:   0%|          | 0.00/2.40M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91bd5847c2744f52a94d619d512a6ba6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1x_DeBLR.pth:   0%|          | 0.00/66.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7a1d607b21f4df0a913ac4ac9d58dcd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"4x-ClearRealityV1.pth:   0%|          | 0.00/9.02M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdf1f398889f43dc9551ef05614568cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"4x-UltraSharp.pth:   0%|          | 0.00/67.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b6ca70567684fe083b37e436a0aeb4e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"4xUltrasharp_4xUltrasharpV10.pt:   0%|          | 0.00/67.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34d79f37eab04866a3ca3ec444df4a9c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"4x_NMKD-Superscale-SP_178000_G.pth:   0%|          | 0.00/67.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2cd833611544069aa74f5ed2a333d1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"4x_RealisticRescaler_100000_G.pth:   0%|          | 0.00/134M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e81c00929cb845538159b45c0aaad0df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)x_UniversalUpscalerV2-Sharp_101000_G.pth:   0%|          | 0.00/67.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41d9eb31cbbd4526a48d18e08bc9bf48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"8x_NMKD-Superscale_150000_G.pth:   0%|          | 0.00/67.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"952ae3c53eb143afbbc1183e49f1e8ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"RealESRGAN_x2.pth:   0%|          | 0.00/67.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fda8daf1e4f467aad417357449cd521"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"RealESRGAN_x4plus.pth:   0%|          | 0.00/67.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65a960d736184d5a8c183fcd1be46fce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"real-world_ccsr.ckpt:   0%|          | 0.00/7.29G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6386518209a5491193e8b6585853d445"}},"metadata":{}},{"name":"stdout","text":"\u001b[35m[\u001b[0m#40d8f3 1.9GiB/1.9GiB\u001b[36m(98%)\u001b[0m CN:16 DL:\u001b[32m288MiB\u001b[0m\u001b[35m]\u001b[0m\u001b[0m0m\u001b[35m]\u001b[0m\u001b[0m\nDownload Results:\ngid   |stat|avg speed  |path/URI\n======+====+===========+=======================================================\n40d8f3|\u001b[1;32mOK\u001b[0m  |   227MiB/s|/opt/models/checkpoints/DreamShaperV8.safetensors\n\nStatus Legend:\n(OK):download completed.\n *** Download Progress Summary as of Mon Oct 14 03:13:10 2024 ***              [0mmm0m\u001b[35m]\u001b[0m\u001b[0m\n===============================================================================\n[#f08df7 1.9GiB/1.9GiB(99%) CN:2 DL:0B]\nFILE: /opt/models/checkpoints/AWPainting.safetensors\n-------------------------------------------------------------------------------\n\n\u001b[35m[\u001b[0m#f08df7 1.9GiB/1.9GiB\u001b[36m(99%)\u001b[0m CN:2 DL:\u001b[32m0B\u001b[0m\u001b[35m]\u001b[0m\u001b[0m\nDownload Results:\ngid   |stat|avg speed  |path/URI\n======+====+===========+=======================================================\nf08df7|\u001b[1;32mOK\u001b[0m  |    32MiB/s|/opt/models/checkpoints/AWPainting.safetensors\n\nStatus Legend:\n(OK):download completed.\n\u001b[35m[\u001b[0m#5135cf 1.8GiB/1.9GiB\u001b[36m(93%)\u001b[0m CN:16 DL:\u001b[32m419MiB\u001b[0m\u001b[35m]\u001b[0m\u001b[0m0m\u001b[35m]\u001b[0m\u001b[0m\nDownload Results:\ngid   |stat|avg speed  |path/URI\n======+====+===========+=======================================================\n5135cf|\u001b[1;32mOK\u001b[0m  |   417MiB/s|/opt/models/checkpoints/ReV_Animated.safetensors\n\nStatus Legend:\n(OK):download completed.\n\u001b[35m[\u001b[0m#7cc5b3 1.9GiB/1.9GiB\u001b[36m(99%)\u001b[0m CN:1 DL:\u001b[32m375MiB\u001b[0m\u001b[35m]\u001b[0m\u001b[0mm0m\u001b[35m]\u001b[0m\u001b[0m\nDownload Results:\ngid   |stat|avg speed  |path/URI\n======+====+===========+=======================================================\n7cc5b3|\u001b[1;32mOK\u001b[0m  |   372MiB/s|/opt/models/checkpoints/MeinaMix.safetensors\n\nStatus Legend:\n(OK):download completed.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Hyper-SD15-8steps-CFG-lora.safetensors:   0%|          | 0.00/269M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8da303ba8e6e4e5880fb55dd79b53ddc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"control_v11e_sd15_ip2p_fp16.safetensors:   0%|          | 0.00/723M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68ad80672261428eaa95a840cbe1ffd1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)ntrol_v11e_sd15_shuffle_fp16.safetensors:   0%|          | 0.00/723M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"499631f9631e46c9a21e765f6cc74bc7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)ontrol_v11f1e_sd15_tile_fp16.safetensors:   0%|          | 0.00/723M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"832c858b8a0c4ee6b5bdf5a66da3df9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)ntrol_v11f1p_sd15_depth_fp16.safetensors:   0%|          | 0.00/723M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38324007a44d4d86b415d4e6e1d80216"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"control_v11p_sd15_canny_fp16.safetensors:   0%|          | 0.00/723M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a043e9a77a084f099d39d5509c46e5e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)ntrol_v11p_sd15_inpaint_fp16.safetensors:   0%|          | 0.00/723M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97b3a22098a3446f9ff822b8f8e8b0c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)ntrol_v11p_sd15_lineart_fp16.safetensors:   0%|          | 0.00/723M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"537704d482154cd89cadc29276d3cbc9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"control_v11p_sd15_mlsd_fp16.safetensors:   0%|          | 0.00/723M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8332aa156fb64d18bc8b82b064e0a32d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)rol_v11p_sd15_normalbae_fp16.safetensors:   0%|          | 0.00/723M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da8f0543da174202a8ad73ace66d9734"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)trol_v11p_sd15_openpose_fp16.safetensors:   0%|          | 0.00/723M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9275bb022dc84a7f916d94d66430255c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)trol_v11p_sd15_scribble_fp16.safetensors:   0%|          | 0.00/723M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bd00f2e0965492390645c70e31305be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"control_v11p_sd15_seg_fp16.safetensors:   0%|          | 0.00/723M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca6f6b616ed7475ab76264d89819c133"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)trol_v11p_sd15_softedge_fp16.safetensors:   0%|          | 0.00/723M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99a1f4182b8c4725943227a7439a4920"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)1p_sd15s2_lineart_anime_fp16.safetensors:   0%|          | 0.00/723M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23808ab30f774d828eb004414628c5fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"control_v11u_sd15_tile_fp16.safetensors:   0%|          | 0.00/723M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b2852cc37ce4aaea396e0eb51e0388e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"ip-adapter_sd15.safetensors:   0%|          | 0.00/44.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b598a7a147054b63a46dec9c29887935"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"ip-adapter-plus_sd15.safetensors:   0%|          | 0.00/98.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"299ed809921340bea349088530ecc34b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"ip-adapter-faceid-plusv2_sd15.bin:   0%|          | 0.00/157M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6dc3de50d4e445f8bf734cfabf24246"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)pter-faceid-plusv2_sd15_lora.safetensors:   0%|          | 0.00/51.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b42307d9d404d5e90623b9cba4e7bdc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.53G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a7f7a2d219b4a389587e16f60ac0121"}},"metadata":{}}]},{"cell_type":"code","source":"%cd /kaggle/working/ComfyUI/custom_nodes\nimport os, subprocess\ncustom_nodes = [d for d in os.listdir(\".\") if os.path.isdir(d)]\nfor custom_node in custom_nodes:\n    if os.path.exists(os.path.join(custom_node, '.git')):\n        print(f'update {custom_node}')\n        %cd $custom_node\n#         !git checkout . \n#         subprocess.run(['git', 'pull'])\n        if os.path.exists( 'requirements.txt'):\n            subprocess.run(['pip', 'install',   '-q','-r','requirements.txt'])\n        %cd /kaggle/working/ComfyUI/custom_nodes","metadata":{"execution":{"iopub.status.busy":"2024-10-14T06:19:54.337899Z","iopub.execute_input":"2024-10-14T06:19:54.338245Z","iopub.status.idle":"2024-10-14T06:20:06.134780Z","shell.execute_reply.started":"2024-10-14T06:19:54.338207Z","shell.execute_reply":"2024-10-14T06:20:06.132862Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"/kaggle/working/ComfyUI/custom_nodes\nupdate ComfyUI-AnimateDiff-Evolved\n/kaggle/working/ComfyUI/custom_nodes/ComfyUI-AnimateDiff-Evolved\n/kaggle/working/ComfyUI/custom_nodes\nupdate ComfyUI-segment-anything-2\n/kaggle/working/ComfyUI/custom_nodes/ComfyUI-segment-anything-2\n","output_type":"stream"},{"name":"stderr","text":"\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[26], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#         !git checkout . \u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#         subprocess.run(['git', 'pull'])\u001b[39;00m\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists( \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequirements.txt\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 11\u001b[0m             \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minstall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-q\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-r\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrequirements.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m         get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/working/ComfyUI/custom_nodes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    507\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n","File \u001b[0;32m/opt/conda/lib/python3.10/subprocess.py:1146\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1146\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/subprocess.py:1959\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   1961\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   1962\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n","File \u001b[0;32m/opt/conda/lib/python3.10/subprocess.py:1917\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1917\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   1920\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"# webui","metadata":{}},{"cell_type":"markdown","source":"## fixed","metadata":{}},{"cell_type":"code","source":"# !pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu124\n!rm -rf /opt/conda/lib/python3.10/site-packages/numpy-1.26.4.dist-info\n!pip install  numpy==1.25.0 numba==0.59.1 \n!pip install insightface\n!pip install face-alignment\n# ChatGLMTokenizer._pad() err, wait transformer fixed\n# !pip uninstall transformers -y; pip install transformers==4.44.2 \n!pip install onnxruntime-gpu --extra-index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/\n!pip install cpm_kernels","metadata":{"execution":{"iopub.status.busy":"2024-10-14T06:18:55.393043Z","iopub.execute_input":"2024-10-14T06:18:55.393498Z","iopub.status.idle":"2024-10-14T06:19:54.335887Z","shell.execute_reply.started":"2024-10-14T06:18:55.393431Z","shell.execute_reply":"2024-10-14T06:19:54.334738Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Requirement already satisfied: numpy==1.25.0 in /opt/conda/lib/python3.10/site-packages (1.25.0)\nRequirement already satisfied: numba==0.59.1 in /opt/conda/lib/python3.10/site-packages (0.59.1)\nRequirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba==0.59.1) (0.42.0)\nRequirement already satisfied: insightface in /opt/conda/lib/python3.10/site-packages (0.7.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from insightface) (1.25.0)\nRequirement already satisfied: onnx in /opt/conda/lib/python3.10/site-packages (from insightface) (1.17.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from insightface) (4.66.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from insightface) (2.32.3)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from insightface) (3.7.5)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from insightface) (10.3.0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from insightface) (1.14.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from insightface) (1.2.2)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from insightface) (0.23.2)\nRequirement already satisfied: easydict in /opt/conda/lib/python3.10/site-packages (from insightface) (1.13)\nRequirement already satisfied: cython in /opt/conda/lib/python3.10/site-packages (from insightface) (3.0.10)\nRequirement already satisfied: albumentations in /opt/conda/lib/python3.10/site-packages (from insightface) (1.4.15)\nRequirement already satisfied: prettytable in /opt/conda/lib/python3.10/site-packages (from insightface) (3.10.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from albumentations->insightface) (6.0.2)\nRequirement already satisfied: pydantic>=2.7.0 in /opt/conda/lib/python3.10/site-packages (from albumentations->insightface) (2.9.2)\nRequirement already satisfied: albucore>=0.0.15 in /opt/conda/lib/python3.10/site-packages (from albumentations->insightface) (0.0.16)\nRequirement already satisfied: eval-type-backport in /opt/conda/lib/python3.10/site-packages (from albumentations->insightface) (0.2.0)\nRequirement already satisfied: opencv-python-headless>=4.9.0.80 in /opt/conda/lib/python3.10/site-packages (from albumentations->insightface) (4.10.0.84)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->insightface) (3.3)\nRequirement already satisfied: imageio>=2.33 in /opt/conda/lib/python3.10/site-packages (from scikit-image->insightface) (2.34.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->insightface) (2024.5.22)\nRequirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image->insightface) (23.2)\nRequirement already satisfied: lazy-loader>=0.4 in /opt/conda/lib/python3.10/site-packages (from scikit-image->insightface) (0.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->insightface) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->insightface) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->insightface) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->insightface) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->insightface) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->insightface) (2.9.0.post0)\nRequirement already satisfied: protobuf>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from onnx->insightface) (4.25.3)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prettytable->insightface) (0.2.13)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->insightface) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->insightface) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->insightface) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->insightface) (2024.8.30)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->insightface) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->insightface) (3.5.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations->insightface) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations->insightface) (2.23.4)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations->insightface) (4.12.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->insightface) (1.16.0)\nRequirement already satisfied: face-alignment in /opt/conda/lib/python3.10/site-packages (1.4.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from face-alignment) (2.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from face-alignment) (1.25.0)\nRequirement already satisfied: scipy>=0.17 in /opt/conda/lib/python3.10/site-packages (from face-alignment) (1.14.1)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from face-alignment) (0.23.2)\nRequirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (from face-alignment) (4.10.0.84)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from face-alignment) (4.66.4)\nRequirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from face-alignment) (0.59.1)\nRequirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->face-alignment) (0.42.0)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->face-alignment) (3.3)\nRequirement already satisfied: pillow>=9.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->face-alignment) (10.3.0)\nRequirement already satisfied: imageio>=2.33 in /opt/conda/lib/python3.10/site-packages (from scikit-image->face-alignment) (2.34.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->face-alignment) (2024.5.22)\nRequirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image->face-alignment) (23.2)\nRequirement already satisfied: lazy-loader>=0.4 in /opt/conda/lib/python3.10/site-packages (from scikit-image->face-alignment) (0.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->face-alignment) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->face-alignment) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->face-alignment) (1.13.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->face-alignment) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->face-alignment) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->face-alignment) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->face-alignment) (1.3.0)\nLooking in indexes: https://pypi.org/simple, https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/\nRequirement already satisfied: onnxruntime-gpu in /opt/conda/lib/python3.10/site-packages (1.19.2)\nRequirement already satisfied: coloredlogs in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (15.0.1)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (24.3.25)\nRequirement already satisfied: numpy>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (1.25.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (23.2)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (4.25.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (1.13.3)\nRequirement already satisfied: humanfriendly>=9.1 in /opt/conda/lib/python3.10/site-packages (from coloredlogs->onnxruntime-gpu) (10.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime-gpu) (1.3.0)\n^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0mRequirement already satisfied: cpm_kernels in /opt/conda/lib/python3.10/site-packages (1.0.11)\n^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip list |grep numba\n!pip list |grep numpy\n!pip list |grep transformers\n!pip list |grep torch\n!pip list |grep cupy\n","metadata":{"execution":{"iopub.status.busy":"2024-10-14T03:24:45.366756Z","iopub.execute_input":"2024-10-14T03:24:45.367119Z","iopub.status.idle":"2024-10-14T03:24:58.908978Z","shell.execute_reply.started":"2024-10-14T03:24:45.367074Z","shell.execute_reply":"2024-10-14T03:24:58.907731Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"numba                                    0.59.1\nnumpy                                    1.25.0\ntransformers                             4.45.1\nonnx2torch                               1.5.15\nopen_clip_torch                          2.26.1\npytorch-ignite                           0.5.1\npytorch-lightning                        2.4.0\npytorch-wpe                              0.0.1\nrotary-embedding-torch                   0.8.4\ntorch                                    2.4.0\ntorch-complex                            0.4.4\ntorchaudio                               2.4.0\ntorchinfo                                1.8.0\ntorchmetrics                             1.4.2\ntorchsde                                 0.2.6\ntorchvision                              0.19.0\ncupy                                     13.3.0\ncupy-cuda12x                             13.3.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# start webui \n%cd /kaggle/working/ComfyUI\nimport subprocess\nimport urllib.request\nprint(\"The password/enpoint ip for localtunnel is:\", urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))\nsubprocess.Popen([\"lt\", \"--port\", \"8188\"])\n!python main.py --dont-print-server --force-fp16","metadata":{"execution":{"iopub.status.busy":"2024-10-14T06:20:09.301504Z","iopub.execute_input":"2024-10-14T06:20:09.301882Z","iopub.status.idle":"2024-10-14T07:23:11.600711Z","shell.execute_reply.started":"2024-10-14T06:20:09.301848Z","shell.execute_reply":"2024-10-14T07:23:11.598843Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"/kaggle/working/ComfyUI\nThe password/enpoint ip for localtunnel is: 34.145.72.142\nyour url is: https://lucky-sites-run.loca.lt\n[START] Security scan\n[DONE] Security scan\n## ComfyUI-Manager: installing dependencies done.\n** ComfyUI startup time: 2024-10-14 06:20:12.679060\n** Platform: Linux\n** Python version: 3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:45:18) [GCC 12.3.0]\n** Python executable: /opt/conda/bin/python\n** ComfyUI Path: /kaggle/working/ComfyUI\n** Log path: /kaggle/working/ComfyUI/comfyui.log\n\nPrestartup times for custom nodes:\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/rgthree-comfy\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Easy-Use\n   2.3 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Manager\n\nTotal VRAM 16269 MB, total RAM 32110 MB\npytorch version: 2.4.0\nForcing FP16.\nSet vram state to: NORMAL_VRAM\nDevice: cuda:0 Tesla P100-PCIE-16GB : cudaMallocAsync\nUsing pytorch cross attention\n[Prompt Server] web root: /kaggle/working/ComfyUI/web\nAdding extra search path checkpoints /opt/models/checkpoints/\nAdding extra search path clip /opt/models/clip/\nAdding extra search path clip_vision /opt/models/clip_vision/\nAdding extra search path configs /opt/models/configs/\nAdding extra search path controlnet /opt/models/controlnet/\nAdding extra search path embeddings /opt/models/embeddings/\nAdding extra search path loras /opt/models/loras/\nAdding extra search path upscale_models /opt/models/upscale_models/\nAdding extra search path vae /opt/models/vae/\nAdding extra search path unet /opt/models/unet/\nAdding extra search path LLM /opt/models/LLM/\nAdding extra search path sam2 /opt/models/sam2/\nAdding extra search path ipadapter /opt/models/ipadapter/\nAdding extra search path animatediff_models /opt/models/animatediff_models/\nAdding extra search path animatediff_motion_lora /opt/models/animatediff_motion_lora/\n/opt/conda/lib/python3.10/site-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n[AnimateDiffEvo] - \u001b[0;31mERROR\u001b[0m - No motion models found. Please download one and place in: ['/opt/models/animatediff_models/', '/kaggle/working/ComfyUI/custom_nodes/ComfyUI-AnimateDiff-Evolved/models', '/kaggle/working/ComfyUI/models/animatediff_models']\n/kaggle/working/ComfyUI/custom_nodes/ComfyUI-segment-anything-2/sam2/modeling/sam/transformer.py:20: UserWarning: Flash Attention is disabled as it requires a GPU with Ampere (8.0) CUDA capability.\n  OLD_GPU, USE_FLASH_ATTN, MATH_KERNEL_ON = get_sdpa_settings()\ntorch version---------------------- 2.4.0\n/opt/conda/lib/python3.10/site-packages/cupy/_environment.py:540: UserWarning: \n--------------------------------------------------------------------------------\n\n  CuPy may not function correctly because multiple CuPy packages are installed\n  in your environment:\n\n    cupy, cupy-cuda12x\n\n  Follow these steps to resolve this issue:\n\n    1. For all packages listed above, run the following command to remove all\n       existing CuPy installations:\n\n         $ pip uninstall <package_name>\n\n      If you previously installed CuPy via conda, also run the following:\n\n         $ conda uninstall cupy\n\n    2. Install the appropriate CuPy package.\n       Refer to the Installation Guide for detailed instructions.\n\n         https://docs.cupy.dev/en/stable/install.html\n\n--------------------------------------------------------------------------------\n\n  warnings.warn(f'''\nTotal VRAM 16269 MB, total RAM 32110 MB\npytorch version: 2.4.0\nForcing FP16.\nSet vram state to: NORMAL_VRAM\nDevice: cuda:0 Tesla P100-PCIE-16GB : cudaMallocAsync\nNumExpr defaulting to 4 threads.\nsageattn not found, using sdpa\nsageattn not found, using sdpa\nsageattn not found, using sdpa\n\u001b[34mWAS Node Suite: \u001b[0mOpenCV Python FFMPEG support is enabled\u001b[0m\n\u001b[34mWAS Node Suite \u001b[93mWarning: \u001b[0m`ffmpeg_bin_path` is not set in `/kaggle/working/ComfyUI/custom_nodes/was-node-suite-comfyui/was_suite_config.json` config file. Will attempt to use system ffmpeg binaries if available.\u001b[0m\n\u001b[34mWAS Node Suite: \u001b[0mFinished.\u001b[0m \u001b[32mLoaded\u001b[0m \u001b[0m218\u001b[0m \u001b[32mnodes successfully.\u001b[0m\n\n\t\u001b[3m\u001b[93m\"Don't watch the clock; do what it does. Keep going.\"\u001b[0m\u001b[3m - Sam Levenson\u001b[0m\n\n\u001b[34m[ComfyUI-Easy-Use] server: \u001b[0mv1.2.4 \u001b[92mLoaded\u001b[0m\n\u001b[34m[ComfyUI-Easy-Use] web root: \u001b[0m/kaggle/working/ComfyUI/custom_nodes/ComfyUI-Easy-Use/web_version/v2 \u001b[92mLoaded\u001b[0m\n### Loading: ComfyUI-Inspire-Pack (V1.3)\n/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n\u001b[0;33m[ReActor]\u001b[0m - \u001b[38;5;173mSTATUS\u001b[0m - \u001b[0;32mRunning v0.5.1-b2 in ComfyUI\u001b[0m\nTorch version: 2.4.0\n\n\u001b[92m[rgthree-comfy] Loaded 42 epic nodes. 🎉\u001b[00m\n\n\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using ckpts path: /kaggle/working/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts\u001b[0m\n\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using symlinks: False\u001b[0m\n\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using ort providers: ['CUDAExecutionProvider', 'DirectMLExecutionProvider', 'OpenVINOExecutionProvider', 'ROCMExecutionProvider', 'CPUExecutionProvider', 'CoreMLExecutionProvider']\u001b[0m\n### Loading: ComfyUI-Manager (V2.51.5)\n### ComfyUI Revision: 2759 [191a0d56] | Released on '2024-10-13'\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json\n\nImport times for custom nodes:\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/websocket_image_save.py\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/cg-use-everywhere\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/stability-ComfyUI-nodes\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/github-stats.json\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/Comfyui_joytag\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-post-processing-nodes\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-MimicMotionWrapper\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Custom-Scripts\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-layerdiffuse\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/rgthree-comfy\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-KJNodes\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Advanced-ControlNet\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Frame-Interpolation\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI_IPAdapter_plus\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-ControlNeXt-SVD\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-segment-anything-2\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI_BiRefNet_ll\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-FLATTEN\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/comfyui_controlnet_aux\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-AnimateDiff-Evolved\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Manager\n   0.1 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-AdvancedLivePortrait\n   0.1 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Easy-Use\n   0.1 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-LivePortraitKJ\n   0.1 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-VideoHelperSuite\n   0.1 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Inspire-Pack\n   0.9 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-fastblend\n   1.4 seconds: /kaggle/working/ComfyUI/custom_nodes/comfyui-reactor-node\n   1.8 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Inspyrenet-Rembg\n   3.2 seconds: /kaggle/working/ComfyUI/custom_nodes/was-node-suite-comfyui\n   3.4 seconds: /kaggle/working/ComfyUI/custom_nodes/GSTTS-ComfyUI\n   4.3 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-CogVideoXWrapper\n\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json\nStarting server\n\nTo see the GUI go to: http://127.0.0.1:8188\nFETCH DATA from: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Manager/extension-node-map.json [DONE]\ngot prompt\nFailed to validate prompt for output 107:\n* Sam2Segmentation 105:\n  - Return type mismatch between linked nodes: mask, STRING != MASK\nOutput will be ignored\ninvalid prompt: {'type': 'prompt_outputs_failed_validation', 'message': 'Prompt outputs failed validation', 'details': '', 'extra_info': {}}\nFETCH DATA from: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Manager/.cache/1742899825_extension-node-map.json [DONE]\nFETCH DATA from: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Manager/.cache/1514988643_custom-node-list.json [DONE]\nFETCH DATA from: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Manager/.cache/746607195_github-stats.json [DONE]\nFETCH DATA from: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Manager/.cache/1742899825_extension-node-map.json [DONE]\ngot prompt\nFailed to validate prompt for output 107:\n* VHS_LoadVideo 102:\n  - Custom validation failed for node: video - Invalid video file: ballerina_davinci.mp4\n  - Custom validation failed for node: force_rate - Invalid video file: ballerina_davinci.mp4\n  - Custom validation failed for node: force_size - Invalid video file: ballerina_davinci.mp4\n  - Custom validation failed for node: custom_width - Invalid video file: ballerina_davinci.mp4\n  - Custom validation failed for node: custom_height - Invalid video file: ballerina_davinci.mp4\n  - Custom validation failed for node: frame_load_cap - Invalid video file: ballerina_davinci.mp4\n  - Custom validation failed for node: skip_first_frames - Invalid video file: ballerina_davinci.mp4\n  - Custom validation failed for node: select_every_nth - Invalid video file: ballerina_davinci.mp4\n  - Custom validation failed for node: unique_id - Invalid video file: ballerina_davinci.mp4\n* Sam2Segmentation 105:\n  - Return type mismatch between linked nodes: mask, STRING != MASK\nOutput will be ignored\nFailed to validate prompt for output 112:\nOutput will be ignored\ninvalid prompt: {'type': 'prompt_outputs_failed_validation', 'message': 'Prompt outputs failed validation', 'details': '', 'extra_info': {}}\ngot prompt\nFailed to validate prompt for output 107:\n* Sam2Segmentation 105:\n  - Return type mismatch between linked nodes: mask, STRING != MASK\nOutput will be ignored\n[{}]\nPrompt executed in 0.32 seconds\ngot prompt\nFailed to validate prompt for output 107:\n* Sam2Segmentation 105:\n  - Return type mismatch between linked nodes: mask, STRING != MASK\nOutput will be ignored\n[{'startX': 625.57, 'startY': 203.64300000000003}]\nPrompt executed in 0.02 seconds\ngot prompt\nFailed to validate prompt for output 107:\n* Sam2Segmentation 105:\n  - Return type mismatch between linked nodes: mask, STRING != MASK\nOutput will be ignored\nPrompt executed in 0.01 seconds\ngot prompt\nFailed to validate prompt for output 107:\n* Sam2Segmentation 105:\n  - Return type mismatch between linked nodes: mask, STRING != MASK\nOutput will be ignored\nPrompt executed in 0.01 seconds\nFETCH DATA from: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Manager/extension-node-map.json [DONE]\ngot prompt\nFailed to validate prompt for output 107:\n* Sam2VideoSegmentationAddPoints 120:\n  - Required input is missing: sam2_model\nOutput will be ignored\ninvalid prompt: {'type': 'prompt_outputs_failed_validation', 'message': 'Prompt outputs failed validation', 'details': '', 'extra_info': {}}\ngot prompt\nWARNING: Sam2VideoSegmentationAddPoints.IS_CHANGED() got an unexpected keyword argument 'coordinates_positive'\nmodel_path:  /kaggle/working/ComfyUI/models/sam2/sam2.1_hiera_base_plus-fp16.safetensors\nUsing model config: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-segment-anything-2/sam2_configs/sam2.1_hiera_b+.yaml\n!!! Exception during processing !!! Loaded model is not SAM2Video\nTraceback (most recent call last):\n  File \"/kaggle/working/ComfyUI/execution.py\", line 323, in execute\n    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 198, in get_output_data\n    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 169, in _map_node_over_list\n    process_inputs(input_dict, i)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 158, in process_inputs\n    results.append(getattr(obj, func)(**inputs))\n  File \"/kaggle/working/ComfyUI/custom_nodes/ComfyUI-segment-anything-2/nodes.py\", line 457, in segment\n    raise ValueError(\"Loaded model is not SAM2Video\")\nValueError: Loaded model is not SAM2Video\n\nPrompt executed in 1.18 seconds\ngot prompt\nWARNING: Sam2VideoSegmentationAddPoints.IS_CHANGED() got an unexpected keyword argument 'coordinates_positive'\n!!! Exception during processing !!! Loaded model is not SAM2Video\nTraceback (most recent call last):\n  File \"/kaggle/working/ComfyUI/execution.py\", line 323, in execute\n    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 198, in get_output_data\n    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 169, in _map_node_over_list\n    process_inputs(input_dict, i)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 158, in process_inputs\n    results.append(getattr(obj, func)(**inputs))\n  File \"/kaggle/working/ComfyUI/custom_nodes/ComfyUI-segment-anything-2/nodes.py\", line 457, in segment\n    raise ValueError(\"Loaded model is not SAM2Video\")\nValueError: Loaded model is not SAM2Video\n\nPrompt executed in 0.01 seconds\ngot prompt\nWARNING: Sam2VideoSegmentationAddPoints.IS_CHANGED() got an unexpected keyword argument 'coordinates_positive'\nmodel_path:  /kaggle/working/ComfyUI/models/sam2/sam2.1_hiera_base_plus-fp16.safetensors\nUsing model config: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-segment-anything-2/sam2_configs/sam2.1_hiera_b+.yaml\nResizing to model input image size:  1024\npositive coordinates:  [[525 456]\n [478 329]]\nnegative coordinates:  [[0 0]]\nInitializing inference state\npropagate in video:   0%|                                | 0/16 [00:00<?, ?it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\nout_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  12%|███                     | 2/16 [00:00<00:01,  7.89it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  19%|████▌                   | 3/16 [00:00<00:02,  5.84it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  25%|██████                  | 4/16 [00:00<00:02,  4.98it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  31%|███████▌                | 5/16 [00:01<00:02,  4.45it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  38%|█████████               | 6/16 [00:01<00:02,  4.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  44%|██████████▌             | 7/16 [00:01<00:02,  3.77it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  50%|████████████            | 8/16 [00:01<00:02,  3.51it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  56%|█████████████▌          | 9/16 [00:02<00:02,  3.36it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  62%|██████████████▍        | 10/16 [00:02<00:01,  3.26it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  69%|███████████████▊       | 11/16 [00:02<00:01,  3.20it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  75%|█████████████████▎     | 12/16 [00:03<00:01,  3.16it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  81%|██████████████████▋    | 13/16 [00:03<00:00,  3.11it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  88%|████████████████████▏  | 14/16 [00:03<00:00,  3.10it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  94%|█████████████████████▌ | 15/16 [00:04<00:00,  3.09it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video: 100%|███████████████████████| 16/16 [00:04<00:00,  3.52it/s]\nTotal masks collected: 16\nPrompt executed in 8.55 seconds\ngot prompt\nWARNING: Sam2VideoSegmentationAddPoints.IS_CHANGED() got an unexpected keyword argument 'coordinates_positive'\n[{'startX': 49.60370800000001, 'startY': 210.81575900000004, 'endX': 51.37526900000001, 'endY': 207.27263700000003}]\nResizing to model input image size:  1024\npositive coordinates:  [[ 525  456]\n [ 478  329]\n [ 128  537]\n [ 229 1054]]\nnegative coordinates:  [[0 0]]\nInitializing inference state\npropagate in video:   0%|                                | 0/16 [00:00<?, ?it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\nout_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  12%|███                     | 2/16 [00:00<00:01,  9.26it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  19%|████▌                   | 3/16 [00:00<00:02,  6.27it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  25%|██████                  | 4/16 [00:00<00:02,  5.17it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  31%|███████▌                | 5/16 [00:00<00:02,  4.55it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  38%|█████████               | 6/16 [00:01<00:02,  4.12it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  44%|██████████▌             | 7/16 [00:01<00:02,  3.80it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  50%|████████████            | 8/16 [00:01<00:02,  3.54it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  56%|█████████████▌          | 9/16 [00:02<00:02,  3.37it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  62%|██████████████▍        | 10/16 [00:02<00:01,  3.27it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  69%|███████████████▊       | 11/16 [00:02<00:01,  3.21it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  75%|█████████████████▎     | 12/16 [00:03<00:01,  3.16it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  81%|██████████████████▋    | 13/16 [00:03<00:00,  3.13it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  88%|████████████████████▏  | 14/16 [00:03<00:00,  3.11it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  94%|█████████████████████▌ | 15/16 [00:04<00:00,  3.10it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video: 100%|███████████████████████| 16/16 [00:04<00:00,  3.56it/s]\nTotal masks collected: 16\nPrompt executed in 7.02 seconds\ngot prompt\nWARNING: Sam2VideoSegmentationAddPoints.IS_CHANGED() got an unexpected keyword argument 'coordinates_positive'\n[{'startX': 49.60370800000001, 'startY': 210.81575900000004, 'endX': 51.37526900000001, 'endY': 207.27263700000003}]\nResizing to model input image size:  1024\npositive coordinates:  [[ 525  456]\n [ 478  329]\n [ 128  537]\n [ 229 1054]]\nnegative coordinates:  [[0 0]]\nInitializing inference state\npropagate in video:   0%|                                 | 0/1 [00:00<?, ?it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video: 100%|████████████████████████| 1/1 [00:00<00:00, 381.40it/s]\nTotal masks collected: 1\nPrompt executed in 0.52 seconds\ngot prompt\nWARNING: Sam2VideoSegmentationAddPoints.IS_CHANGED() got an unexpected keyword argument 'coordinates_positive'\n[{'startX': 49.60370800000001, 'startY': 210.81575900000004, 'endX': 51.37526900000001, 'endY': 207.27263700000003}]\nResizing to model input image size:  1024\npositive coordinates:  [[ 525  456]\n [ 478  329]\n [ 128  537]\n [ 229 1054]]\nnegative coordinates:  [[0 0]]\nInitializing inference state\npropagate in video:   0%|                                 | 0/1 [00:00<?, ?it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video: 100%|████████████████████████| 1/1 [00:00<00:00, 373.86it/s]\nTotal masks collected: 1\nPrompt executed in 0.44 seconds\ngot prompt\nWARNING: Sam2VideoSegmentationAddPoints.IS_CHANGED() got an unexpected keyword argument 'coordinates_positive'\n[{'startX': 49.60370800000001, 'startY': 210.81575900000004, 'endX': 51.37526900000001, 'endY': 207.27263700000003}]\nResizing to model input image size:  1024\npositive coordinates:  [[ 525  456]\n [ 478  329]\n [ 128  537]\n [ 229 1054]]\nnegative coordinates:  [[0 0]]\nInitializing inference state\npropagate in video:   0%|                                 | 0/1 [00:00<?, ?it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video: 100%|████████████████████████| 1/1 [00:00<00:00, 472.44it/s]\nTotal masks collected: 1\nPrompt executed in 0.38 seconds\ngot prompt\nWARNING: Sam2VideoSegmentationAddPoints.IS_CHANGED() got an unexpected keyword argument 'coordinates_positive'\n[{'startX': 49.60370800000001, 'startY': 210.81575900000004, 'endX': 51.37526900000001, 'endY': 207.27263700000003}]\nResizing to model input image size:  1024\npositive coordinates:  [[ 525  456]\n [ 478  329]\n [ 128  537]\n [ 229 1054]]\nnegative coordinates:  [[0 0]]\nInitializing inference state\npropagate in video:   0%|                                 | 0/1 [00:00<?, ?it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video: 100%|████████████████████████| 1/1 [00:00<00:00, 435.36it/s]\nTotal masks collected: 1\nPrompt executed in 0.39 seconds\ngot prompt\nWARNING: Sam2VideoSegmentationAddPoints.IS_CHANGED() got an unexpected keyword argument 'coordinates_positive'\n[{'startX': 49.60370800000001, 'startY': 210.81575900000004, 'endX': 51.37526900000001, 'endY': 207.27263700000003}]\nResizing to model input image size:  1024\npositive coordinates:  [[ 525  456]\n [ 478  329]\n [ 128  537]\n [ 229 1054]]\nnegative coordinates:  [[0 0]]\nInitializing inference state\npropagate in video:   0%|                                 | 0/1 [00:00<?, ?it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video: 100%|████████████████████████| 1/1 [00:00<00:00, 415.69it/s]\nTotal masks collected: 1\nPrompt executed in 0.43 seconds\ngot prompt\nWARNING: Sam2VideoSegmentationAddPoints.IS_CHANGED() got an unexpected keyword argument 'coordinates_positive'\n[{'startX': 49.60370800000001, 'startY': 210.81575900000004, 'endX': 51.37526900000001, 'endY': 207.27263700000003}]\nResizing to model input image size:  1024\npositive coordinates:  [[ 499 1083]\n [ 338  608]\n [  59  863]\n [ 229 1054]]\nnegative coordinates:  [[0 0]]\nInitializing inference state\npropagate in video:   0%|                                | 0/72 [00:00<?, ?it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\nout_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:   3%|▋                       | 2/72 [00:00<00:07,  9.26it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:   4%|█                       | 3/72 [00:00<00:11,  6.25it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:   6%|█▎                      | 4/72 [00:00<00:13,  5.16it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:   7%|█▋                      | 5/72 [00:00<00:14,  4.54it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:   8%|██                      | 6/72 [00:01<00:16,  4.11it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  10%|██▎                     | 7/72 [00:01<00:17,  3.79it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  11%|██▋                     | 8/72 [00:01<00:18,  3.52it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  12%|███                     | 9/72 [00:02<00:18,  3.36it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  14%|███▏                   | 10/72 [00:02<00:18,  3.27it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  15%|███▌                   | 11/72 [00:02<00:19,  3.20it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  17%|███▊                   | 12/72 [00:03<00:18,  3.16it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  18%|████▏                  | 13/72 [00:03<00:18,  3.13it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  19%|████▍                  | 14/72 [00:03<00:18,  3.11it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  21%|████▊                  | 15/72 [00:04<00:18,  3.10it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  22%|█████                  | 16/72 [00:04<00:18,  3.09it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  24%|█████▍                 | 17/72 [00:04<00:17,  3.09it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  25%|█████▊                 | 18/72 [00:05<00:17,  3.08it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  26%|██████                 | 19/72 [00:05<00:17,  3.08it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  28%|██████▍                | 20/72 [00:05<00:16,  3.08it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  29%|██████▋                | 21/72 [00:06<00:16,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  31%|███████                | 22/72 [00:06<00:16,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  32%|███████▎               | 23/72 [00:06<00:15,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  33%|███████▋               | 24/72 [00:07<00:15,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  35%|███████▉               | 25/72 [00:07<00:15,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  36%|████████▎              | 26/72 [00:07<00:14,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  38%|████████▋              | 27/72 [00:08<00:14,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  39%|████████▉              | 28/72 [00:08<00:14,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  40%|█████████▎             | 29/72 [00:08<00:14,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  42%|█████████▌             | 30/72 [00:09<00:13,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  43%|█████████▉             | 31/72 [00:09<00:13,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  44%|██████████▏            | 32/72 [00:09<00:13,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  46%|██████████▌            | 33/72 [00:10<00:12,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  47%|██████████▊            | 34/72 [00:10<00:12,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  49%|███████████▏           | 35/72 [00:10<00:12,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  50%|███████████▌           | 36/72 [00:11<00:11,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  51%|███████████▊           | 37/72 [00:11<00:11,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  53%|████████████▏          | 38/72 [00:11<00:11,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  54%|████████████▍          | 39/72 [00:11<00:10,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  56%|████████████▊          | 40/72 [00:12<00:10,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  57%|█████████████          | 41/72 [00:12<00:10,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  58%|█████████████▍         | 42/72 [00:12<00:09,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  60%|█████████████▋         | 43/72 [00:13<00:09,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  61%|██████████████         | 44/72 [00:13<00:09,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  62%|██████████████▍        | 45/72 [00:13<00:08,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  64%|██████████████▋        | 46/72 [00:14<00:08,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  65%|███████████████        | 47/72 [00:14<00:08,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  67%|███████████████▎       | 48/72 [00:14<00:07,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  68%|███████████████▋       | 49/72 [00:15<00:07,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  69%|███████████████▉       | 50/72 [00:15<00:07,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  71%|████████████████▎      | 51/72 [00:15<00:06,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  72%|████████████████▌      | 52/72 [00:16<00:06,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  74%|████████████████▉      | 53/72 [00:16<00:06,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  75%|█████████████████▎     | 54/72 [00:16<00:05,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  76%|█████████████████▌     | 55/72 [00:17<00:05,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  78%|█████████████████▉     | 56/72 [00:17<00:05,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  79%|██████████████████▏    | 57/72 [00:17<00:04,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  81%|██████████████████▌    | 58/72 [00:18<00:04,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  82%|██████████████████▊    | 59/72 [00:18<00:04,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  83%|███████████████████▏   | 60/72 [00:18<00:03,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  85%|███████████████████▍   | 61/72 [00:19<00:03,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  86%|███████████████████▊   | 62/72 [00:19<00:03,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  88%|████████████████████▏  | 63/72 [00:19<00:02,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  89%|████████████████████▍  | 64/72 [00:20<00:02,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  90%|████████████████████▊  | 65/72 [00:20<00:02,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  92%|█████████████████████  | 66/72 [00:20<00:01,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  93%|█████████████████████▍ | 67/72 [00:21<00:01,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  94%|█████████████████████▋ | 68/72 [00:21<00:01,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  96%|██████████████████████ | 69/72 [00:21<00:00,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  97%|██████████████████████▎| 70/72 [00:22<00:00,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  99%|██████████████████████▋| 71/72 [00:22<00:00,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video: 100%|███████████████████████| 72/72 [00:22<00:00,  3.16it/s]\nTotal masks collected: 72\nPrompt executed in 35.06 seconds\ngot prompt\nWARNING: Sam2VideoSegmentationAddPoints.IS_CHANGED() got an unexpected keyword argument 'coordinates_positive'\nResizing to model input image size:  1024\npositive coordinates:  [[ 499 1083]\n [ 338  608]\n [  59  863]\n [ 229 1054]]\nnegative coordinates:  [[0 0]]\nInitializing inference state\npropagate in video:   0%|                                | 0/72 [00:00<?, ?it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\nout_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:   3%|▋                       | 2/72 [00:00<00:07,  9.23it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:   4%|█                       | 3/72 [00:00<00:11,  6.26it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:   6%|█▎                      | 4/72 [00:00<00:13,  5.16it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:   7%|█▋                      | 5/72 [00:00<00:14,  4.54it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:   8%|██                      | 6/72 [00:01<00:16,  4.12it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  10%|██▎                     | 7/72 [00:01<00:17,  3.79it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  11%|██▋                     | 8/72 [00:01<00:18,  3.53it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  12%|███                     | 9/72 [00:02<00:18,  3.37it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  14%|███▏                   | 10/72 [00:02<00:18,  3.27it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  15%|███▌                   | 11/72 [00:02<00:19,  3.19it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  17%|███▊                   | 12/72 [00:03<00:19,  3.15it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  18%|████▏                  | 13/72 [00:03<00:18,  3.13it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  19%|████▍                  | 14/72 [00:03<00:18,  3.11it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  21%|████▊                  | 15/72 [00:04<00:18,  3.09it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  22%|█████                  | 16/72 [00:04<00:18,  3.09it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  24%|█████▍                 | 17/72 [00:04<00:17,  3.08it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  25%|█████▊                 | 18/72 [00:05<00:17,  3.08it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  26%|██████                 | 19/72 [00:05<00:17,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  28%|██████▍                | 20/72 [00:05<00:17,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  29%|██████▋                | 21/72 [00:06<00:16,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  31%|███████                | 22/72 [00:06<00:16,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  32%|███████▎               | 23/72 [00:06<00:15,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  33%|███████▋               | 24/72 [00:07<00:15,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  35%|███████▉               | 25/72 [00:07<00:15,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  36%|████████▎              | 26/72 [00:07<00:14,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  38%|████████▋              | 27/72 [00:08<00:14,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  39%|████████▉              | 28/72 [00:08<00:14,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  40%|█████████▎             | 29/72 [00:08<00:14,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  42%|█████████▌             | 30/72 [00:09<00:13,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  43%|█████████▉             | 31/72 [00:09<00:13,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  44%|██████████▏            | 32/72 [00:09<00:13,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  46%|██████████▌            | 33/72 [00:10<00:12,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  47%|██████████▊            | 34/72 [00:10<00:12,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  49%|███████████▏           | 35/72 [00:10<00:12,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  50%|███████████▌           | 36/72 [00:11<00:11,  3.05it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  51%|███████████▊           | 37/72 [00:11<00:11,  3.05it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  53%|████████████▏          | 38/72 [00:11<00:11,  3.05it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  54%|████████████▍          | 39/72 [00:12<00:10,  3.05it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  56%|████████████▊          | 40/72 [00:12<00:10,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  57%|█████████████          | 41/72 [00:12<00:10,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  58%|█████████████▍         | 42/72 [00:13<00:09,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  60%|█████████████▋         | 43/72 [00:13<00:09,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  61%|██████████████         | 44/72 [00:13<00:09,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  62%|██████████████▍        | 45/72 [00:13<00:08,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  64%|██████████████▋        | 46/72 [00:14<00:08,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  65%|███████████████        | 47/72 [00:14<00:08,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  67%|███████████████▎       | 48/72 [00:14<00:07,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  68%|███████████████▋       | 49/72 [00:15<00:07,  3.05it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  69%|███████████████▉       | 50/72 [00:15<00:07,  3.05it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  71%|████████████████▎      | 51/72 [00:15<00:06,  3.05it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  72%|████████████████▌      | 52/72 [00:16<00:06,  3.05it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  74%|████████████████▉      | 53/72 [00:16<00:06,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  75%|█████████████████▎     | 54/72 [00:16<00:05,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  76%|█████████████████▌     | 55/72 [00:17<00:05,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  78%|█████████████████▉     | 56/72 [00:17<00:05,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  79%|██████████████████▏    | 57/72 [00:17<00:04,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  81%|██████████████████▌    | 58/72 [00:18<00:04,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  82%|██████████████████▊    | 59/72 [00:18<00:04,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  83%|███████████████████▏   | 60/72 [00:18<00:03,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  85%|███████████████████▍   | 61/72 [00:19<00:03,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  86%|███████████████████▊   | 62/72 [00:19<00:03,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  88%|████████████████████▏  | 63/72 [00:19<00:02,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  89%|████████████████████▍  | 64/72 [00:20<00:02,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  90%|████████████████████▊  | 65/72 [00:20<00:02,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  92%|█████████████████████  | 66/72 [00:20<00:01,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  93%|█████████████████████▍ | 67/72 [00:21<00:01,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  94%|█████████████████████▋ | 68/72 [00:21<00:01,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  96%|██████████████████████ | 69/72 [00:21<00:00,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  97%|██████████████████████▎| 70/72 [00:22<00:00,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  99%|██████████████████████▋| 71/72 [00:22<00:00,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video: 100%|███████████████████████| 72/72 [00:22<00:00,  3.16it/s]\nTotal masks collected: 72\nPrompt executed in 33.91 seconds\ngot prompt\nWARNING: Sam2VideoSegmentationAddPoints.IS_CHANGED() got an unexpected keyword argument 'coordinates_positive'\n[{'startX': 49.60370800000001, 'startY': 210.81575900000004, 'endX': 51.37526900000001, 'endY': 207.27263700000003}]\nResizing to model input image size:  1024\npositive coordinates:  [[ 499 1083]\n [ 338  608]\n [  59  863]\n [ 229 1054]]\nnegative coordinates:  [[0 0]]\nInitializing inference state\npropagate in video:   0%|                                | 0/72 [00:00<?, ?it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\nout_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:   3%|▋                       | 2/72 [00:00<00:07,  9.27it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:   4%|█                       | 3/72 [00:00<00:11,  6.26it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:   6%|█▎                      | 4/72 [00:00<00:13,  5.16it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:   7%|█▋                      | 5/72 [00:00<00:14,  4.54it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:   8%|██                      | 6/72 [00:01<00:16,  4.12it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  10%|██▎                     | 7/72 [00:01<00:17,  3.79it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  11%|██▋                     | 8/72 [00:01<00:18,  3.53it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  12%|███                     | 9/72 [00:02<00:18,  3.37it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  14%|███▏                   | 10/72 [00:02<00:18,  3.27it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  15%|███▌                   | 11/72 [00:02<00:19,  3.21it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  17%|███▊                   | 12/72 [00:03<00:18,  3.16it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  18%|████▏                  | 13/72 [00:03<00:18,  3.13it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  19%|████▍                  | 14/72 [00:03<00:18,  3.11it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  21%|████▊                  | 15/72 [00:04<00:18,  3.10it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  22%|█████                  | 16/72 [00:04<00:18,  3.09it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  24%|█████▍                 | 17/72 [00:04<00:17,  3.08it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  25%|█████▊                 | 18/72 [00:05<00:17,  3.08it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  26%|██████                 | 19/72 [00:05<00:17,  3.08it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  28%|██████▍                | 20/72 [00:05<00:16,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  29%|██████▋                | 21/72 [00:06<00:16,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  31%|███████                | 22/72 [00:06<00:16,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  32%|███████▎               | 23/72 [00:06<00:15,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  33%|███████▋               | 24/72 [00:07<00:15,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  35%|███████▉               | 25/72 [00:07<00:15,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  36%|████████▎              | 26/72 [00:07<00:14,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  38%|████████▋              | 27/72 [00:08<00:14,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  39%|████████▉              | 28/72 [00:08<00:14,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  40%|█████████▎             | 29/72 [00:08<00:14,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  42%|█████████▌             | 30/72 [00:09<00:13,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  43%|█████████▉             | 31/72 [00:09<00:13,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  44%|██████████▏            | 32/72 [00:09<00:13,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  46%|██████████▌            | 33/72 [00:10<00:12,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  47%|██████████▊            | 34/72 [00:10<00:12,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  49%|███████████▏           | 35/72 [00:10<00:12,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  50%|███████████▌           | 36/72 [00:11<00:11,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  51%|███████████▊           | 37/72 [00:11<00:11,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  53%|████████████▏          | 38/72 [00:11<00:11,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  54%|████████████▍          | 39/72 [00:11<00:10,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  56%|████████████▊          | 40/72 [00:12<00:10,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  57%|█████████████          | 41/72 [00:12<00:10,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  58%|█████████████▍         | 42/72 [00:12<00:09,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  60%|█████████████▋         | 43/72 [00:13<00:09,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  61%|██████████████         | 44/72 [00:13<00:09,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  62%|██████████████▍        | 45/72 [00:13<00:08,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  64%|██████████████▋        | 46/72 [00:14<00:08,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  65%|███████████████        | 47/72 [00:14<00:08,  3.05it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  67%|███████████████▎       | 48/72 [00:14<00:07,  3.05it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  68%|███████████████▋       | 49/72 [00:15<00:07,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  69%|███████████████▉       | 50/72 [00:15<00:07,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  71%|████████████████▎      | 51/72 [00:15<00:06,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  72%|████████████████▌      | 52/72 [00:16<00:06,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  74%|████████████████▉      | 53/72 [00:16<00:06,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  75%|█████████████████▎     | 54/72 [00:16<00:05,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  76%|█████████████████▌     | 55/72 [00:17<00:05,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  78%|█████████████████▉     | 56/72 [00:17<00:05,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  79%|██████████████████▏    | 57/72 [00:17<00:04,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  81%|██████████████████▌    | 58/72 [00:18<00:04,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  82%|██████████████████▊    | 59/72 [00:18<00:04,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  83%|███████████████████▏   | 60/72 [00:18<00:03,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  85%|███████████████████▍   | 61/72 [00:19<00:03,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  86%|███████████████████▊   | 62/72 [00:19<00:03,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  88%|████████████████████▏  | 63/72 [00:19<00:02,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  89%|████████████████████▍  | 64/72 [00:20<00:02,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  90%|████████████████████▊  | 65/72 [00:20<00:02,  3.06it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  92%|█████████████████████  | 66/72 [00:20<00:01,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  93%|█████████████████████▍ | 67/72 [00:21<00:01,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  94%|█████████████████████▋ | 68/72 [00:21<00:01,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  96%|██████████████████████ | 69/72 [00:21<00:00,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  97%|██████████████████████▎| 70/72 [00:22<00:00,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video:  99%|██████████████████████▋| 71/72 [00:22<00:00,  3.07it/s]out_mask_logits torch.Size([1, 1, 1280, 720])\npropagate in video: 100%|███████████████████████| 72/72 [00:22<00:00,  3.16it/s]\nTotal masks collected: 72\nPrompt executed in 60.51 seconds\ngot prompt\nFailed to validate prompt for output 336:\n* (prompt):\n  - Required input is missing: images\n* PreviewImage 336:\n  - Required input is missing: images\nOutput will be ignored\nFailed to validate prompt for output 307:\n* VAELoader 106:\n  - Value not in list: vae_name: 'vae-ft-mse-840000-ema-pruned.safetensors' not in []\n* ADE_LoadAnimateDiffModel 200:\n  - Value not in list: model_name: 'motion_module/mm_sd15_v3.safetensors' not in []\n* LoraLoaderModelOnly 203:\n  - Value not in list: lora_name: 'lora/mm_sd15_v3_adapter.safetensors' not in ['Hyper-SD15-8steps-CFG-lora.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors']\nOutput will be ignored\nmodel_path is /kaggle/working/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/TheMistoAI/MistoLine/Anyline/MTEED.pth\nmodel_path is /kaggle/working/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/lllyasviel/Annotators/sk_model.pth\nmodel_path is /kaggle/working/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/lllyasviel/Annotators/sk_model2.pth\nxFormers not available\nxFormers not available\nmodel_path is /kaggle/working/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/depth-anything/Depth-Anything-V2-Large/depth_anything_v2_vitl.pth\nusing MLP layer as FFN\nPrompt executed in 28.31 seconds\ngot prompt\nFailed to validate prompt for output 47:\n* CogVideoSampler 64:\n  - Return type mismatch between linked nodes: image_cond_latents, INT != LATENT\n  - Return type mismatch between linked nodes: controlnet, INT != COGVIDECONTROLNET\n  - Return type mismatch between linked nodes: context_options, INT != COGCONTEXT\nOutput will be ignored\ninvalid prompt: {'type': 'prompt_outputs_failed_validation', 'message': 'Prompt outputs failed validation', 'details': '', 'extra_info': {}}\ngot prompt\nFailed to validate prompt for output 47:\n* ImageConcanate 58:\n  - Required input is missing: image1\nOutput will be ignored\ninvalid prompt: {'type': 'prompt_outputs_failed_validation', 'message': 'Prompt outputs failed validation', 'details': '', 'extra_info': {}}\ngot prompt\nRequested to load SD3ClipModel_\nLoading 1 new model\nloaded completely 0.0 4541.693359375 True\n!!! Exception during processing !!! 'Pose' models not supported in 'CogVideoXFunVid2VidSampler', use the 'CogVideoXFunControlSampler'\nTraceback (most recent call last):\n  File \"/kaggle/working/ComfyUI/execution.py\", line 323, in execute\n    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 198, in get_output_data\n    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 169, in _map_node_over_list\n    process_inputs(input_dict, i)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 158, in process_inputs\n    results.append(getattr(obj, func)(**inputs))\n  File \"/kaggle/working/ComfyUI/custom_nodes/ComfyUI-CogVideoXWrapper/nodes.py\", line 1188, in process\n    assert \"pose\" not in base_path.lower(), \"'Pose' models not supported in 'CogVideoXFunVid2VidSampler', use the 'CogVideoXFunControlSampler'\"\nAssertionError: 'Pose' models not supported in 'CogVideoXFunVid2VidSampler', use the 'CogVideoXFunControlSampler'\n\nPrompt executed in 36.66 seconds\ngot prompt\n!!! Exception during processing !!! 'Pose' models not supported in 'CogVideoXFunVid2VidSampler', use the 'CogVideoXFunControlSampler'\nTraceback (most recent call last):\n  File \"/kaggle/working/ComfyUI/execution.py\", line 323, in execute\n    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 198, in get_output_data\n    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 169, in _map_node_over_list\n    process_inputs(input_dict, i)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 158, in process_inputs\n    results.append(getattr(obj, func)(**inputs))\n  File \"/kaggle/working/ComfyUI/custom_nodes/ComfyUI-CogVideoXWrapper/nodes.py\", line 1188, in process\n    assert \"pose\" not in base_path.lower(), \"'Pose' models not supported in 'CogVideoXFunVid2VidSampler', use the 'CogVideoXFunControlSampler'\"\nAssertionError: 'Pose' models not supported in 'CogVideoXFunVid2VidSampler', use the 'CogVideoXFunControlSampler'\n\nPrompt executed in 0.24 seconds\ngot prompt\n!!! Exception during processing !!! 'Pose' models not supported in 'CogVideoXFunVid2VidSampler', use the 'CogVideoXFunControlSampler'\nTraceback (most recent call last):\n  File \"/kaggle/working/ComfyUI/execution.py\", line 323, in execute\n    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 198, in get_output_data\n    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 169, in _map_node_over_list\n    process_inputs(input_dict, i)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 158, in process_inputs\n    results.append(getattr(obj, func)(**inputs))\n  File \"/kaggle/working/ComfyUI/custom_nodes/ComfyUI-CogVideoXWrapper/nodes.py\", line 1188, in process\n    assert \"pose\" not in base_path.lower(), \"'Pose' models not supported in 'CogVideoXFunVid2VidSampler', use the 'CogVideoXFunControlSampler'\"\nAssertionError: 'Pose' models not supported in 'CogVideoXFunVid2VidSampler', use the 'CogVideoXFunControlSampler'\n\nPrompt executed in 0.02 seconds\ngot prompt\nDownloading model to: /kaggle/working/ComfyUI/models/CogVideo/GGUF/CogVideoX_5b_fun_1_1_GGUF_Q4_0.safetensors\n!!! Exception during processing !!! Cannot generate a cpu tensor from a generator of type cuda.\nTraceback (most recent call last):\n  File \"/kaggle/working/ComfyUI/execution.py\", line 323, in execute\n    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 198, in get_output_data\n    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 169, in _map_node_over_list\n    process_inputs(input_dict, i)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 158, in process_inputs\n    results.append(getattr(obj, func)(**inputs))\n  File \"/kaggle/working/ComfyUI/custom_nodes/ComfyUI-CogVideoXWrapper/nodes.py\", line 1235, in process\n    latents = pipe(\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n    return func(*args, **kwargs)\n  File \"/kaggle/working/ComfyUI/custom_nodes/ComfyUI-CogVideoXWrapper/cogvideox_fun/pipeline_cogvideox_inpaint.py\", line 762, in __call__\n    latents_outputs = self.prepare_latents(\n  File \"/kaggle/working/ComfyUI/custom_nodes/ComfyUI-CogVideoXWrapper/cogvideox_fun/pipeline_cogvideox_inpaint.py\", line 315, in prepare_latents\n    noise = randn_tensor(shape, generator=generator, device=torch.device(\"cpu\"), dtype=dtype)\n  File \"/opt/conda/lib/python3.10/site-packages/diffusers/utils/torch_utils.py\", line 67, in randn_tensor\n    raise ValueError(f\"Cannot generate a {device} tensor from a generator of type {gen_device_type}.\")\nValueError: Cannot generate a cpu tensor from a generator of type cuda.\n\nPrompt executed in 25.04 seconds\ngot prompt\n!!! Exception during processing !!! Cannot generate a cpu tensor from a generator of type cuda.\nTraceback (most recent call last):\n  File \"/kaggle/working/ComfyUI/execution.py\", line 323, in execute\n    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 198, in get_output_data\n    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 169, in _map_node_over_list\n    process_inputs(input_dict, i)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 158, in process_inputs\n    results.append(getattr(obj, func)(**inputs))\n  File \"/kaggle/working/ComfyUI/custom_nodes/ComfyUI-CogVideoXWrapper/nodes.py\", line 1235, in process\n    latents = pipe(\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n    return func(*args, **kwargs)\n  File \"/kaggle/working/ComfyUI/custom_nodes/ComfyUI-CogVideoXWrapper/cogvideox_fun/pipeline_cogvideox_inpaint.py\", line 762, in __call__\n    latents_outputs = self.prepare_latents(\n  File \"/kaggle/working/ComfyUI/custom_nodes/ComfyUI-CogVideoXWrapper/cogvideox_fun/pipeline_cogvideox_inpaint.py\", line 315, in prepare_latents\n    noise = randn_tensor(shape, generator=generator, device=torch.device(\"cpu\"), dtype=dtype)\n  File \"/opt/conda/lib/python3.10/site-packages/diffusers/utils/torch_utils.py\", line 67, in randn_tensor\n    raise ValueError(f\"Cannot generate a {device} tensor from a generator of type {gen_device_type}.\")\nValueError: Cannot generate a cpu tensor from a generator of type cuda.\n\nPrompt executed in 0.45 seconds\ngot prompt\n!!! Exception during processing !!! Cannot generate a cpu tensor from a generator of type cuda.\nTraceback (most recent call last):\n  File \"/kaggle/working/ComfyUI/execution.py\", line 323, in execute\n    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 198, in get_output_data\n    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 169, in _map_node_over_list\n    process_inputs(input_dict, i)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 158, in process_inputs\n    results.append(getattr(obj, func)(**inputs))\n  File \"/kaggle/working/ComfyUI/custom_nodes/ComfyUI-CogVideoXWrapper/nodes.py\", line 1235, in process\n    latents = pipe(\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n    return func(*args, **kwargs)\n  File \"/kaggle/working/ComfyUI/custom_nodes/ComfyUI-CogVideoXWrapper/cogvideox_fun/pipeline_cogvideox_inpaint.py\", line 762, in __call__\n    latents_outputs = self.prepare_latents(\n  File \"/kaggle/working/ComfyUI/custom_nodes/ComfyUI-CogVideoXWrapper/cogvideox_fun/pipeline_cogvideox_inpaint.py\", line 315, in prepare_latents\n    noise = randn_tensor(shape, generator=generator, device=torch.device(\"cpu\"), dtype=dtype)\n  File \"/opt/conda/lib/python3.10/site-packages/diffusers/utils/torch_utils.py\", line 67, in randn_tensor\n    raise ValueError(f\"Cannot generate a {device} tensor from a generator of type {gen_device_type}.\")\nValueError: Cannot generate a cpu tensor from a generator of type cuda.\n\nPrompt executed in 0.41 seconds\ngot prompt\n!!! Exception during processing !!! Cannot generate a cpu tensor from a generator of type cuda.\nTraceback (most recent call last):\n  File \"/kaggle/working/ComfyUI/execution.py\", line 323, in execute\n    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 198, in get_output_data\n    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 169, in _map_node_over_list\n    process_inputs(input_dict, i)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 158, in process_inputs\n    results.append(getattr(obj, func)(**inputs))\n  File \"/kaggle/working/ComfyUI/custom_nodes/ComfyUI-CogVideoXWrapper/nodes.py\", line 1235, in process\n    latents = pipe(\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n    return func(*args, **kwargs)\n  File \"/kaggle/working/ComfyUI/custom_nodes/ComfyUI-CogVideoXWrapper/cogvideox_fun/pipeline_cogvideox_inpaint.py\", line 762, in __call__\n    latents_outputs = self.prepare_latents(\n  File \"/kaggle/working/ComfyUI/custom_nodes/ComfyUI-CogVideoXWrapper/cogvideox_fun/pipeline_cogvideox_inpaint.py\", line 315, in prepare_latents\n    noise = randn_tensor(shape, generator=generator, device=torch.device(\"cpu\"), dtype=dtype)\n  File \"/opt/conda/lib/python3.10/site-packages/diffusers/utils/torch_utils.py\", line 67, in randn_tensor\n    raise ValueError(f\"Cannot generate a {device} tensor from a generator of type {gen_device_type}.\")\nValueError: Cannot generate a cpu tensor from a generator of type cuda.\n\nPrompt executed in 0.40 seconds\ngot prompt\n!!! Exception during processing !!! Cannot generate a cpu tensor from a generator of type cuda.\nTraceback (most recent call last):\n  File \"/kaggle/working/ComfyUI/execution.py\", line 323, in execute\n    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 198, in get_output_data\n    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 169, in _map_node_over_list\n    process_inputs(input_dict, i)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 158, in process_inputs\n    results.append(getattr(obj, func)(**inputs))\n  File \"/kaggle/working/ComfyUI/custom_nodes/ComfyUI-CogVideoXWrapper/nodes.py\", line 1235, in process\n    latents = pipe(\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n    return func(*args, **kwargs)\n  File \"/kaggle/working/ComfyUI/custom_nodes/ComfyUI-CogVideoXWrapper/cogvideox_fun/pipeline_cogvideox_inpaint.py\", line 762, in __call__\n    latents_outputs = self.prepare_latents(\n  File \"/kaggle/working/ComfyUI/custom_nodes/ComfyUI-CogVideoXWrapper/cogvideox_fun/pipeline_cogvideox_inpaint.py\", line 315, in prepare_latents\n    noise = randn_tensor(shape, generator=generator, device=torch.device(\"cpu\"), dtype=dtype)\n  File \"/opt/conda/lib/python3.10/site-packages/diffusers/utils/torch_utils.py\", line 67, in randn_tensor\n    raise ValueError(f\"Cannot generate a {device} tensor from a generator of type {gen_device_type}.\")\nValueError: Cannot generate a cpu tensor from a generator of type cuda.\n\nPrompt executed in 6.71 seconds\ngot prompt\n!!! Exception during processing !!! Cannot generate a cpu tensor from a generator of type cuda.\nTraceback (most recent call last):\n  File \"/kaggle/working/ComfyUI/execution.py\", line 323, in execute\n    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 198, in get_output_data\n    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 169, in _map_node_over_list\n    process_inputs(input_dict, i)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 158, in process_inputs\n    results.append(getattr(obj, func)(**inputs))\n  File \"/kaggle/working/ComfyUI/custom_nodes/ComfyUI-CogVideoXWrapper/nodes.py\", line 1235, in process\n    latents = pipe(\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n    return func(*args, **kwargs)\n  File \"/kaggle/working/ComfyUI/custom_nodes/ComfyUI-CogVideoXWrapper/cogvideox_fun/pipeline_cogvideox_inpaint.py\", line 762, in __call__\n    latents_outputs = self.prepare_latents(\n  File \"/kaggle/working/ComfyUI/custom_nodes/ComfyUI-CogVideoXWrapper/cogvideox_fun/pipeline_cogvideox_inpaint.py\", line 315, in prepare_latents\n    noise = randn_tensor(shape, generator=generator, device=torch.device(\"cpu\"), dtype=dtype)\n  File \"/opt/conda/lib/python3.10/site-packages/diffusers/utils/torch_utils.py\", line 67, in randn_tensor\n    raise ValueError(f\"Cannot generate a {device} tensor from a generator of type {gen_device_type}.\")\nValueError: Cannot generate a cpu tensor from a generator of type cuda.\n\nPrompt executed in 5.32 seconds\ngot prompt\n!!! Exception during processing !!! Cannot generate a cpu tensor from a generator of type cuda.\nTraceback (most recent call last):\n  File \"/kaggle/working/ComfyUI/execution.py\", line 323, in execute\n    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 198, in get_output_data\n    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 169, in _map_node_over_list\n    process_inputs(input_dict, i)\n  File \"/kaggle/working/ComfyUI/execution.py\", line 158, in process_inputs\n    results.append(getattr(obj, func)(**inputs))\n  File \"/kaggle/working/ComfyUI/custom_nodes/ComfyUI-CogVideoXWrapper/nodes.py\", line 1235, in process\n    latents = pipe(\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n    return func(*args, **kwargs)\n  File \"/kaggle/working/ComfyUI/custom_nodes/ComfyUI-CogVideoXWrapper/cogvideox_fun/pipeline_cogvideox_inpaint.py\", line 762, in __call__\n    latents_outputs = self.prepare_latents(\n  File \"/kaggle/working/ComfyUI/custom_nodes/ComfyUI-CogVideoXWrapper/cogvideox_fun/pipeline_cogvideox_inpaint.py\", line 315, in prepare_latents\n    noise = randn_tensor(shape, generator=generator, device=torch.device(\"cpu\"), dtype=dtype)\n  File \"/opt/conda/lib/python3.10/site-packages/diffusers/utils/torch_utils.py\", line 67, in randn_tensor\n    raise ValueError(f\"Cannot generate a {device} tensor from a generator of type {gen_device_type}.\")\nValueError: Cannot generate a cpu tensor from a generator of type cuda.\n\nPrompt executed in 6.47 seconds\ngot prompt\nFailed to validate prompt for output 78:\n* ReActorFaceSwap 77:\n  - Value not in list: swap_model: 'inswapper_128.onnx' not in []\nOutput will be ignored\nDownloading model to: /kaggle/working/ComfyUI/models/mimicmotion/MimicMotionMergedUnet_1-0-fp16.safetensors\nLoading model from: /kaggle/working/ComfyUI/models/mimicmotion/MimicMotionMergedUnet_1-0-fp16.safetensors\nProcessing interrupted\nPrompt executed in 13.93 seconds\ngot prompt\nFailed to validate prompt for output 78:\n* ReActorFaceSwap 77:\n  - Value not in list: swap_model: 'inswapper_128.onnx' not in []\nOutput will be ignored\nLoading model from: /kaggle/working/ComfyUI/models/mimicmotion/MimicMotionMergedUnet_1-0-fp16.safetensors\nDownloading SVD model to: /kaggle/working/ComfyUI/models/mimicmotion/MimicMotionMergedUnet_1-0-fp16.safetensors\n","output_type":"stream"}]},{"cell_type":"code","source":"#clear output\n%cd /kaggle/working/ComfyUI\n!rm -rf /kaggle/working/ComfyUI/output/*\n# !rm -rf /kaggle/working/ComfyUI/input/*","metadata":{"execution":{"iopub.status.busy":"2024-10-14T03:41:15.686932Z","iopub.execute_input":"2024-10-14T03:41:15.687413Z","iopub.status.idle":"2024-10-14T03:41:16.676505Z","shell.execute_reply.started":"2024-10-14T03:41:15.687352Z","shell.execute_reply":"2024-10-14T03:41:16.675309Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"/kaggle/working/ComfyUI\n","output_type":"stream"}]},{"cell_type":"code","source":"#TODO\n# clear DISK\n%cd /kaggle/working/ComfyUI\n!du -hd1 ./|sort -hr\n!du -hd1 ./models|sort -hr\n!du -hd1 ./custom_nodes|sort -hr\n","metadata":{"execution":{"iopub.status.busy":"2024-10-14T03:41:16.680546Z","iopub.execute_input":"2024-10-14T03:41:16.680967Z","iopub.status.idle":"2024-10-14T03:41:19.740936Z","shell.execute_reply.started":"2024-10-14T03:41:16.680928Z","shell.execute_reply":"2024-10-14T03:41:19.739801Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"/kaggle/working/ComfyUI\n8.2G\t./\n6.3G\t./custom_nodes\n1.8G\t./models\n30M\t./.git\n28M\t./input\n14M\t./web\n6.9M\t./comfy\n660K\t./comfy_extras\n424K\t./user\n160K\t./__pycache__\n136K\t./tests\n108K\t./tests-unit\n84K\t./api_server\n72K\t./comfy_execution\n72K\t./.github\n68K\t./app\n48K\t./.ci\n36K\t./model_filemanager\n24K\t./script_examples\n24K\t./notebooks\n20K\t./utils\n4.0K\t./output\n1.8G\t./models/facerestore_models\n1.8G\t./models\n268K\t./models/embeddings\n52K\t./models/configs\n28K\t./models/controlnet\n8.0K\t./models/reactor\n4.0K\t./models/vae_approx\n4.0K\t./models/vae\n4.0K\t./models/upscale_models\n4.0K\t./models/unet\n4.0K\t./models/style_models\n4.0K\t./models/photomaker\n4.0K\t./models/loras\n4.0K\t./models/hypernetworks\n4.0K\t./models/gligen\n4.0K\t./models/diffusion_models\n4.0K\t./models/diffusers\n4.0K\t./models/clip_vision\n4.0K\t./models/clip\n4.0K\t./models/checkpoints\n4.0K\t./models/animatediff_motion_lora\n4.0K\t./models/animatediff_models\n6.3G\t./custom_nodes\n4.4G\t./custom_nodes/comfyui_controlnet_aux\n1.5G\t./custom_nodes/GSTTS-ComfyUI\n98M\t./custom_nodes/ComfyUI-Frame-Interpolation\n71M\t./custom_nodes/was-node-suite-comfyui\n52M\t./custom_nodes/ComfyUI-KJNodes\n35M\t./custom_nodes/ComfyUI-MimicMotionWrapper\n32M\t./custom_nodes/ComfyUI-LivePortraitKJ\n30M\t./custom_nodes/ComfyUI-AdvancedLivePortrait\n26M\t./custom_nodes/comfyui-reactor-node\n23M\t./custom_nodes/ComfyUI-Manager\n20M\t./custom_nodes/ComfyUI-Easy-Use\n16M\t./custom_nodes/cg-use-everywhere\n14M\t./custom_nodes/ComfyUI-ControlNeXt-SVD\n9.7M\t./custom_nodes/rgthree-comfy\n8.0M\t./custom_nodes/ComfyUI_BiRefNet_ll\n7.6M\t./custom_nodes/ComfyUI-post-processing-nodes\n5.8M\t./custom_nodes/ComfyUI_IPAdapter_plus\n2.7M\t./custom_nodes/ComfyUI-AnimateDiff-Evolved\n1.6M\t./custom_nodes/Comfyui_joytag\n1.5M\t./custom_nodes/ComfyUI-fastblend\n1.4M\t./custom_nodes/ComfyUI-Custom-Scripts\n1.4M\t./custom_nodes/ComfyUI-Advanced-ControlNet\n1.3M\t./custom_nodes/ComfyUI-segment-anything-2\n1.3M\t./custom_nodes/ComfyUI-VideoHelperSuite\n1.3M\t./custom_nodes/ComfyUI-Inspire-Pack\n1.2M\t./custom_nodes/ComfyUI-CogVideoXWrapper\n668K\t./custom_nodes/ComfyUI-FLATTEN\n596K\t./custom_nodes/ComfyUI-layerdiffuse\n276K\t./custom_nodes/ComfyUI-Inspyrenet-Rembg\n236K\t./custom_nodes/stability-ComfyUI-nodes\n8.0K\t./custom_nodes/__pycache__\n","output_type":"stream"}]},{"cell_type":"code","source":"# cd ","metadata":{"execution":{"iopub.status.busy":"2024-10-14T06:18:35.996321Z","iopub.execute_input":"2024-10-14T06:18:35.996748Z","iopub.status.idle":"2024-10-14T06:18:50.175830Z","shell.execute_reply.started":"2024-10-14T06:18:35.996706Z","shell.execute_reply":"2024-10-14T06:18:50.174487Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"sam2.1_hiera_base_plus-fp16.safetensors:   0%|          | 0.00/162M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65e15f107e784f63824415ba286c1da2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sam2.1_hiera_large-fp16.safetensors:   0%|          | 0.00/449M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"775bc23e69984a4692e96fb58bf39baa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sam2.1_hiera_small-fp16.safetensors:   0%|          | 0.00/92.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4db8cd7dbd8746a482eadc8d39f9129a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sam2.1_hiera_tiny-fp16.safetensors:   0%|          | 0.00/78.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6570a91dc37406e9ffe7bebc5a10fa0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"groundingdino_swinb_cogcoor.pth:   0%|          | 0.00/938M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddd65e5fd26b457d9995def2483abe0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"groundingdino_swint_ogc.pth:   0%|          | 0.00/694M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a3fa2412c82497a8b94175c9cd88d53"}},"metadata":{}}]}]}